{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BINGQILINGYA/MLtest/blob/main/AssignmentA2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQR6BJw4KtIg"
      },
      "source": [
        "# Assignment Brief: Convolutional Neural Networks in PyTorch  \n",
        "\n",
        "## Deadline: 03 November 2023, 14:00 GMT\n",
        "\n",
        "## Number of marks available: 10\n",
        "\n",
        "In this practical, we will build a convolutional neural network to classify handwritten digits. More specifically, we will use the MNIST dataset to implement and evaluate a neural network-based model for classification of handwritten digits. The main aim is for you to learn, enjoy, and hopefully benefit from it.\n",
        "\n",
        "You should implement and test your solution in PyTorch.\n",
        "\n",
        "### Please READ the whole assignment first, before starting to work on it.\n",
        "\n",
        "### How and what to submit\n",
        "\n",
        "A. A **Jupyter Notebook** with the code in all the cells executed and outputs displayed.\n",
        "\n",
        "B. Name your Notebook **COMP61011_AssignmentA2_XXXXXX.ipynb** where XXXXXX is your username such as such as abc18de. Example: `COMP61011_AssignmentA2_abc18de.ipynb`\n",
        "\n",
        "C. Upload the Jupyter Notebook in B to Blackboard under the **Computing Assignment (pytorch)** submission area before the deadline. **Please pay close attention to submitting to the right place!**\n",
        "\n",
        "D. **NO DATA UPLOAD**: Please do not upload the data files used in this Notebook. We have a copy already.\n",
        "\n",
        "\n",
        "### Assessment Criteria\n",
        "\n",
        "* Being able to use PyTorch to build, train, and evaluate a Convolutional Neural Network for supervised learning.\n",
        "\n",
        "* Understanding the architecture of a Convolutional Neural Network, and gaining practical experience in designing and training such a network.\n",
        "\n",
        "* Understanding concepts such as convolution, pooling, and padding, and how they are used in a Convolutional Neural Network. Understanding loss and activation functions.\n",
        "\n",
        "* Being able to monitor and report the performance of a neural network on a given dataset with respect to accuracy and the chosen loss function.\n",
        "\n",
        "### Code quality and use of Python libraries\n",
        "When writing your code, you will find out that there are operations that are repeated at least twice. These operations should be carried out in functions. Furthermore, if your code is unreadable, we may not award marks for that section. Make sure to check the following:\n",
        "\n",
        "* Did you include Python functions to solve the question and avoid repeating code?\n",
        "* Did you comment your code to make it readable to others?\n",
        "\n",
        "Furthermore, please try to avoid using any imports apart from the ones already provided in the Notebook. You can easily install all recommended modules for this assignment by running the following command in your terminal: `python -m pip install -r requirements.txt`\n",
        "\n",
        "\n",
        "### Late submissions\n",
        "\n",
        "We follow Department's guidelines about late submissions, i.e., a deduction of 10% of the mark each 24 hours the work is late after the deadline. NO late submission will be marked one week after the deadline. Please read [this link](https://wiki.cs.manchester.ac.uk/index.php/UGHandbook23:Main#Late_Submission_of_Coursework_Penalty).\n",
        "\n",
        "### Use of unfair means\n",
        "\n",
        "**Any form of unfair means is treated as a serious academic offence and action may be taken under the Discipline Regulations.** Please carefully read [what constitutes Unfair Means](https://documents.manchester.ac.uk/display.aspx?DocID=2870) if not sure. If you still have questions, please ask your Personal tutor or the Lecturers.\n",
        "\n",
        "-------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94XZwXctKtIj"
      },
      "source": [
        "## Background\n",
        "\n",
        "Read about convolution and [how 2-D convolution](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) and  [Max-pooling](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) are implemented in PyTorch.\n",
        "\n",
        "It would help you review the lecture notes to understand how the size of the next layer is computed; you may need to specify these as parameters, rather than them being inferred based on the model specification. Also be sure to understand the difference between `valid` and `same` padding. It'll help to understand how the sizes are affected by strides, padding, etc., in order to implement the network properly.\n",
        "\n",
        "For further reading on CNNs, you may wish to visit the [CS132n course site](https://cs231n.github.io/convolutional-networks/). For a much more in-depth guide to convolution arithmetic, see [this 2016 paper](https://arxiv.org/pdf/1603.07285v1.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3oOBwzbKtIj"
      },
      "source": [
        "## Loading the MNIST dataset\n",
        "For your convenience, the required python modules for this assignment have been provided in `requirements.txt`. You can run the following terminal command to install them: `python -m pip install -r requirements.txt`\n",
        "\n",
        "A copy of the MNIST dataset is included in PyTorch. We will download it, then load it into memory using the `torchvision` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLaN4Y3dKtIj",
        "outputId": "d5188d1a-5888-417b-c840-f823e5032696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 127382420.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 28475715.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 42413689.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 21796943.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: \n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch, torchvision, torchsummary\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# The values 0.1307 and 0.3081 used for the Normalize() transformation below are the global mean and standard\n",
        "# deviation of the MNIST dataset. This is equivalent to scaling all pixel values between [0, 1].\n",
        "transform = torchvision.transforms.Compose([\n",
        "              torchvision.transforms.ToTensor(),\n",
        "              torchvision.transforms.Normalize(\n",
        "                (0.1307,), (0.3081,))\n",
        "            ])\n",
        "\n",
        "train_data = torchvision.datasets.MNIST('', train=True, download=True, transform=transform)\n",
        "test_data = torchvision.datasets.MNIST('', train=False, download=True, transform=transform)\n",
        "\n",
        "# We can see some information about this data, including the transform we've applied.\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "QhJgCB-zKtIl",
        "outputId": "d8df10eb-046c-471c-e853-e86a998727af"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize the first 16 elements of the training set\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i in range(16):\n",
        "    ax = fig.add_subplot(4, 4, i + 1)\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "    ax.imshow(train_data.data[i], cmap='gray')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZhoZzqjKtIl"
      },
      "source": [
        "## Convolutional Neural Network (3 marks)\n",
        "\n",
        "Write a CNN class which defines your model.\n",
        "\n",
        "Below is a suggested CNN configuration, which achieves above 98% accuracy in the training, validation and testing. You could use this suggested configuration, or amend it, as you wish. If you deviate from the below configuration, you **must** include comments explaining your changes.\n",
        "- The inputs to the first layer should be 28x28x1 images (1 because these are grey scale), and this is the expected input of the model.\n",
        "- Add a convolutional layer with 25 filters of size 12x12x1 (and the ReLU non-linearity). Use a stride of 2 in both directions, and ensure that there is no padding.\n",
        "- PyTorch automatically initialises weights in most cases, but to demonstrate how it's done it here, we'll initialise weights as Gaussian random variables with mean 0 and variance 0.0025. For biases we'll initialise everything with a constant 0.1. This is because we're mainly going to be using ReLU non-linearities. **If you use a custom configuration, please ensure that you demonstrate how to manually initialise weights and biases.**\n",
        "- Add a second convolutional layer with 64 filters of size 5x5x25 that maintains the same width and height. Use stride of 1 in both directions and add padding as necessary, and use the ReLU non-linearity.\n",
        "- Add a max_pooling layer with pool size 2x2.\n",
        "- Add a Flatten-type layer: https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html.\n",
        "- Add a fully connected layer with 1024 units. Each unit in the max_pool should be connected to these 1024 units. Add the ReLU non-linearity to these units.\n",
        "- Add a Dropout layer to reduce overfitting, with a 0.2 rate.\n",
        "- Add another fully connected layer to get 10 output units, and a softmax activation function.\n",
        "\n",
        "Finally, use the [pytorch-summary](https://github.com/sksq96/pytorch-summary) package to check the configuration of your CNN model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lhhmoMaOKtIl"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "class CNN(torch.nn.Module):\n",
        "    # Your code here\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=25, kernel_size=12, stride=2)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=25, out_channels=64, kernel_size=5)\n",
        "        self.max_pool = torch.nn.MaxPool2d(kernel_size=2)\n",
        "        self.fc1 = torch.nn.Linear(256, 1024)\n",
        "        self.fc2 = torch.nn.Linear(1024, 10)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.dropout = torch.nn.Dropout(p=0.2)\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "    # remove this line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjbbCCakKtIl",
        "outputId": "ed3cca24-f737-48bb-b67c-a297703d313d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1             [-1, 25, 9, 9]           3,625\n",
            "              ReLU-2             [-1, 25, 9, 9]               0\n",
            "            Conv2d-3             [-1, 64, 5, 5]          40,064\n",
            "              ReLU-4             [-1, 64, 5, 5]               0\n",
            "         MaxPool2d-5             [-1, 64, 2, 2]               0\n",
            "            Linear-6                 [-1, 1024]         263,168\n",
            "              ReLU-7                 [-1, 1024]               0\n",
            "           Dropout-8                 [-1, 1024]               0\n",
            "            Linear-9                   [-1, 10]          10,250\n",
            "          Softmax-10                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 317,107\n",
            "Trainable params: 317,107\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.08\n",
            "Params size (MB): 1.21\n",
            "Estimated Total Size (MB): 1.29\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Summarise the model\n",
        "# Define your CNN model instance and move it to the same device as the data\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CNN().to(device)\n",
        "\n",
        "# Check the model configuration\n",
        "torchsummary.summary(model, (1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX7S6NawKtIl"
      },
      "source": [
        "## Loss function, accuracy and train/test algorithm (3 marks)\n",
        "\n",
        "- We'll use the cross-entropy loss function. Hint: you may need to one-hot encode the labels.\n",
        "- Accuracy is simply defined as the fraction of data correctly classified.\n",
        "- For training, use the [AdamOptimizer](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) (read the documentation) and set the learning rate to be 1e-4.\n",
        "- Record the training and validation accuracy for each training iteration; however, do not touch the test dataset.\n",
        "- You may find it useful to print the accuracy or loss every 100 batches or so, to see how the training is progressing. This is not required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Tnh5vdizKtIl"
      },
      "outputs": [],
      "source": [
        "# PyTorch requires that we specify a device. This is the CPU or GPU that PyTorch will use to run the model.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Your code here\n",
        "model.to(device)\n",
        "\n",
        "# Create an instance for computing the cross-entropy loss\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Create an instance to perform Adam optimization with a learning rate of 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Train the model\n",
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = 100.0 * correct / total\n",
        "\n",
        "    return train_loss, train_accuracy\n",
        "\n",
        "# Test the model\n",
        "def test(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    test_loss = running_loss / len(test_loader)\n",
        "    test_accuracy = 100.0 * correct / total\n",
        "\n",
        "    return test_loss, test_accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxTOdMAHKtIm"
      },
      "source": [
        "## Training and evaluation (2 marks)\n",
        "Train and evaluate your model on the MNIST dataset. Use a reasonable data split for evaluation, e.g. 10% of the training data. It would help to use minibatches (e.g. of size 50). Try about 1000-5000 iterations. You may want to start out with fewer iterations to make sure your code is making good progress. Once you are sure your code is correct, you can let it run for more iterations - it will take a bit of time for the model to finish training. Once you are sure your optimisation is working properly, you should run the resulting model on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsCOCseYKtIm",
        "outputId": "ba89cd27-74e0-4e68-d14b-b9e68584b422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 train_loss 1.6597709469221256 train_accuracy 82.92407407407407\n",
            "epoch 1 train_loss 1.5253954961344047 train_accuracy 94.26481481481481\n",
            "epoch 2 train_loss 1.5068572640419007 train_accuracy 95.89444444444445\n",
            "epoch 3 train_loss 1.4975328533737748 train_accuracy 96.66481481481482\n",
            "epoch 4 train_loss 1.4916184592026251 train_accuracy 97.24444444444444\n",
            "epoch 5 train_loss 1.4879851597326774 train_accuracy 97.57037037037037\n",
            "epoch 6 train_loss 1.484231122776314 train_accuracy 97.92777777777778\n",
            "epoch 7 train_loss 1.482002290531441 train_accuracy 98.13333333333334\n",
            "epoch 8 train_loss 1.480028133480637 train_accuracy 98.29074074074074\n",
            "epoch 9 train_loss 1.478704148972476 train_accuracy 98.39444444444445\n",
            "epoch 10 train_loss 1.4768962857899843 train_accuracy 98.58888888888889\n",
            "epoch 11 train_loss 1.4757758575457114 train_accuracy 98.67407407407407\n",
            "epoch 12 train_loss 1.4748474584685431 train_accuracy 98.73703703703704\n",
            "epoch 13 train_loss 1.4732735579764402 train_accuracy 98.8962962962963\n",
            "epoch 14 train_loss 1.4728258163840682 train_accuracy 98.94259259259259\n",
            "epoch 15 train_loss 1.4721103503748223 train_accuracy 99.00555555555556\n",
            "epoch 16 train_loss 1.4713228903434894 train_accuracy 99.0925925925926\n",
            "epoch 17 train_loss 1.4704255797244885 train_accuracy 99.17407407407407\n",
            "epoch 18 train_loss 1.4701700463339133 train_accuracy 99.19259259259259\n",
            "epoch 19 train_loss 1.4691544240271603 train_accuracy 99.27407407407408\n",
            "epoch 20 train_loss 1.4691079392477318 train_accuracy 99.27037037037037\n",
            "epoch 21 train_loss 1.468466924296485 train_accuracy 99.33518518518518\n",
            "epoch 22 train_loss 1.4682764018023455 train_accuracy 99.3425925925926\n",
            "epoch 23 train_loss 1.467675142376511 train_accuracy 99.41296296296296\n",
            "epoch 24 train_loss 1.4674769732687207 train_accuracy 99.41666666666667\n",
            "epoch 25 train_loss 1.4669770293765598 train_accuracy 99.47407407407407\n",
            "epoch 26 train_loss 1.4670087148745854 train_accuracy 99.47222222222223\n",
            "epoch 27 train_loss 1.4663511374482403 train_accuracy 99.52592592592593\n",
            "epoch 28 train_loss 1.4666595143300516 train_accuracy 99.5037037037037\n",
            "epoch 29 train_loss 1.4663544844698022 train_accuracy 99.53518518518518\n",
            "epoch 30 train_loss 1.4663214378886753 train_accuracy 99.52592592592593\n",
            "epoch 31 train_loss 1.4659086290333005 train_accuracy 99.56481481481481\n",
            "epoch 32 train_loss 1.465768892455984 train_accuracy 99.59074074074074\n",
            "epoch 33 train_loss 1.4652905620910504 train_accuracy 99.62592592592593\n",
            "epoch 34 train_loss 1.4656126076424563 train_accuracy 99.58148148148148\n",
            "epoch 35 train_loss 1.465516279803382 train_accuracy 99.5962962962963\n",
            "epoch 36 train_loss 1.4651182968307424 train_accuracy 99.64074074074074\n",
            "epoch 37 train_loss 1.4651981193710257 train_accuracy 99.62777777777778\n",
            "epoch 38 train_loss 1.4650350317910865 train_accuracy 99.63333333333334\n",
            "epoch 39 train_loss 1.464961925038585 train_accuracy 99.6537037037037\n",
            "epoch 40 train_loss 1.4650625865768503 train_accuracy 99.63703703703703\n",
            "epoch 41 train_loss 1.4647292133834626 train_accuracy 99.67407407407407\n",
            "epoch 42 train_loss 1.4647953242063523 train_accuracy 99.65185185185184\n",
            "epoch 43 train_loss 1.4647259406469486 train_accuracy 99.66851851851852\n",
            "epoch 44 train_loss 1.4645011606039824 train_accuracy 99.68703703703704\n",
            "epoch 45 train_loss 1.4647235250031507 train_accuracy 99.66666666666667\n",
            "epoch 46 train_loss 1.4647543752634966 train_accuracy 99.66666666666667\n",
            "epoch 47 train_loss 1.4646364326830263 train_accuracy 99.66296296296296\n",
            "epoch 48 train_loss 1.464351161872899 train_accuracy 99.69444444444444\n",
            "epoch 49 train_loss 1.4645457167316367 train_accuracy 99.67962962962963\n",
            "epoch 50 train_loss 1.4643838900106925 train_accuracy 99.69444444444444\n",
            "epoch 51 train_loss 1.4641197195759525 train_accuracy 99.71296296296296\n",
            "epoch 52 train_loss 1.4640238972725692 train_accuracy 99.72037037037038\n",
            "epoch 53 train_loss 1.4642076737350889 train_accuracy 99.70925925925926\n",
            "epoch 54 train_loss 1.464295400403164 train_accuracy 99.7074074074074\n",
            "epoch 55 train_loss 1.4640914308804054 train_accuracy 99.72592592592592\n",
            "epoch 56 train_loss 1.4641817712121539 train_accuracy 99.72037037037038\n",
            "epoch 57 train_loss 1.4642617131824847 train_accuracy 99.70925925925926\n",
            "epoch 58 train_loss 1.4643172848003883 train_accuracy 99.70185185185186\n",
            "epoch 59 train_loss 1.4638944767139577 train_accuracy 99.74259259259259\n",
            "epoch 60 train_loss 1.463948079391762 train_accuracy 99.72592592592592\n",
            "epoch 61 train_loss 1.4638983070850373 train_accuracy 99.7388888888889\n",
            "epoch 62 train_loss 1.4641232271989186 train_accuracy 99.70925925925926\n",
            "epoch 63 train_loss 1.4637573092072098 train_accuracy 99.74814814814815\n",
            "epoch 64 train_loss 1.4638181340915186 train_accuracy 99.74074074074075\n",
            "epoch 65 train_loss 1.463850278324551 train_accuracy 99.74074074074075\n",
            "epoch 66 train_loss 1.4637352491970415 train_accuracy 99.74444444444444\n",
            "epoch 67 train_loss 1.463953588406245 train_accuracy 99.73333333333333\n",
            "epoch 68 train_loss 1.4639989424634863 train_accuracy 99.73333333333333\n",
            "epoch 69 train_loss 1.4636212981409498 train_accuracy 99.76666666666667\n",
            "epoch 70 train_loss 1.4635794385715768 train_accuracy 99.76666666666667\n",
            "epoch 71 train_loss 1.4640741657327723 train_accuracy 99.72037037037038\n",
            "epoch 72 train_loss 1.4635326398743524 train_accuracy 99.77407407407408\n",
            "epoch 73 train_loss 1.4635577742700223 train_accuracy 99.76296296296296\n",
            "epoch 74 train_loss 1.463631843637537 train_accuracy 99.75925925925925\n",
            "epoch 75 train_loss 1.4641212517464604 train_accuracy 99.70555555555555\n",
            "epoch 76 train_loss 1.4635347902774811 train_accuracy 99.76851851851852\n",
            "epoch 77 train_loss 1.463598949820907 train_accuracy 99.76481481481481\n",
            "epoch 78 train_loss 1.4633097696083563 train_accuracy 99.79629629629629\n",
            "epoch 79 train_loss 1.4632590665861411 train_accuracy 99.79629629629629\n",
            "epoch 80 train_loss 1.4636877084219897 train_accuracy 99.75555555555556\n",
            "epoch 81 train_loss 1.463572112939976 train_accuracy 99.76481481481481\n",
            "epoch 82 train_loss 1.4633728648777362 train_accuracy 99.78518518518518\n",
            "epoch 83 train_loss 1.4634813435651637 train_accuracy 99.77407407407408\n",
            "epoch 84 train_loss 1.4634110231090476 train_accuracy 99.77407407407408\n",
            "epoch 85 train_loss 1.4634252803193197 train_accuracy 99.77777777777777\n",
            "epoch 86 train_loss 1.4633996354209051 train_accuracy 99.77777777777777\n",
            "epoch 87 train_loss 1.4634466191132864 train_accuracy 99.77222222222223\n",
            "epoch 88 train_loss 1.4634578502840465 train_accuracy 99.77407407407408\n",
            "epoch 89 train_loss 1.4633940720999683 train_accuracy 99.78148148148148\n",
            "epoch 90 train_loss 1.4633873846795824 train_accuracy 99.78333333333333\n",
            "epoch 91 train_loss 1.4632634728043168 train_accuracy 99.79629629629629\n",
            "epoch 92 train_loss 1.4631917662090725 train_accuracy 99.8037037037037\n",
            "epoch 93 train_loss 1.4633416955117826 train_accuracy 99.79074074074074\n",
            "epoch 94 train_loss 1.4633860265767134 train_accuracy 99.78148148148148\n",
            "epoch 95 train_loss 1.4633173889584012 train_accuracy 99.78518518518518\n",
            "epoch 96 train_loss 1.4634904936507895 train_accuracy 99.77037037037037\n",
            "epoch 97 train_loss 1.4631523365223849 train_accuracy 99.80740740740741\n",
            "epoch 98 train_loss 1.463203865841583 train_accuracy 99.79629629629629\n",
            "epoch 99 train_loss 1.463316484954622 train_accuracy 99.78703703703704\n",
            "epoch 99 validation_loss 1.4732348442077636 validation_accuracy 98.76666666666667\n",
            "epoch 100 train_loss 1.4633096680597022 train_accuracy 99.79074074074074\n",
            "epoch 101 train_loss 1.463239340208195 train_accuracy 99.7925925925926\n",
            "epoch 102 train_loss 1.4635455580773178 train_accuracy 99.77407407407408\n",
            "epoch 103 train_loss 1.4633289650634482 train_accuracy 99.79074074074074\n",
            "epoch 104 train_loss 1.4634789878571475 train_accuracy 99.76296296296296\n",
            "epoch 105 train_loss 1.4631006521207315 train_accuracy 99.80925925925926\n",
            "epoch 106 train_loss 1.463174816303783 train_accuracy 99.8\n",
            "epoch 107 train_loss 1.4631544950935575 train_accuracy 99.8037037037037\n",
            "epoch 108 train_loss 1.4633840098425195 train_accuracy 99.78148148148148\n",
            "epoch 109 train_loss 1.463027215997378 train_accuracy 99.81481481481481\n",
            "epoch 110 train_loss 1.4629132418720812 train_accuracy 99.82962962962964\n",
            "epoch 111 train_loss 1.4629569863831555 train_accuracy 99.82222222222222\n",
            "epoch 112 train_loss 1.4633071730534235 train_accuracy 99.78518518518518\n",
            "epoch 113 train_loss 1.463089273152528 train_accuracy 99.80740740740741\n",
            "epoch 114 train_loss 1.463185849123531 train_accuracy 99.8037037037037\n",
            "epoch 115 train_loss 1.4633144515532035 train_accuracy 99.78148148148148\n",
            "epoch 116 train_loss 1.4630810222140065 train_accuracy 99.81296296296296\n",
            "epoch 117 train_loss 1.4629828148418003 train_accuracy 99.82037037037037\n",
            "epoch 118 train_loss 1.4630922750190452 train_accuracy 99.80925925925926\n",
            "epoch 119 train_loss 1.4633073445823457 train_accuracy 99.79444444444445\n",
            "epoch 120 train_loss 1.4629340993033515 train_accuracy 99.82777777777778\n",
            "epoch 121 train_loss 1.463068049594208 train_accuracy 99.81111111111112\n",
            "epoch 122 train_loss 1.4631221185127894 train_accuracy 99.80925925925926\n",
            "epoch 123 train_loss 1.4630180288244177 train_accuracy 99.81481481481481\n",
            "epoch 124 train_loss 1.4629474583599302 train_accuracy 99.82407407407408\n",
            "epoch 125 train_loss 1.4630349930789737 train_accuracy 99.81666666666666\n",
            "epoch 126 train_loss 1.4630224025911756 train_accuracy 99.81481481481481\n",
            "epoch 127 train_loss 1.4629713089377792 train_accuracy 99.82222222222222\n",
            "epoch 128 train_loss 1.4633690119893463 train_accuracy 99.78148148148148\n",
            "epoch 129 train_loss 1.463000304279504 train_accuracy 99.81666666666666\n",
            "epoch 130 train_loss 1.462832350201077 train_accuracy 99.83518518518518\n",
            "epoch 131 train_loss 1.4630192425515918 train_accuracy 99.81481481481481\n",
            "epoch 132 train_loss 1.4627997503236487 train_accuracy 99.83333333333333\n",
            "epoch 133 train_loss 1.4633762932486005 train_accuracy 99.77962962962962\n",
            "epoch 134 train_loss 1.4630843041119752 train_accuracy 99.80925925925926\n",
            "epoch 135 train_loss 1.4629850143635714 train_accuracy 99.81851851851852\n",
            "epoch 136 train_loss 1.4630211193252494 train_accuracy 99.81481481481481\n",
            "epoch 137 train_loss 1.463234700538494 train_accuracy 99.79814814814814\n",
            "epoch 138 train_loss 1.4629117422633702 train_accuracy 99.82777777777778\n",
            "epoch 139 train_loss 1.4629919499158859 train_accuracy 99.81666666666666\n",
            "epoch 140 train_loss 1.4630451167071308 train_accuracy 99.81666666666666\n",
            "epoch 141 train_loss 1.462924779013351 train_accuracy 99.82037037037037\n",
            "epoch 142 train_loss 1.4629364890080911 train_accuracy 99.82592592592593\n",
            "epoch 143 train_loss 1.463053028009556 train_accuracy 99.81481481481481\n",
            "epoch 144 train_loss 1.4631776913448615 train_accuracy 99.80185185185185\n",
            "epoch 145 train_loss 1.4630872598400821 train_accuracy 99.80555555555556\n",
            "epoch 146 train_loss 1.4627448128329383 train_accuracy 99.8425925925926\n",
            "epoch 147 train_loss 1.4632422493563757 train_accuracy 99.79074074074074\n",
            "epoch 148 train_loss 1.4629253972459721 train_accuracy 99.82592592592593\n",
            "epoch 149 train_loss 1.4630514293909074 train_accuracy 99.81481481481481\n",
            "epoch 150 train_loss 1.4629162509132314 train_accuracy 99.82777777777778\n",
            "epoch 151 train_loss 1.4629975034130944 train_accuracy 99.81666666666666\n",
            "epoch 152 train_loss 1.4629819249665295 train_accuracy 99.82407407407408\n",
            "epoch 153 train_loss 1.4630225530377141 train_accuracy 99.81296296296296\n",
            "epoch 154 train_loss 1.4630562387130879 train_accuracy 99.81296296296296\n",
            "epoch 155 train_loss 1.4627319987173433 train_accuracy 99.84444444444445\n",
            "epoch 156 train_loss 1.4629607123357278 train_accuracy 99.81666666666666\n",
            "epoch 157 train_loss 1.4629853845746428 train_accuracy 99.81851851851852\n",
            "epoch 158 train_loss 1.4627831391714237 train_accuracy 99.83888888888889\n",
            "epoch 159 train_loss 1.4630145330120017 train_accuracy 99.81851851851852\n",
            "epoch 160 train_loss 1.4629137567899846 train_accuracy 99.82037037037037\n",
            "epoch 161 train_loss 1.4627995165409866 train_accuracy 99.83888888888889\n",
            "epoch 162 train_loss 1.4632098309419774 train_accuracy 99.79074074074074\n",
            "epoch 163 train_loss 1.4629722590799685 train_accuracy 99.81851851851852\n",
            "epoch 164 train_loss 1.4626011708268414 train_accuracy 99.85555555555555\n",
            "epoch 165 train_loss 1.4627666589286592 train_accuracy 99.84074074074074\n",
            "epoch 166 train_loss 1.4630141506592433 train_accuracy 99.81481481481481\n",
            "epoch 167 train_loss 1.462757342281165 train_accuracy 99.84074074074074\n",
            "epoch 168 train_loss 1.4627832237217162 train_accuracy 99.84074074074074\n",
            "epoch 169 train_loss 1.4629343292227497 train_accuracy 99.82407407407408\n",
            "epoch 170 train_loss 1.4630340039730072 train_accuracy 99.81111111111112\n",
            "epoch 171 train_loss 1.4629420697689057 train_accuracy 99.82592592592593\n",
            "epoch 172 train_loss 1.4627282681288543 train_accuracy 99.84444444444445\n",
            "epoch 173 train_loss 1.4632536931170357 train_accuracy 99.79444444444445\n",
            "epoch 174 train_loss 1.4628854118011616 train_accuracy 99.82777777777778\n",
            "epoch 175 train_loss 1.4627230906928028 train_accuracy 99.84444444444445\n",
            "epoch 176 train_loss 1.46290561998332 train_accuracy 99.82407407407408\n",
            "epoch 177 train_loss 1.462867866401319 train_accuracy 99.82777777777778\n",
            "epoch 178 train_loss 1.4628392020861307 train_accuracy 99.83148148148148\n",
            "epoch 179 train_loss 1.4627267025135182 train_accuracy 99.8425925925926\n",
            "epoch 180 train_loss 1.4629832275487757 train_accuracy 99.81666666666666\n",
            "epoch 181 train_loss 1.4629129492574269 train_accuracy 99.82592592592593\n",
            "epoch 182 train_loss 1.4629354374276267 train_accuracy 99.82222222222222\n",
            "epoch 183 train_loss 1.4629619744088915 train_accuracy 99.82037037037037\n",
            "epoch 184 train_loss 1.4627354745511656 train_accuracy 99.8425925925926\n",
            "epoch 185 train_loss 1.4625765758532066 train_accuracy 99.85740740740741\n",
            "epoch 186 train_loss 1.4628335661358303 train_accuracy 99.82962962962964\n",
            "epoch 187 train_loss 1.46286789101583 train_accuracy 99.82962962962964\n",
            "epoch 188 train_loss 1.46294871226505 train_accuracy 99.82037037037037\n",
            "epoch 189 train_loss 1.4628114855951733 train_accuracy 99.83518518518518\n",
            "epoch 190 train_loss 1.4626727738866099 train_accuracy 99.84814814814816\n",
            "epoch 191 train_loss 1.462842783111113 train_accuracy 99.83148148148148\n",
            "epoch 192 train_loss 1.4629096226559746 train_accuracy 99.82592592592593\n",
            "epoch 193 train_loss 1.462886890437868 train_accuracy 99.82407407407408\n",
            "epoch 194 train_loss 1.462723457592505 train_accuracy 99.84444444444445\n",
            "epoch 195 train_loss 1.462892887879301 train_accuracy 99.82407407407408\n",
            "epoch 196 train_loss 1.4629344356280787 train_accuracy 99.81851851851852\n",
            "epoch 197 train_loss 1.4627443810304006 train_accuracy 99.84074074074074\n",
            "epoch 198 train_loss 1.4631598387603406 train_accuracy 99.79814814814814\n",
            "epoch 199 train_loss 1.4627753948723827 train_accuracy 99.84074074074074\n",
            "epoch 199 validation_loss 1.472998105486234 validation_accuracy 98.8\n",
            "epoch 200 train_loss 1.4626525935199526 train_accuracy 99.85\n",
            "epoch 201 train_loss 1.4626978507748356 train_accuracy 99.8462962962963\n",
            "epoch 202 train_loss 1.4627661850717333 train_accuracy 99.84074074074074\n",
            "epoch 203 train_loss 1.4629464268684387 train_accuracy 99.81666666666666\n",
            "epoch 204 train_loss 1.4627060177149596 train_accuracy 99.84814814814816\n",
            "epoch 205 train_loss 1.4626499436519764 train_accuracy 99.8537037037037\n",
            "epoch 206 train_loss 1.462628142038981 train_accuracy 99.85185185185185\n",
            "epoch 207 train_loss 1.462834558001271 train_accuracy 99.83333333333333\n",
            "epoch 208 train_loss 1.462797701579553 train_accuracy 99.83148148148148\n",
            "epoch 209 train_loss 1.4628354303262852 train_accuracy 99.83148148148148\n",
            "epoch 210 train_loss 1.462762575900113 train_accuracy 99.84074074074074\n",
            "epoch 211 train_loss 1.4628284668480909 train_accuracy 99.83518518518518\n",
            "epoch 212 train_loss 1.4629908918230623 train_accuracy 99.81851851851852\n",
            "epoch 213 train_loss 1.462666568601573 train_accuracy 99.85185185185185\n",
            "epoch 214 train_loss 1.4627772918453923 train_accuracy 99.83703703703704\n",
            "epoch 215 train_loss 1.4627272019783655 train_accuracy 99.84444444444445\n",
            "epoch 216 train_loss 1.462779685192638 train_accuracy 99.84074074074074\n",
            "epoch 217 train_loss 1.4629075907998614 train_accuracy 99.82222222222222\n",
            "epoch 218 train_loss 1.4627705289257897 train_accuracy 99.84074074074074\n",
            "epoch 219 train_loss 1.4628175982722529 train_accuracy 99.83333333333333\n",
            "epoch 220 train_loss 1.4627107965725439 train_accuracy 99.8462962962963\n",
            "epoch 221 train_loss 1.4626571549309624 train_accuracy 99.85185185185185\n",
            "epoch 222 train_loss 1.462903697733526 train_accuracy 99.82777777777778\n",
            "epoch 223 train_loss 1.4626518602724428 train_accuracy 99.85555555555555\n",
            "epoch 224 train_loss 1.4625064727332857 train_accuracy 99.86481481481482\n",
            "epoch 225 train_loss 1.4628604154895852 train_accuracy 99.82962962962964\n",
            "epoch 226 train_loss 1.462742512314408 train_accuracy 99.8425925925926\n",
            "epoch 227 train_loss 1.4626511481073168 train_accuracy 99.85\n",
            "epoch 228 train_loss 1.4626302608737238 train_accuracy 99.8537037037037\n",
            "epoch 229 train_loss 1.462927226998188 train_accuracy 99.82222222222222\n",
            "epoch 230 train_loss 1.4628234486888956 train_accuracy 99.83333333333333\n",
            "epoch 231 train_loss 1.4625218606657453 train_accuracy 99.86481481481482\n",
            "epoch 232 train_loss 1.4626092871030172 train_accuracy 99.8537037037037\n",
            "epoch 233 train_loss 1.4625590601453076 train_accuracy 99.85925925925926\n",
            "epoch 234 train_loss 1.462712977881785 train_accuracy 99.84814814814816\n",
            "epoch 235 train_loss 1.4627477568608742 train_accuracy 99.84074074074074\n",
            "epoch 236 train_loss 1.4627789582367297 train_accuracy 99.83703703703704\n",
            "epoch 237 train_loss 1.462661752435896 train_accuracy 99.85185185185185\n",
            "epoch 238 train_loss 1.4626244139892084 train_accuracy 99.85555555555555\n",
            "epoch 239 train_loss 1.4628313542516143 train_accuracy 99.83333333333333\n",
            "epoch 240 train_loss 1.4627175898463638 train_accuracy 99.8425925925926\n",
            "epoch 241 train_loss 1.4625569118393793 train_accuracy 99.86296296296297\n",
            "epoch 242 train_loss 1.462552614013354 train_accuracy 99.86111111111111\n",
            "epoch 243 train_loss 1.4628390229410595 train_accuracy 99.83333333333333\n",
            "epoch 244 train_loss 1.4625921127972779 train_accuracy 99.85740740740741\n",
            "epoch 245 train_loss 1.4625976498480195 train_accuracy 99.85555555555555\n",
            "epoch 246 train_loss 1.462446814113193 train_accuracy 99.87037037037037\n",
            "epoch 247 train_loss 1.462845241913089 train_accuracy 99.83148148148148\n",
            "epoch 248 train_loss 1.4626922635016617 train_accuracy 99.8462962962963\n",
            "epoch 249 train_loss 1.462838066065753 train_accuracy 99.82962962962964\n",
            "epoch 250 train_loss 1.4625440429758143 train_accuracy 99.85925925925926\n",
            "epoch 251 train_loss 1.4626367359249681 train_accuracy 99.8537037037037\n",
            "epoch 252 train_loss 1.4626014963344292 train_accuracy 99.8537037037037\n",
            "epoch 253 train_loss 1.4625693907340367 train_accuracy 99.85740740740741\n",
            "epoch 254 train_loss 1.4628024795541057 train_accuracy 99.83333333333333\n",
            "epoch 255 train_loss 1.4627183811532127 train_accuracy 99.8425925925926\n",
            "epoch 256 train_loss 1.4627452584328475 train_accuracy 99.84074074074074\n",
            "epoch 257 train_loss 1.4628220392598046 train_accuracy 99.83518518518518\n",
            "epoch 258 train_loss 1.4624644079694042 train_accuracy 99.86851851851851\n",
            "epoch 259 train_loss 1.4625651384945269 train_accuracy 99.85925925925926\n",
            "epoch 260 train_loss 1.462522174804299 train_accuracy 99.86296296296297\n",
            "epoch 261 train_loss 1.462638951672448 train_accuracy 99.85185185185185\n",
            "epoch 262 train_loss 1.4626129048841972 train_accuracy 99.85740740740741\n",
            "epoch 263 train_loss 1.4626573974335635 train_accuracy 99.85185185185185\n",
            "epoch 264 train_loss 1.4624385281845376 train_accuracy 99.87222222222222\n",
            "epoch 265 train_loss 1.4626412874018704 train_accuracy 99.85185185185185\n",
            "epoch 266 train_loss 1.4624341283683424 train_accuracy 99.87222222222222\n",
            "epoch 267 train_loss 1.4626788483725655 train_accuracy 99.85\n",
            "epoch 268 train_loss 1.4627847338164295 train_accuracy 99.83703703703704\n",
            "epoch 269 train_loss 1.462616965064296 train_accuracy 99.85555555555555\n",
            "epoch 270 train_loss 1.4627129842837652 train_accuracy 99.84444444444445\n",
            "epoch 271 train_loss 1.4626778106998515 train_accuracy 99.85185185185185\n",
            "epoch 272 train_loss 1.4626752630428033 train_accuracy 99.8462962962963\n",
            "epoch 273 train_loss 1.4627116510161646 train_accuracy 99.8462962962963\n",
            "epoch 274 train_loss 1.462544874570988 train_accuracy 99.86111111111111\n",
            "epoch 275 train_loss 1.4624105474463216 train_accuracy 99.87407407407407\n",
            "epoch 276 train_loss 1.4629848650208226 train_accuracy 99.81481481481481\n",
            "epoch 277 train_loss 1.4624332383826928 train_accuracy 99.87222222222222\n",
            "epoch 278 train_loss 1.4625690145625008 train_accuracy 99.85925925925926\n",
            "epoch 279 train_loss 1.4626781551926225 train_accuracy 99.84444444444445\n",
            "epoch 280 train_loss 1.462539389508742 train_accuracy 99.86111111111111\n",
            "epoch 281 train_loss 1.4624668735044974 train_accuracy 99.86851851851851\n",
            "epoch 282 train_loss 1.462528062529034 train_accuracy 99.86296296296297\n",
            "epoch 283 train_loss 1.462391859403363 train_accuracy 99.87592592592593\n",
            "epoch 284 train_loss 1.4628619772416573 train_accuracy 99.83148148148148\n",
            "epoch 285 train_loss 1.4625150936621207 train_accuracy 99.86666666666666\n",
            "epoch 286 train_loss 1.4625888927115334 train_accuracy 99.85740740740741\n",
            "epoch 287 train_loss 1.462695531381501 train_accuracy 99.84814814814816\n",
            "epoch 288 train_loss 1.4626949036562884 train_accuracy 99.84814814814816\n",
            "epoch 289 train_loss 1.4626493966137921 train_accuracy 99.85\n",
            "epoch 290 train_loss 1.462479625807868 train_accuracy 99.87037037037037\n",
            "epoch 291 train_loss 1.4625299362120805 train_accuracy 99.86296296296297\n",
            "epoch 292 train_loss 1.4623914261658986 train_accuracy 99.87592592592593\n",
            "epoch 293 train_loss 1.4625598932857866 train_accuracy 99.85925925925926\n",
            "epoch 294 train_loss 1.4626905582569263 train_accuracy 99.8462962962963\n",
            "epoch 295 train_loss 1.462680153383149 train_accuracy 99.84814814814816\n",
            "epoch 296 train_loss 1.46266201933225 train_accuracy 99.85\n",
            "epoch 297 train_loss 1.462611108356052 train_accuracy 99.8537037037037\n",
            "epoch 298 train_loss 1.462445738028597 train_accuracy 99.87222222222222\n",
            "epoch 299 train_loss 1.4626381719553911 train_accuracy 99.85185185185185\n",
            "epoch 299 validation_loss 1.4729788949092228 validation_accuracy 98.76666666666667\n",
            "epoch 300 train_loss 1.4626344759155203 train_accuracy 99.85185185185185\n",
            "epoch 301 train_loss 1.4626121153434117 train_accuracy 99.85740740740741\n",
            "epoch 302 train_loss 1.462667875930115 train_accuracy 99.85185185185185\n",
            "epoch 303 train_loss 1.4626349286900626 train_accuracy 99.85185185185185\n",
            "epoch 304 train_loss 1.462705464385174 train_accuracy 99.84444444444445\n",
            "epoch 305 train_loss 1.4628043093063212 train_accuracy 99.83333333333333\n",
            "epoch 306 train_loss 1.462623037121914 train_accuracy 99.8537037037037\n",
            "epoch 307 train_loss 1.4624477908567146 train_accuracy 99.87037037037037\n",
            "epoch 308 train_loss 1.4624489931044755 train_accuracy 99.87222222222222\n",
            "epoch 309 train_loss 1.462807861853529 train_accuracy 99.83148148148148\n",
            "epoch 310 train_loss 1.4625615207133469 train_accuracy 99.85925925925926\n",
            "epoch 311 train_loss 1.462479657597012 train_accuracy 99.86851851851851\n",
            "epoch 312 train_loss 1.4625828399702354 train_accuracy 99.85925925925926\n",
            "epoch 313 train_loss 1.4628150002823936 train_accuracy 99.83703703703704\n",
            "epoch 314 train_loss 1.4626829588854755 train_accuracy 99.84444444444445\n",
            "epoch 315 train_loss 1.4625392453538046 train_accuracy 99.86111111111111\n",
            "epoch 316 train_loss 1.462522444460127 train_accuracy 99.86296296296297\n",
            "epoch 317 train_loss 1.4625823354279552 train_accuracy 99.85740740740741\n",
            "epoch 318 train_loss 1.4624603764878379 train_accuracy 99.86851851851851\n",
            "epoch 319 train_loss 1.46256566312578 train_accuracy 99.85925925925926\n",
            "epoch 320 train_loss 1.4626205171699878 train_accuracy 99.85555555555555\n",
            "epoch 321 train_loss 1.4625266093898703 train_accuracy 99.86481481481482\n",
            "epoch 322 train_loss 1.4624849136228915 train_accuracy 99.86666666666666\n",
            "epoch 323 train_loss 1.4624117228719924 train_accuracy 99.87407407407407\n",
            "epoch 324 train_loss 1.4624458000615792 train_accuracy 99.87222222222222\n",
            "epoch 325 train_loss 1.4626561015844346 train_accuracy 99.85\n",
            "epoch 326 train_loss 1.4624904306950393 train_accuracy 99.86666666666666\n",
            "epoch 327 train_loss 1.4626473829702096 train_accuracy 99.85185185185185\n",
            "epoch 328 train_loss 1.4625295797983806 train_accuracy 99.86666666666666\n",
            "epoch 329 train_loss 1.4625031816738623 train_accuracy 99.86666666666666\n",
            "epoch 330 train_loss 1.462444053755866 train_accuracy 99.87037037037037\n",
            "epoch 331 train_loss 1.4627302126752006 train_accuracy 99.84074074074074\n",
            "epoch 332 train_loss 1.4625021555909403 train_accuracy 99.86666666666666\n",
            "epoch 333 train_loss 1.4623581846555074 train_accuracy 99.87962962962963\n",
            "epoch 334 train_loss 1.46237414015664 train_accuracy 99.87777777777778\n",
            "epoch 335 train_loss 1.4623542889400765 train_accuracy 99.87962962962963\n",
            "epoch 336 train_loss 1.4631293124622768 train_accuracy 99.8037037037037\n",
            "epoch 337 train_loss 1.462562835768417 train_accuracy 99.86111111111111\n",
            "epoch 338 train_loss 1.4624689192683609 train_accuracy 99.86851851851851\n",
            "epoch 339 train_loss 1.4627612505797987 train_accuracy 99.83703703703704\n",
            "epoch 340 train_loss 1.4625513597770974 train_accuracy 99.86111111111111\n",
            "epoch 341 train_loss 1.462434932479152 train_accuracy 99.87222222222222\n",
            "epoch 342 train_loss 1.462488074766265 train_accuracy 99.86666666666666\n",
            "epoch 343 train_loss 1.4627041155541385 train_accuracy 99.8462962962963\n",
            "epoch 344 train_loss 1.4626162674691943 train_accuracy 99.85\n",
            "epoch 345 train_loss 1.4624493496285544 train_accuracy 99.87037037037037\n",
            "epoch 346 train_loss 1.4625915188480307 train_accuracy 99.85555555555555\n",
            "epoch 347 train_loss 1.4624278884243083 train_accuracy 99.87222222222222\n",
            "epoch 348 train_loss 1.4626561205696176 train_accuracy 99.85185185185185\n",
            "epoch 349 train_loss 1.4626616575099805 train_accuracy 99.8537037037037\n",
            "epoch 350 train_loss 1.4625178879057918 train_accuracy 99.86481481481482\n",
            "epoch 351 train_loss 1.46262522218404 train_accuracy 99.85185185185185\n",
            "epoch 352 train_loss 1.4625580187197085 train_accuracy 99.86111111111111\n",
            "epoch 353 train_loss 1.4624827084717926 train_accuracy 99.86851851851851\n",
            "epoch 354 train_loss 1.4625040857880205 train_accuracy 99.86666666666666\n",
            "epoch 355 train_loss 1.4625945185069684 train_accuracy 99.85555555555555\n",
            "epoch 356 train_loss 1.4626605023940404 train_accuracy 99.85\n",
            "epoch 357 train_loss 1.4626974765901213 train_accuracy 99.8462962962963\n",
            "epoch 358 train_loss 1.4624914097565191 train_accuracy 99.86296296296297\n",
            "epoch 359 train_loss 1.4624942739804585 train_accuracy 99.86481481481482\n",
            "epoch 360 train_loss 1.4624440242846808 train_accuracy 99.87037037037037\n",
            "epoch 361 train_loss 1.4623637505151608 train_accuracy 99.87962962962963\n",
            "epoch 362 train_loss 1.4623976554031726 train_accuracy 99.87592592592593\n",
            "epoch 363 train_loss 1.4626408719354205 train_accuracy 99.85\n",
            "epoch 364 train_loss 1.4628396687684235 train_accuracy 99.83518518518518\n",
            "epoch 365 train_loss 1.4624506987907269 train_accuracy 99.87037037037037\n",
            "epoch 366 train_loss 1.4623740271285728 train_accuracy 99.87777777777778\n",
            "epoch 367 train_loss 1.4623779460235877 train_accuracy 99.87777777777778\n",
            "epoch 368 train_loss 1.4624834305710264 train_accuracy 99.87037037037037\n",
            "epoch 369 train_loss 1.4624331713826568 train_accuracy 99.87222222222222\n",
            "epoch 370 train_loss 1.4623836597910633 train_accuracy 99.87777777777778\n",
            "epoch 371 train_loss 1.4624829684142713 train_accuracy 99.86666666666666\n",
            "epoch 372 train_loss 1.4625703631727784 train_accuracy 99.85925925925926\n",
            "epoch 373 train_loss 1.4626782345551033 train_accuracy 99.8462962962963\n",
            "epoch 374 train_loss 1.4625481652992742 train_accuracy 99.85925925925926\n",
            "epoch 375 train_loss 1.4623905144355915 train_accuracy 99.87592592592593\n",
            "epoch 376 train_loss 1.4624970359934701 train_accuracy 99.86666666666666\n",
            "epoch 377 train_loss 1.4623689798293291 train_accuracy 99.87777777777778\n",
            "epoch 378 train_loss 1.4623541838592953 train_accuracy 99.87962962962963\n",
            "epoch 379 train_loss 1.4627712982672232 train_accuracy 99.83888888888889\n",
            "epoch 380 train_loss 1.462566026824492 train_accuracy 99.85925925925926\n",
            "epoch 381 train_loss 1.4627227713664372 train_accuracy 99.8425925925926\n",
            "epoch 382 train_loss 1.4624144139113249 train_accuracy 99.87407407407407\n",
            "epoch 383 train_loss 1.4624225387970606 train_accuracy 99.87222222222222\n",
            "epoch 384 train_loss 1.462624858595707 train_accuracy 99.85\n",
            "epoch 385 train_loss 1.4625486535054666 train_accuracy 99.86111111111111\n",
            "epoch 386 train_loss 1.462428973118464 train_accuracy 99.87407407407407\n",
            "epoch 387 train_loss 1.4623977067293945 train_accuracy 99.87407407407407\n",
            "epoch 388 train_loss 1.4624055164831655 train_accuracy 99.87407407407407\n",
            "epoch 389 train_loss 1.46266129149331 train_accuracy 99.84814814814816\n",
            "epoch 390 train_loss 1.4625128784665355 train_accuracy 99.86481481481482\n",
            "epoch 391 train_loss 1.4623620645867454 train_accuracy 99.87777777777778\n",
            "epoch 392 train_loss 1.462415107201647 train_accuracy 99.87592592592593\n",
            "epoch 393 train_loss 1.4625303169091544 train_accuracy 99.86111111111111\n",
            "epoch 394 train_loss 1.4625191630036742 train_accuracy 99.86296296296297\n",
            "epoch 395 train_loss 1.462627069817649 train_accuracy 99.85\n",
            "epoch 396 train_loss 1.4625736819373236 train_accuracy 99.85925925925926\n",
            "epoch 397 train_loss 1.4624537201943222 train_accuracy 99.87222222222222\n",
            "epoch 398 train_loss 1.4625421126683553 train_accuracy 99.85925925925926\n",
            "epoch 399 train_loss 1.4624120149347517 train_accuracy 99.87407407407407\n",
            "epoch 399 validation_loss 1.4717729032039641 validation_accuracy 98.93333333333334\n",
            "epoch 400 train_loss 1.462439306025152 train_accuracy 99.87222222222222\n",
            "epoch 401 train_loss 1.462407915128602 train_accuracy 99.87592592592593\n",
            "epoch 402 train_loss 1.4624757300924371 train_accuracy 99.86666666666666\n",
            "epoch 403 train_loss 1.462330084045728 train_accuracy 99.88333333333334\n",
            "epoch 404 train_loss 1.462747758626938 train_accuracy 99.84074074074074\n",
            "epoch 405 train_loss 1.462500595273795 train_accuracy 99.86666666666666\n",
            "epoch 406 train_loss 1.4625990693215971 train_accuracy 99.85185185185185\n",
            "epoch 407 train_loss 1.4625076842528801 train_accuracy 99.86111111111111\n",
            "epoch 408 train_loss 1.4625581402469565 train_accuracy 99.86111111111111\n",
            "epoch 409 train_loss 1.4623015978822003 train_accuracy 99.88518518518518\n",
            "epoch 410 train_loss 1.4623200254307853 train_accuracy 99.88333333333334\n",
            "epoch 411 train_loss 1.462813236205666 train_accuracy 99.83518518518518\n",
            "epoch 412 train_loss 1.4624025756562198 train_accuracy 99.87592592592593\n",
            "epoch 413 train_loss 1.4623416664423765 train_accuracy 99.88148148148149\n",
            "epoch 414 train_loss 1.462447773747974 train_accuracy 99.86851851851851\n",
            "epoch 415 train_loss 1.46258012884193 train_accuracy 99.86111111111111\n",
            "epoch 416 train_loss 1.4624296623247641 train_accuracy 99.87407407407407\n",
            "epoch 417 train_loss 1.4622639705737432 train_accuracy 99.88888888888889\n",
            "epoch 418 train_loss 1.4623858864660617 train_accuracy 99.87592592592593\n",
            "epoch 419 train_loss 1.4624464142101783 train_accuracy 99.87222222222222\n",
            "epoch 420 train_loss 1.4624568785782213 train_accuracy 99.87037037037037\n",
            "epoch 421 train_loss 1.4625388347440296 train_accuracy 99.86111111111111\n",
            "epoch 422 train_loss 1.462461042073038 train_accuracy 99.87037037037037\n",
            "epoch 423 train_loss 1.462482143441836 train_accuracy 99.86481481481482\n",
            "epoch 424 train_loss 1.4623655916364104 train_accuracy 99.87962962962963\n",
            "epoch 425 train_loss 1.4624228682782916 train_accuracy 99.87222222222222\n",
            "epoch 426 train_loss 1.4624002440108193 train_accuracy 99.87407407407407\n",
            "epoch 427 train_loss 1.4623276576951698 train_accuracy 99.88333333333334\n",
            "epoch 428 train_loss 1.4626282774739796 train_accuracy 99.85185185185185\n",
            "epoch 429 train_loss 1.4624788253395646 train_accuracy 99.86481481481482\n",
            "epoch 430 train_loss 1.4626207931174173 train_accuracy 99.8537037037037\n",
            "epoch 431 train_loss 1.462381922867563 train_accuracy 99.87777777777778\n",
            "epoch 432 train_loss 1.4625549729223604 train_accuracy 99.85925925925926\n",
            "epoch 433 train_loss 1.462315027360563 train_accuracy 99.88333333333334\n",
            "epoch 434 train_loss 1.4625811713713186 train_accuracy 99.85925925925926\n",
            "epoch 435 train_loss 1.4623752345641454 train_accuracy 99.87777777777778\n",
            "epoch 436 train_loss 1.462337596659307 train_accuracy 99.88148148148149\n",
            "epoch 437 train_loss 1.4623276613376759 train_accuracy 99.88333333333334\n",
            "epoch 438 train_loss 1.4624745572054827 train_accuracy 99.86851851851851\n",
            "epoch 439 train_loss 1.462467246695801 train_accuracy 99.86851851851851\n",
            "epoch 440 train_loss 1.4625080936484867 train_accuracy 99.86481481481482\n",
            "epoch 441 train_loss 1.4624176656758343 train_accuracy 99.87407407407407\n",
            "epoch 442 train_loss 1.4624768186498571 train_accuracy 99.86666666666666\n",
            "epoch 443 train_loss 1.4624488019280963 train_accuracy 99.87222222222222\n",
            "epoch 444 train_loss 1.4624670345474173 train_accuracy 99.86851851851851\n",
            "epoch 445 train_loss 1.462449918742533 train_accuracy 99.87037037037037\n",
            "epoch 446 train_loss 1.4625464570743065 train_accuracy 99.86111111111111\n",
            "epoch 447 train_loss 1.4623821467161178 train_accuracy 99.87777777777778\n",
            "epoch 448 train_loss 1.4623843787996857 train_accuracy 99.87592592592593\n",
            "epoch 449 train_loss 1.4626372700488126 train_accuracy 99.85185185185185\n",
            "epoch 450 train_loss 1.4626305530468622 train_accuracy 99.85\n",
            "epoch 451 train_loss 1.4624464157554837 train_accuracy 99.87037037037037\n",
            "epoch 452 train_loss 1.462558599423479 train_accuracy 99.86296296296297\n",
            "epoch 453 train_loss 1.4624704875327923 train_accuracy 99.86666666666666\n",
            "epoch 454 train_loss 1.4625249682753174 train_accuracy 99.86111111111111\n",
            "epoch 455 train_loss 1.4623448881838057 train_accuracy 99.87962962962963\n",
            "epoch 456 train_loss 1.462281275347427 train_accuracy 99.88703703703703\n",
            "epoch 457 train_loss 1.4622620663157215 train_accuracy 99.88888888888889\n",
            "epoch 458 train_loss 1.4625426831068815 train_accuracy 99.86111111111111\n",
            "epoch 459 train_loss 1.4623188774894784 train_accuracy 99.88333333333334\n",
            "epoch 460 train_loss 1.4622808092170292 train_accuracy 99.88703703703703\n",
            "epoch 461 train_loss 1.4623123164530154 train_accuracy 99.88333333333334\n",
            "epoch 462 train_loss 1.4625861965947682 train_accuracy 99.85740740740741\n",
            "epoch 463 train_loss 1.462472676789319 train_accuracy 99.86851851851851\n",
            "epoch 464 train_loss 1.4623601333962546 train_accuracy 99.87777777777778\n",
            "epoch 465 train_loss 1.4624482329244968 train_accuracy 99.86851851851851\n",
            "epoch 466 train_loss 1.462264206232848 train_accuracy 99.88888888888889\n",
            "epoch 467 train_loss 1.4623783763911988 train_accuracy 99.87592592592593\n",
            "epoch 468 train_loss 1.462384541939806 train_accuracy 99.87592592592593\n",
            "epoch 469 train_loss 1.462732281949785 train_accuracy 99.84444444444445\n",
            "epoch 470 train_loss 1.4623648722966511 train_accuracy 99.87962962962963\n",
            "epoch 471 train_loss 1.462391396694713 train_accuracy 99.87592592592593\n",
            "epoch 472 train_loss 1.4623465281945687 train_accuracy 99.88148148148149\n",
            "epoch 473 train_loss 1.4624754593328193 train_accuracy 99.86666666666666\n",
            "epoch 474 train_loss 1.4623377593579117 train_accuracy 99.87962962962963\n",
            "epoch 475 train_loss 1.4622642137386181 train_accuracy 99.88888888888889\n",
            "epoch 476 train_loss 1.4625002442686645 train_accuracy 99.86666666666666\n",
            "epoch 477 train_loss 1.4624906300394624 train_accuracy 99.86851851851851\n",
            "epoch 478 train_loss 1.4624217315956398 train_accuracy 99.87407407407407\n",
            "epoch 479 train_loss 1.4622619006368849 train_accuracy 99.88888888888889\n",
            "epoch 480 train_loss 1.4623403552505705 train_accuracy 99.88148148148149\n",
            "epoch 481 train_loss 1.4623548526454855 train_accuracy 99.87962962962963\n",
            "epoch 482 train_loss 1.4626547746084355 train_accuracy 99.84814814814816\n",
            "epoch 483 train_loss 1.4625939458608628 train_accuracy 99.85555555555555\n",
            "epoch 484 train_loss 1.4622906172717058 train_accuracy 99.88703703703703\n",
            "epoch 485 train_loss 1.4622809677212327 train_accuracy 99.88703703703703\n",
            "epoch 486 train_loss 1.4622750984297859 train_accuracy 99.88703703703703\n",
            "epoch 487 train_loss 1.4623918573061625 train_accuracy 99.87592592592593\n",
            "epoch 488 train_loss 1.462512883654347 train_accuracy 99.86296296296297\n",
            "epoch 489 train_loss 1.4623202897884227 train_accuracy 99.88333333333334\n",
            "epoch 490 train_loss 1.4622814701663123 train_accuracy 99.88703703703703\n",
            "epoch 491 train_loss 1.4622985787965632 train_accuracy 99.88518518518518\n",
            "epoch 492 train_loss 1.462340565080996 train_accuracy 99.88148148148149\n",
            "epoch 493 train_loss 1.4628553882793145 train_accuracy 99.82962962962964\n",
            "epoch 494 train_loss 1.4626347283522287 train_accuracy 99.84814814814816\n",
            "epoch 495 train_loss 1.4625009755293528 train_accuracy 99.86481481481482\n",
            "epoch 496 train_loss 1.4624116469312598 train_accuracy 99.87407407407407\n",
            "epoch 497 train_loss 1.46228780525702 train_accuracy 99.88518518518518\n",
            "epoch 498 train_loss 1.46254970950109 train_accuracy 99.85925925925926\n",
            "epoch 499 train_loss 1.462402386466662 train_accuracy 99.87407407407407\n",
            "epoch 499 validation_loss 1.4728678345680237 validation_accuracy 98.83333333333333\n",
            "epoch 500 train_loss 1.4623008183859012 train_accuracy 99.88518518518518\n",
            "epoch 501 train_loss 1.4626546763711505 train_accuracy 99.85\n",
            "epoch 502 train_loss 1.4624128501724314 train_accuracy 99.87222222222222\n",
            "epoch 503 train_loss 1.4623924260890042 train_accuracy 99.87777777777778\n",
            "epoch 504 train_loss 1.4624590479665331 train_accuracy 99.86851851851851\n",
            "epoch 505 train_loss 1.4623908229448177 train_accuracy 99.87407407407407\n",
            "epoch 506 train_loss 1.4623797670558647 train_accuracy 99.87592592592593\n",
            "epoch 507 train_loss 1.4623557527860005 train_accuracy 99.88148148148149\n",
            "epoch 508 train_loss 1.4622842929981372 train_accuracy 99.88703703703703\n",
            "epoch 509 train_loss 1.4625012111884577 train_accuracy 99.86481481481482\n",
            "epoch 510 train_loss 1.4624201136606712 train_accuracy 99.87407407407407\n",
            "epoch 511 train_loss 1.4624458977469692 train_accuracy 99.87037037037037\n",
            "epoch 512 train_loss 1.4624601034102616 train_accuracy 99.86851851851851\n",
            "epoch 513 train_loss 1.462456927586485 train_accuracy 99.87037037037037\n",
            "epoch 514 train_loss 1.4625268324657723 train_accuracy 99.86296296296297\n",
            "epoch 515 train_loss 1.462412158648173 train_accuracy 99.87407407407407\n",
            "epoch 516 train_loss 1.4623498755472677 train_accuracy 99.87962962962963\n",
            "epoch 517 train_loss 1.4624505915023662 train_accuracy 99.87037037037037\n",
            "epoch 518 train_loss 1.4623649032027632 train_accuracy 99.87962962962963\n",
            "epoch 519 train_loss 1.4624027327254967 train_accuracy 99.87592592592593\n",
            "epoch 520 train_loss 1.4623887691232893 train_accuracy 99.87407407407407\n",
            "epoch 521 train_loss 1.462579862276713 train_accuracy 99.85925925925926\n",
            "epoch 522 train_loss 1.462334664773058 train_accuracy 99.88148148148149\n",
            "epoch 523 train_loss 1.4623614640147597 train_accuracy 99.87962962962963\n",
            "epoch 524 train_loss 1.4624517033497493 train_accuracy 99.87037037037037\n",
            "epoch 525 train_loss 1.4623987176903972 train_accuracy 99.87592592592593\n",
            "epoch 526 train_loss 1.4625109323748835 train_accuracy 99.86296296296297\n",
            "epoch 527 train_loss 1.4623809175358877 train_accuracy 99.87592592592593\n",
            "epoch 528 train_loss 1.462539611811991 train_accuracy 99.86111111111111\n",
            "epoch 529 train_loss 1.4623420344458686 train_accuracy 99.88148148148149\n",
            "epoch 530 train_loss 1.462604566856667 train_accuracy 99.85740740740741\n",
            "epoch 531 train_loss 1.4625329427145146 train_accuracy 99.86296296296297\n",
            "epoch 532 train_loss 1.4624964942534764 train_accuracy 99.86296296296297\n",
            "epoch 533 train_loss 1.4625305827017183 train_accuracy 99.86296296296297\n",
            "epoch 534 train_loss 1.462280324763722 train_accuracy 99.88703703703703\n",
            "epoch 535 train_loss 1.4623020081608384 train_accuracy 99.88518518518518\n",
            "epoch 536 train_loss 1.462324427013044 train_accuracy 99.88333333333334\n",
            "epoch 537 train_loss 1.4623497895620488 train_accuracy 99.88148148148149\n",
            "epoch 538 train_loss 1.4625047465165457 train_accuracy 99.86296296296297\n",
            "epoch 539 train_loss 1.462293615937233 train_accuracy 99.88518518518518\n",
            "epoch 540 train_loss 1.4624107050674933 train_accuracy 99.87407407407407\n",
            "epoch 541 train_loss 1.4624769909514321 train_accuracy 99.86666666666666\n",
            "epoch 542 train_loss 1.462533246477445 train_accuracy 99.85925925925926\n",
            "epoch 543 train_loss 1.4624315558760255 train_accuracy 99.87037037037037\n",
            "epoch 544 train_loss 1.4624632248172054 train_accuracy 99.86851851851851\n",
            "epoch 545 train_loss 1.4623663993897262 train_accuracy 99.88148148148149\n",
            "epoch 546 train_loss 1.4623798901284182 train_accuracy 99.87962962962963\n",
            "epoch 547 train_loss 1.4624005133355105 train_accuracy 99.87407407407407\n",
            "epoch 548 train_loss 1.4624695171912512 train_accuracy 99.86666666666666\n",
            "epoch 549 train_loss 1.4623909715149137 train_accuracy 99.87407407407407\n",
            "epoch 550 train_loss 1.4623949471447202 train_accuracy 99.87592592592593\n",
            "epoch 551 train_loss 1.4625525937036232 train_accuracy 99.85740740740741\n",
            "epoch 552 train_loss 1.462336974453043 train_accuracy 99.88148148148149\n",
            "epoch 553 train_loss 1.4623619891979076 train_accuracy 99.87962962962963\n",
            "epoch 554 train_loss 1.4623422086238862 train_accuracy 99.88148148148149\n",
            "epoch 555 train_loss 1.4622433263946462 train_accuracy 99.89074074074074\n",
            "epoch 556 train_loss 1.462375901915409 train_accuracy 99.87777777777778\n",
            "epoch 557 train_loss 1.462662258302724 train_accuracy 99.84814814814816\n",
            "epoch 558 train_loss 1.4624280524474602 train_accuracy 99.87037037037037\n",
            "epoch 559 train_loss 1.4624754485156801 train_accuracy 99.86851851851851\n",
            "epoch 560 train_loss 1.4623749014404086 train_accuracy 99.87777777777778\n",
            "epoch 561 train_loss 1.462335956979681 train_accuracy 99.88333333333334\n",
            "epoch 562 train_loss 1.4623145397062656 train_accuracy 99.88333333333334\n",
            "epoch 563 train_loss 1.4622634767382234 train_accuracy 99.88888888888889\n",
            "epoch 564 train_loss 1.462343622688894 train_accuracy 99.87962962962963\n",
            "epoch 565 train_loss 1.4623861458566454 train_accuracy 99.87407407407407\n",
            "epoch 566 train_loss 1.462393366297086 train_accuracy 99.87592592592593\n",
            "epoch 567 train_loss 1.4622971802949905 train_accuracy 99.88518518518518\n",
            "epoch 568 train_loss 1.4623145875003603 train_accuracy 99.88333333333334\n",
            "epoch 569 train_loss 1.4623477462265226 train_accuracy 99.87962962962963\n",
            "epoch 570 train_loss 1.4625760676684203 train_accuracy 99.85925925925926\n",
            "epoch 571 train_loss 1.4623293043286711 train_accuracy 99.88148148148149\n",
            "epoch 572 train_loss 1.4624384426408343 train_accuracy 99.87037037037037\n",
            "epoch 573 train_loss 1.4622828556431664 train_accuracy 99.88703703703703\n",
            "epoch 574 train_loss 1.4622662581779338 train_accuracy 99.88888888888889\n",
            "epoch 575 train_loss 1.4622437866749587 train_accuracy 99.89074074074074\n",
            "epoch 576 train_loss 1.4622235464828985 train_accuracy 99.89259259259259\n",
            "epoch 577 train_loss 1.4626062645956321 train_accuracy 99.85555555555555\n",
            "epoch 578 train_loss 1.462394357610632 train_accuracy 99.87592592592593\n",
            "epoch 579 train_loss 1.462359122104115 train_accuracy 99.87962962962963\n",
            "epoch 580 train_loss 1.4623430760922256 train_accuracy 99.88148148148149\n",
            "epoch 581 train_loss 1.4624614777388396 train_accuracy 99.86851851851851\n",
            "epoch 582 train_loss 1.462530682042793 train_accuracy 99.85925925925926\n",
            "epoch 583 train_loss 1.462377789285448 train_accuracy 99.87777777777778\n",
            "epoch 584 train_loss 1.4623120047427989 train_accuracy 99.88518518518518\n",
            "epoch 585 train_loss 1.4622441459585118 train_accuracy 99.89074074074074\n",
            "epoch 586 train_loss 1.4622856203052732 train_accuracy 99.88703703703703\n",
            "epoch 587 train_loss 1.4624828231555445 train_accuracy 99.86481481481482\n",
            "epoch 588 train_loss 1.462277415174025 train_accuracy 99.88703703703703\n",
            "epoch 589 train_loss 1.4622602232076503 train_accuracy 99.88888888888889\n",
            "epoch 590 train_loss 1.4625455875087667 train_accuracy 99.85925925925926\n",
            "epoch 591 train_loss 1.4623018734984927 train_accuracy 99.88518518518518\n",
            "epoch 592 train_loss 1.462370064081969 train_accuracy 99.87777777777778\n",
            "epoch 593 train_loss 1.4623596327172386 train_accuracy 99.87777777777778\n",
            "epoch 594 train_loss 1.4622247529250605 train_accuracy 99.89259259259259\n",
            "epoch 595 train_loss 1.4625002645783953 train_accuracy 99.86481481481482\n",
            "epoch 596 train_loss 1.4623304594446112 train_accuracy 99.88148148148149\n",
            "epoch 597 train_loss 1.4622627525417893 train_accuracy 99.88888888888889\n",
            "epoch 598 train_loss 1.462225028320595 train_accuracy 99.89259259259259\n",
            "epoch 599 train_loss 1.4622806861444755 train_accuracy 99.88703703703703\n",
            "epoch 599 validation_loss 1.4721993774175643 validation_accuracy 98.88333333333334\n",
            "epoch 600 train_loss 1.4626595858070586 train_accuracy 99.84814814814816\n",
            "epoch 601 train_loss 1.4625213438713993 train_accuracy 99.86296296296297\n",
            "epoch 602 train_loss 1.4623471075737917 train_accuracy 99.88148148148149\n",
            "epoch 603 train_loss 1.4622650075841832 train_accuracy 99.88888888888889\n",
            "epoch 604 train_loss 1.4622600493607698 train_accuracy 99.88888888888889\n",
            "epoch 605 train_loss 1.462635495044567 train_accuracy 99.85\n",
            "epoch 606 train_loss 1.4623781288111652 train_accuracy 99.87777777777778\n",
            "epoch 607 train_loss 1.462533018986384 train_accuracy 99.86296296296297\n",
            "epoch 608 train_loss 1.46247151405723 train_accuracy 99.86666666666666\n",
            "epoch 609 train_loss 1.4623318140153532 train_accuracy 99.88148148148149\n",
            "epoch 610 train_loss 1.4623371019407554 train_accuracy 99.88148148148149\n",
            "epoch 611 train_loss 1.462497125952332 train_accuracy 99.86481481481482\n",
            "epoch 612 train_loss 1.4623108038195858 train_accuracy 99.88703703703703\n",
            "epoch 613 train_loss 1.4624025216809025 train_accuracy 99.87407407407407\n",
            "epoch 614 train_loss 1.4623316837681664 train_accuracy 99.88333333333334\n",
            "epoch 615 train_loss 1.4623305082321167 train_accuracy 99.88148148148149\n",
            "epoch 616 train_loss 1.4625045120716096 train_accuracy 99.86481481481482\n",
            "epoch 617 train_loss 1.4623520067444553 train_accuracy 99.87962962962963\n",
            "epoch 618 train_loss 1.4622879560346957 train_accuracy 99.88703703703703\n",
            "epoch 619 train_loss 1.4623387451525087 train_accuracy 99.87962962962963\n",
            "epoch 620 train_loss 1.4622914017350586 train_accuracy 99.88518518518518\n",
            "epoch 621 train_loss 1.462395801809099 train_accuracy 99.87407407407407\n",
            "epoch 622 train_loss 1.4624836497836642 train_accuracy 99.86851851851851\n",
            "epoch 623 train_loss 1.462365092613079 train_accuracy 99.87962962962963\n",
            "epoch 624 train_loss 1.4622420479853948 train_accuracy 99.89074074074074\n",
            "epoch 625 train_loss 1.4622611734602187 train_accuracy 99.88888888888889\n",
            "epoch 626 train_loss 1.462260581056277 train_accuracy 99.88888888888889\n",
            "epoch 627 train_loss 1.4624561410259318 train_accuracy 99.86851851851851\n",
            "epoch 628 train_loss 1.46245460179117 train_accuracy 99.86851851851851\n",
            "epoch 629 train_loss 1.4624903483523264 train_accuracy 99.86481481481482\n",
            "epoch 630 train_loss 1.46233807084737 train_accuracy 99.88148148148149\n",
            "epoch 631 train_loss 1.4624109673279304 train_accuracy 99.87222222222222\n",
            "epoch 632 train_loss 1.4623580950277824 train_accuracy 99.88148148148149\n",
            "epoch 633 train_loss 1.4623228043317795 train_accuracy 99.88333333333334\n",
            "epoch 634 train_loss 1.4623046515164553 train_accuracy 99.88518518518518\n",
            "epoch 635 train_loss 1.4622622021922358 train_accuracy 99.88888888888889\n",
            "epoch 636 train_loss 1.4622249235709508 train_accuracy 99.89259259259259\n",
            "epoch 637 train_loss 1.4624655718052828 train_accuracy 99.86851851851851\n",
            "epoch 638 train_loss 1.4623474610072595 train_accuracy 99.88148148148149\n",
            "epoch 639 train_loss 1.462534475436917 train_accuracy 99.86111111111111\n",
            "epoch 640 train_loss 1.4624036463322463 train_accuracy 99.87407407407407\n",
            "epoch 641 train_loss 1.462392422888014 train_accuracy 99.87592592592593\n",
            "epoch 642 train_loss 1.4622709261046516 train_accuracy 99.88888888888889\n",
            "epoch 643 train_loss 1.462485377435331 train_accuracy 99.86481481481482\n",
            "epoch 644 train_loss 1.4623420582877265 train_accuracy 99.87962962962963\n",
            "epoch 645 train_loss 1.462348367218618 train_accuracy 99.87962962962963\n",
            "epoch 646 train_loss 1.4623874896102482 train_accuracy 99.87777777777778\n",
            "epoch 647 train_loss 1.4622988646781003 train_accuracy 99.88518518518518\n",
            "epoch 648 train_loss 1.4623143292135663 train_accuracy 99.88148148148149\n",
            "epoch 649 train_loss 1.4624154803929506 train_accuracy 99.87222222222222\n",
            "epoch 650 train_loss 1.4623369285353909 train_accuracy 99.88148148148149\n",
            "epoch 651 train_loss 1.4622951293433155 train_accuracy 99.88518518518518\n",
            "epoch 652 train_loss 1.4622583232544086 train_accuracy 99.88888888888889\n",
            "epoch 653 train_loss 1.462450408714789 train_accuracy 99.87037037037037\n",
            "epoch 654 train_loss 1.4623797783145198 train_accuracy 99.87777777777778\n",
            "epoch 655 train_loss 1.4622629113771297 train_accuracy 99.88888888888889\n",
            "epoch 656 train_loss 1.4624496035001897 train_accuracy 99.87222222222222\n",
            "epoch 657 train_loss 1.462429384500892 train_accuracy 99.87222222222222\n",
            "epoch 658 train_loss 1.4622795827962733 train_accuracy 99.88703703703703\n",
            "epoch 659 train_loss 1.4623501311849665 train_accuracy 99.87962962962963\n",
            "epoch 660 train_loss 1.462445095843739 train_accuracy 99.87037037037037\n",
            "epoch 661 train_loss 1.4623753015641814 train_accuracy 99.87777777777778\n",
            "epoch 662 train_loss 1.4623739788929622 train_accuracy 99.87777777777778\n",
            "epoch 663 train_loss 1.4624174294648347 train_accuracy 99.87407407407407\n",
            "epoch 664 train_loss 1.4622611631949742 train_accuracy 99.88888888888889\n",
            "epoch 665 train_loss 1.4624227307460926 train_accuracy 99.87222222222222\n",
            "epoch 666 train_loss 1.4623791106321193 train_accuracy 99.87777777777778\n",
            "epoch 667 train_loss 1.462448243631257 train_accuracy 99.87222222222222\n",
            "epoch 668 train_loss 1.4624544777252055 train_accuracy 99.86666666666666\n",
            "epoch 669 train_loss 1.4624092702512388 train_accuracy 99.87407407407407\n",
            "epoch 670 train_loss 1.4623340368270874 train_accuracy 99.88148148148149\n",
            "epoch 671 train_loss 1.4625079755429868 train_accuracy 99.86296296296297\n",
            "epoch 672 train_loss 1.4622887154420217 train_accuracy 99.88703703703703\n",
            "epoch 673 train_loss 1.4623126874367396 train_accuracy 99.88333333333334\n",
            "epoch 674 train_loss 1.4623153901762433 train_accuracy 99.88333333333334\n",
            "epoch 675 train_loss 1.4626109069144284 train_accuracy 99.85555555555555\n",
            "epoch 676 train_loss 1.4623526619540321 train_accuracy 99.87962962962963\n",
            "epoch 677 train_loss 1.462304490915051 train_accuracy 99.88518518518518\n",
            "epoch 678 train_loss 1.4622611936595704 train_accuracy 99.88888888888889\n",
            "epoch 679 train_loss 1.4622801268542254 train_accuracy 99.88703703703703\n",
            "epoch 680 train_loss 1.4623829989521593 train_accuracy 99.87777777777778\n",
            "epoch 681 train_loss 1.4624527778890397 train_accuracy 99.87037037037037\n",
            "epoch 682 train_loss 1.4623224957121743 train_accuracy 99.88333333333334\n",
            "epoch 683 train_loss 1.4622838454114067 train_accuracy 99.88703703703703\n",
            "epoch 684 train_loss 1.4623270317360206 train_accuracy 99.88333333333334\n",
            "epoch 685 train_loss 1.4623934127666331 train_accuracy 99.87407407407407\n",
            "epoch 686 train_loss 1.462258552732291 train_accuracy 99.88888888888889\n",
            "epoch 687 train_loss 1.4623292161358727 train_accuracy 99.88333333333334\n",
            "epoch 688 train_loss 1.4623336996193286 train_accuracy 99.88333333333334\n",
            "epoch 689 train_loss 1.462434126160763 train_accuracy 99.87222222222222\n",
            "epoch 690 train_loss 1.462266543617955 train_accuracy 99.88888888888889\n",
            "epoch 691 train_loss 1.4623054944806628 train_accuracy 99.88333333333334\n",
            "epoch 692 train_loss 1.4623130928587031 train_accuracy 99.88333333333334\n",
            "epoch 693 train_loss 1.4623405554780253 train_accuracy 99.88148148148149\n",
            "epoch 694 train_loss 1.46236984497971 train_accuracy 99.87962962962963\n",
            "epoch 695 train_loss 1.4624598372865607 train_accuracy 99.86851851851851\n",
            "epoch 696 train_loss 1.4623695702464492 train_accuracy 99.87777777777778\n",
            "epoch 697 train_loss 1.462223939652796 train_accuracy 99.89259259259259\n",
            "epoch 698 train_loss 1.4622259573804008 train_accuracy 99.89259259259259\n",
            "epoch 699 train_loss 1.462213694276633 train_accuracy 99.89259259259259\n",
            "epoch 699 validation_loss 1.4722588688135148 validation_accuracy 98.86666666666666\n",
            "epoch 700 train_loss 1.4623342599029894 train_accuracy 99.88148148148149\n",
            "epoch 701 train_loss 1.4622062223928947 train_accuracy 99.89444444444445\n",
            "epoch 702 train_loss 1.4622243227782072 train_accuracy 99.89259259259259\n",
            "epoch 703 train_loss 1.4624441655697646 train_accuracy 99.87037037037037\n",
            "epoch 704 train_loss 1.4624147651372132 train_accuracy 99.87222222222222\n",
            "epoch 705 train_loss 1.4623362449584183 train_accuracy 99.88333333333334\n",
            "epoch 706 train_loss 1.4623479023023889 train_accuracy 99.88148148148149\n",
            "epoch 707 train_loss 1.4624024055622242 train_accuracy 99.87407407407407\n",
            "epoch 708 train_loss 1.4622948124452873 train_accuracy 99.88518518518518\n",
            "epoch 709 train_loss 1.4623753759596083 train_accuracy 99.87777777777778\n",
            "epoch 710 train_loss 1.4622044728861914 train_accuracy 99.89444444444445\n",
            "epoch 711 train_loss 1.462223234883061 train_accuracy 99.89259259259259\n",
            "epoch 712 train_loss 1.4623355608295512 train_accuracy 99.88148148148149\n",
            "epoch 713 train_loss 1.4624573364301965 train_accuracy 99.86851851851851\n",
            "epoch 714 train_loss 1.4623223659065034 train_accuracy 99.88333333333334\n",
            "epoch 715 train_loss 1.462249462582447 train_accuracy 99.89074074074074\n",
            "epoch 716 train_loss 1.4622979167434904 train_accuracy 99.88518518518518\n",
            "epoch 717 train_loss 1.4624344769451354 train_accuracy 99.87037037037037\n",
            "epoch 718 train_loss 1.462309562276911 train_accuracy 99.88518518518518\n",
            "epoch 719 train_loss 1.4622658791365446 train_accuracy 99.88888888888889\n",
            "epoch 720 train_loss 1.462241224668644 train_accuracy 99.89074074074074\n",
            "epoch 721 train_loss 1.4621881386748066 train_accuracy 99.8962962962963\n",
            "epoch 722 train_loss 1.4624861709497594 train_accuracy 99.86666666666666\n",
            "epoch 723 train_loss 1.4622970787463365 train_accuracy 99.88518518518518\n",
            "epoch 724 train_loss 1.4622840695910984 train_accuracy 99.88703703703703\n",
            "epoch 725 train_loss 1.4622980294404206 train_accuracy 99.88518518518518\n",
            "epoch 726 train_loss 1.4622302662443232 train_accuracy 99.89259259259259\n",
            "epoch 727 train_loss 1.4623618337843154 train_accuracy 99.87777777777778\n",
            "epoch 728 train_loss 1.4623323610535375 train_accuracy 99.88148148148149\n",
            "epoch 729 train_loss 1.4622514441057488 train_accuracy 99.89074074074074\n",
            "epoch 730 train_loss 1.4621689875920614 train_accuracy 99.89814814814815\n",
            "epoch 731 train_loss 1.4621692621045643 train_accuracy 99.89814814814815\n",
            "epoch 732 train_loss 1.4623733988514653 train_accuracy 99.87962962962963\n",
            "epoch 733 train_loss 1.4624208208587435 train_accuracy 99.87222222222222\n",
            "epoch 734 train_loss 1.4622713602251476 train_accuracy 99.88703703703703\n",
            "epoch 735 train_loss 1.4622259210657191 train_accuracy 99.89259259259259\n",
            "epoch 736 train_loss 1.462170292713024 train_accuracy 99.89814814814815\n",
            "epoch 737 train_loss 1.462205833086261 train_accuracy 99.89444444444445\n",
            "epoch 738 train_loss 1.4623073363745653 train_accuracy 99.88518518518518\n",
            "epoch 739 train_loss 1.4623584660115065 train_accuracy 99.87962962962963\n",
            "epoch 740 train_loss 1.462227627524623 train_accuracy 99.89259259259259\n",
            "epoch 741 train_loss 1.4622200455930499 train_accuracy 99.89259259259259\n",
            "epoch 742 train_loss 1.4622104911892502 train_accuracy 99.89444444444445\n",
            "epoch 743 train_loss 1.4621693055938791 train_accuracy 99.89814814814815\n",
            "epoch 744 train_loss 1.4624276261638711 train_accuracy 99.87037037037037\n",
            "epoch 745 train_loss 1.4622534719882188 train_accuracy 99.89074074074074\n",
            "epoch 746 train_loss 1.4622354202800327 train_accuracy 99.89074074074074\n",
            "epoch 747 train_loss 1.462268074243157 train_accuracy 99.89074074074074\n",
            "epoch 748 train_loss 1.4623872511916691 train_accuracy 99.87592592592593\n",
            "epoch 749 train_loss 1.4624178483530328 train_accuracy 99.87407407407407\n",
            "epoch 750 train_loss 1.4622550868325763 train_accuracy 99.89074074074074\n",
            "epoch 751 train_loss 1.462206102962847 train_accuracy 99.89444444444445\n",
            "epoch 752 train_loss 1.46219556386824 train_accuracy 99.8962962962963\n",
            "epoch 753 train_loss 1.4623131618455605 train_accuracy 99.88333333333334\n",
            "epoch 754 train_loss 1.4624356440923831 train_accuracy 99.87222222222222\n",
            "epoch 755 train_loss 1.4622987454688108 train_accuracy 99.88518518518518\n",
            "epoch 756 train_loss 1.4623220403989157 train_accuracy 99.88333333333334\n",
            "epoch 757 train_loss 1.4622879742472261 train_accuracy 99.88518518518518\n",
            "epoch 758 train_loss 1.462440907403275 train_accuracy 99.87037037037037\n",
            "epoch 759 train_loss 1.462205821937985 train_accuracy 99.89444444444445\n",
            "epoch 760 train_loss 1.4621702355367165 train_accuracy 99.89814814814815\n",
            "epoch 761 train_loss 1.462262581564762 train_accuracy 99.89074074074074\n",
            "epoch 762 train_loss 1.462270731837661 train_accuracy 99.88888888888889\n",
            "epoch 763 train_loss 1.46234778408651 train_accuracy 99.87962962962963\n",
            "epoch 764 train_loss 1.4622622580439957 train_accuracy 99.88888888888889\n",
            "epoch 765 train_loss 1.4623042689429389 train_accuracy 99.88518518518518\n",
            "epoch 766 train_loss 1.4623251107003954 train_accuracy 99.88333333333334\n",
            "epoch 767 train_loss 1.4624368224982862 train_accuracy 99.87407407407407\n",
            "epoch 768 train_loss 1.4624070318760696 train_accuracy 99.87407407407407\n",
            "epoch 769 train_loss 1.4623197937453234 train_accuracy 99.88333333333334\n",
            "epoch 770 train_loss 1.4623044816432176 train_accuracy 99.88703703703703\n",
            "epoch 771 train_loss 1.4625050562399404 train_accuracy 99.86296296296297\n",
            "epoch 772 train_loss 1.4623588542143504 train_accuracy 99.87962962962963\n",
            "epoch 773 train_loss 1.462284845886407 train_accuracy 99.88703703703703\n",
            "epoch 774 train_loss 1.4622033798032337 train_accuracy 99.89444444444445\n",
            "epoch 775 train_loss 1.4622234085091839 train_accuracy 99.89259259259259\n",
            "epoch 776 train_loss 1.4623714643496055 train_accuracy 99.87777777777778\n",
            "epoch 777 train_loss 1.4622351341777378 train_accuracy 99.89259259259259\n",
            "epoch 778 train_loss 1.462400644796866 train_accuracy 99.87407407407407\n",
            "epoch 779 train_loss 1.4623521798186832 train_accuracy 99.87962962962963\n",
            "epoch 780 train_loss 1.4622817249209792 train_accuracy 99.88703703703703\n",
            "epoch 781 train_loss 1.4622601318138617 train_accuracy 99.88888888888889\n",
            "epoch 782 train_loss 1.4623951507939232 train_accuracy 99.87592592592593\n",
            "epoch 783 train_loss 1.4622523496548334 train_accuracy 99.89074074074074\n",
            "epoch 784 train_loss 1.462207884810589 train_accuracy 99.89444444444445\n",
            "epoch 785 train_loss 1.462223035759396 train_accuracy 99.89444444444445\n",
            "epoch 786 train_loss 1.4622225088101846 train_accuracy 99.89259259259259\n",
            "epoch 787 train_loss 1.4622303772855687 train_accuracy 99.89259259259259\n",
            "epoch 788 train_loss 1.4622809958678704 train_accuracy 99.88703703703703\n",
            "epoch 789 train_loss 1.4623231633945748 train_accuracy 99.88333333333334\n",
            "epoch 790 train_loss 1.4623836989755983 train_accuracy 99.87592592592593\n",
            "epoch 791 train_loss 1.4622797628243764 train_accuracy 99.88703703703703\n",
            "epoch 792 train_loss 1.4624230319703067 train_accuracy 99.87407407407407\n",
            "epoch 793 train_loss 1.4623095893197589 train_accuracy 99.88333333333334\n",
            "epoch 794 train_loss 1.4622834065446146 train_accuracy 99.88703703703703\n",
            "epoch 795 train_loss 1.4621696687406964 train_accuracy 99.89814814814815\n",
            "epoch 796 train_loss 1.4623900998521735 train_accuracy 99.87777777777778\n",
            "epoch 797 train_loss 1.4623499476247364 train_accuracy 99.88148148148149\n",
            "epoch 798 train_loss 1.4622589804508068 train_accuracy 99.88888888888889\n",
            "epoch 799 train_loss 1.4623287271570276 train_accuracy 99.88333333333334\n",
            "epoch 799 validation_loss 1.471903771162033 validation_accuracy 98.9\n",
            "epoch 800 train_loss 1.462332664485331 train_accuracy 99.88148148148149\n",
            "epoch 801 train_loss 1.4622683876090579 train_accuracy 99.88703703703703\n",
            "epoch 802 train_loss 1.46235936096421 train_accuracy 99.87962962962963\n",
            "epoch 803 train_loss 1.4623492105139626 train_accuracy 99.87962962962963\n",
            "epoch 804 train_loss 1.4622839783076886 train_accuracy 99.88703703703703\n",
            "epoch 805 train_loss 1.4623159600628748 train_accuracy 99.88148148148149\n",
            "epoch 806 train_loss 1.4624580213317164 train_accuracy 99.86851851851851\n",
            "epoch 807 train_loss 1.462294748094347 train_accuracy 99.88518518518518\n",
            "epoch 808 train_loss 1.4623723070930552 train_accuracy 99.87962962962963\n",
            "epoch 809 train_loss 1.4622852775785657 train_accuracy 99.88703703703703\n",
            "epoch 810 train_loss 1.4622435322514287 train_accuracy 99.89074074074074\n",
            "epoch 811 train_loss 1.4622588476649037 train_accuracy 99.88888888888889\n",
            "epoch 812 train_loss 1.462282955646515 train_accuracy 99.88703703703703\n",
            "epoch 813 train_loss 1.462183956857081 train_accuracy 99.8962962962963\n",
            "epoch 814 train_loss 1.46225026095355 train_accuracy 99.89074074074074\n",
            "epoch 815 train_loss 1.462223196029663 train_accuracy 99.89259259259259\n",
            "epoch 816 train_loss 1.4623943086023683 train_accuracy 99.87592592592593\n",
            "epoch 817 train_loss 1.4623444149891536 train_accuracy 99.88333333333334\n",
            "epoch 818 train_loss 1.4622547775506973 train_accuracy 99.89074074074074\n",
            "epoch 819 train_loss 1.4622679115445525 train_accuracy 99.88888888888889\n",
            "epoch 820 train_loss 1.4622073340195196 train_accuracy 99.89444444444445\n",
            "epoch 821 train_loss 1.4622128209582081 train_accuracy 99.89444444444445\n",
            "epoch 822 train_loss 1.4622298461419565 train_accuracy 99.89259259259259\n",
            "epoch 823 train_loss 1.4621690092263397 train_accuracy 99.89814814814815\n",
            "epoch 824 train_loss 1.4621869770465075 train_accuracy 99.8962962962963\n",
            "epoch 825 train_loss 1.4622062655510726 train_accuracy 99.89444444444445\n",
            "epoch 826 train_loss 1.4625790588281773 train_accuracy 99.85555555555555\n",
            "epoch 827 train_loss 1.46227743934702 train_accuracy 99.88703703703703\n",
            "epoch 828 train_loss 1.462327108339027 train_accuracy 99.88333333333334\n",
            "epoch 829 train_loss 1.4623024142450756 train_accuracy 99.88703703703703\n",
            "epoch 830 train_loss 1.4623901829675392 train_accuracy 99.87407407407407\n",
            "epoch 831 train_loss 1.4623794830507701 train_accuracy 99.87592592592593\n",
            "epoch 832 train_loss 1.4623501455342327 train_accuracy 99.87962962962963\n",
            "epoch 833 train_loss 1.4626616305775113 train_accuracy 99.85\n",
            "epoch 834 train_loss 1.4623451741757216 train_accuracy 99.88148148148149\n",
            "epoch 835 train_loss 1.4622315633076208 train_accuracy 99.89259259259259\n",
            "epoch 836 train_loss 1.4621858730360313 train_accuracy 99.8962962962963\n",
            "epoch 837 train_loss 1.4622163620260027 train_accuracy 99.89259259259259\n",
            "epoch 838 train_loss 1.4622730677878415 train_accuracy 99.88703703703703\n",
            "epoch 839 train_loss 1.4621684710184732 train_accuracy 99.89814814814815\n",
            "epoch 840 train_loss 1.4623599855988114 train_accuracy 99.87777777777778\n",
            "epoch 841 train_loss 1.4624596816522104 train_accuracy 99.86851851851851\n",
            "epoch 842 train_loss 1.4621892393739135 train_accuracy 99.8962962962963\n",
            "epoch 843 train_loss 1.462300960112501 train_accuracy 99.88518518518518\n",
            "epoch 844 train_loss 1.4622124952298623 train_accuracy 99.89259259259259\n",
            "epoch 845 train_loss 1.4621944395480333 train_accuracy 99.8962962962963\n",
            "epoch 846 train_loss 1.4622756762637033 train_accuracy 99.88703703703703\n",
            "epoch 847 train_loss 1.4624906946111609 train_accuracy 99.86481481481482\n",
            "epoch 848 train_loss 1.4621891199438661 train_accuracy 99.8962962962963\n",
            "epoch 849 train_loss 1.4622491085970843 train_accuracy 99.88888888888889\n",
            "epoch 850 train_loss 1.4623051816666568 train_accuracy 99.88518518518518\n",
            "epoch 851 train_loss 1.4621685885720783 train_accuracy 99.89814814814815\n",
            "epoch 852 train_loss 1.4622140072010181 train_accuracy 99.89444444444445\n",
            "epoch 853 train_loss 1.46218614478906 train_accuracy 99.8962962962963\n",
            "epoch 854 train_loss 1.462204894092348 train_accuracy 99.89444444444445\n",
            "epoch 855 train_loss 1.4622114368059016 train_accuracy 99.89444444444445\n",
            "epoch 856 train_loss 1.46234722049148 train_accuracy 99.88333333333334\n",
            "epoch 857 train_loss 1.4623084399435256 train_accuracy 99.88518518518518\n",
            "epoch 858 train_loss 1.462293397166111 train_accuracy 99.88333333333334\n",
            "epoch 859 train_loss 1.4622234521088777 train_accuracy 99.89259259259259\n",
            "epoch 860 train_loss 1.462151081804876 train_accuracy 99.9\n",
            "epoch 861 train_loss 1.4622129882927295 train_accuracy 99.89444444444445\n",
            "epoch 862 train_loss 1.46219087364497 train_accuracy 99.8962962962963\n",
            "epoch 863 train_loss 1.462151304549641 train_accuracy 99.9\n",
            "epoch 864 train_loss 1.4622493214077419 train_accuracy 99.89074074074074\n",
            "epoch 865 train_loss 1.4622734154816026 train_accuracy 99.88703703703703\n",
            "epoch 866 train_loss 1.462397527694702 train_accuracy 99.87962962962963\n",
            "epoch 867 train_loss 1.4623130823727006 train_accuracy 99.88518518518518\n",
            "epoch 868 train_loss 1.4622634370017935 train_accuracy 99.88888888888889\n",
            "epoch 869 train_loss 1.462169881772112 train_accuracy 99.89814814814815\n",
            "epoch 870 train_loss 1.4621690423400313 train_accuracy 99.89814814814815\n",
            "epoch 871 train_loss 1.4622525190865552 train_accuracy 99.89074074074074\n",
            "epoch 872 train_loss 1.4622330327828725 train_accuracy 99.89074074074074\n",
            "epoch 873 train_loss 1.4623069646181883 train_accuracy 99.88518518518518\n",
            "epoch 874 train_loss 1.4622408214542602 train_accuracy 99.89074074074074\n",
            "epoch 875 train_loss 1.4621691673994064 train_accuracy 99.89814814814815\n",
            "epoch 876 train_loss 1.4622601858995579 train_accuracy 99.88888888888889\n",
            "epoch 877 train_loss 1.4623248073789807 train_accuracy 99.88333333333334\n",
            "epoch 878 train_loss 1.4624370274720369 train_accuracy 99.87037037037037\n",
            "epoch 879 train_loss 1.4623498376872806 train_accuracy 99.87777777777778\n",
            "epoch 880 train_loss 1.4622685613455595 train_accuracy 99.88888888888889\n",
            "epoch 881 train_loss 1.4621865679820378 train_accuracy 99.8962962962963\n",
            "epoch 882 train_loss 1.4623166849215825 train_accuracy 99.88333333333334\n",
            "epoch 883 train_loss 1.4622272074222564 train_accuracy 99.89259259259259\n",
            "epoch 884 train_loss 1.4622453809888274 train_accuracy 99.89074074074074\n",
            "epoch 885 train_loss 1.4623300927656668 train_accuracy 99.88148148148149\n",
            "epoch 886 train_loss 1.4625940069004342 train_accuracy 99.85740740740741\n",
            "epoch 887 train_loss 1.462442981644913 train_accuracy 99.87037037037037\n",
            "epoch 888 train_loss 1.4622811395812918 train_accuracy 99.88703703703703\n",
            "epoch 889 train_loss 1.4623418237324115 train_accuracy 99.88148148148149\n",
            "epoch 890 train_loss 1.4624271636759794 train_accuracy 99.87222222222222\n",
            "epoch 891 train_loss 1.4623581028646893 train_accuracy 99.87962962962963\n",
            "epoch 892 train_loss 1.462274671263165 train_accuracy 99.88703703703703\n",
            "epoch 893 train_loss 1.462187608524605 train_accuracy 99.8962962962963\n",
            "epoch 894 train_loss 1.4621698180834453 train_accuracy 99.89814814814815\n",
            "epoch 895 train_loss 1.4621813580945686 train_accuracy 99.8962962962963\n",
            "epoch 896 train_loss 1.462303551810759 train_accuracy 99.88518518518518\n",
            "epoch 897 train_loss 1.4622878899176917 train_accuracy 99.88518518518518\n",
            "epoch 898 train_loss 1.462189397767738 train_accuracy 99.8962962962963\n",
            "epoch 899 train_loss 1.4622009258579325 train_accuracy 99.89444444444445\n",
            "epoch 899 validation_loss 1.4714166402816773 validation_accuracy 98.96666666666667\n",
            "epoch 900 train_loss 1.4621524490691997 train_accuracy 99.9\n",
            "epoch 901 train_loss 1.4622071651396928 train_accuracy 99.89444444444445\n",
            "epoch 902 train_loss 1.4622203405256624 train_accuracy 99.89259259259259\n",
            "epoch 903 train_loss 1.4621506692082793 train_accuracy 99.9\n",
            "epoch 904 train_loss 1.4622988279219027 train_accuracy 99.88518518518518\n",
            "epoch 905 train_loss 1.4624339231738337 train_accuracy 99.87037037037037\n",
            "epoch 906 train_loss 1.4622659277032923 train_accuracy 99.89074074074074\n",
            "epoch 907 train_loss 1.4622784825386825 train_accuracy 99.88703703703703\n",
            "epoch 908 train_loss 1.4621983414446866 train_accuracy 99.8962962962963\n",
            "epoch 909 train_loss 1.4625166126975306 train_accuracy 99.86111111111111\n",
            "epoch 910 train_loss 1.4623340336260973 train_accuracy 99.88148148148149\n",
            "epoch 911 train_loss 1.4623247073756325 train_accuracy 99.88333333333334\n",
            "epoch 912 train_loss 1.462187409180182 train_accuracy 99.8962962962963\n",
            "epoch 913 train_loss 1.4624176096033168 train_accuracy 99.87407407407407\n",
            "epoch 914 train_loss 1.4622695355503648 train_accuracy 99.88888888888889\n",
            "epoch 915 train_loss 1.4623246239291297 train_accuracy 99.88333333333334\n",
            "epoch 916 train_loss 1.4623018051739092 train_accuracy 99.88333333333334\n",
            "epoch 917 train_loss 1.4623502042558458 train_accuracy 99.87962962962963\n",
            "epoch 918 train_loss 1.4622440139452617 train_accuracy 99.89074074074074\n",
            "epoch 919 train_loss 1.4622466638132379 train_accuracy 99.89074074074074\n",
            "epoch 920 train_loss 1.4621741045404364 train_accuracy 99.89814814814815\n",
            "epoch 921 train_loss 1.462279670657935 train_accuracy 99.88703703703703\n",
            "epoch 922 train_loss 1.46220808007099 train_accuracy 99.89444444444445\n",
            "epoch 923 train_loss 1.4623202084391205 train_accuracy 99.88333333333334\n",
            "epoch 924 train_loss 1.4623515516519547 train_accuracy 99.87962962962963\n",
            "epoch 925 train_loss 1.4622880691731417 train_accuracy 99.88518518518518\n",
            "epoch 926 train_loss 1.4624651573322438 train_accuracy 99.86666666666666\n",
            "epoch 927 train_loss 1.4623174758972945 train_accuracy 99.88518518518518\n",
            "epoch 928 train_loss 1.4621502335424776 train_accuracy 99.9\n",
            "epoch 929 train_loss 1.4621506523202967 train_accuracy 99.9\n",
            "epoch 930 train_loss 1.4623708651021674 train_accuracy 99.87962962962963\n",
            "epoch 931 train_loss 1.462210104531712 train_accuracy 99.89444444444445\n",
            "epoch 932 train_loss 1.4621675118252082 train_accuracy 99.89814814814815\n",
            "epoch 933 train_loss 1.4621476642511508 train_accuracy 99.9\n",
            "epoch 934 train_loss 1.462150646801348 train_accuracy 99.9\n",
            "epoch 935 train_loss 1.4621959808799956 train_accuracy 99.89444444444445\n",
            "epoch 936 train_loss 1.4622957152348977 train_accuracy 99.88518518518518\n",
            "epoch 937 train_loss 1.4622376690308252 train_accuracy 99.89074074074074\n",
            "epoch 938 train_loss 1.4622377477310322 train_accuracy 99.89074074074074\n",
            "epoch 939 train_loss 1.4622389800018734 train_accuracy 99.89074074074074\n",
            "epoch 940 train_loss 1.4621506061818865 train_accuracy 99.9\n",
            "epoch 941 train_loss 1.4622019676146685 train_accuracy 99.89444444444445\n",
            "epoch 942 train_loss 1.4623045020633274 train_accuracy 99.88333333333334\n",
            "epoch 943 train_loss 1.4622538070987772 train_accuracy 99.88888888888889\n",
            "epoch 944 train_loss 1.4623581444775617 train_accuracy 99.87962962962963\n",
            "epoch 945 train_loss 1.4621709357809138 train_accuracy 99.89814814814815\n",
            "epoch 946 train_loss 1.462150678259355 train_accuracy 99.9\n",
            "epoch 947 train_loss 1.4621967134652314 train_accuracy 99.8962962962963\n",
            "epoch 948 train_loss 1.4622024346280982 train_accuracy 99.89444444444445\n",
            "epoch 949 train_loss 1.4622144954072105 train_accuracy 99.89444444444445\n",
            "epoch 950 train_loss 1.4622460103697248 train_accuracy 99.89074074074074\n",
            "epoch 951 train_loss 1.4624553506021147 train_accuracy 99.87222222222222\n",
            "epoch 952 train_loss 1.4622083916708275 train_accuracy 99.89444444444445\n",
            "epoch 953 train_loss 1.4622568053227885 train_accuracy 99.88888888888889\n",
            "epoch 954 train_loss 1.4621858994166057 train_accuracy 99.8962962962963\n",
            "epoch 955 train_loss 1.4622967682502888 train_accuracy 99.88703703703703\n",
            "epoch 956 train_loss 1.4623905219413615 train_accuracy 99.87592592592593\n",
            "epoch 957 train_loss 1.4622896743041498 train_accuracy 99.88518518518518\n",
            "epoch 958 train_loss 1.462174853792897 train_accuracy 99.8962962962963\n",
            "epoch 959 train_loss 1.462281654719953 train_accuracy 99.88703703703703\n",
            "epoch 960 train_loss 1.4621902615935713 train_accuracy 99.8962962962963\n",
            "epoch 961 train_loss 1.462243879282916 train_accuracy 99.89259259259259\n",
            "epoch 962 train_loss 1.4621403581566281 train_accuracy 99.90185185185184\n",
            "epoch 963 train_loss 1.4622937822783435 train_accuracy 99.88518518518518\n",
            "epoch 964 train_loss 1.4621551721184343 train_accuracy 99.9\n",
            "epoch 965 train_loss 1.4622203553164448 train_accuracy 99.89259259259259\n",
            "epoch 966 train_loss 1.4622597175615806 train_accuracy 99.88888888888889\n",
            "epoch 967 train_loss 1.4623787041063663 train_accuracy 99.87407407407407\n",
            "epoch 968 train_loss 1.4622353163030413 train_accuracy 99.89259259259259\n",
            "epoch 969 train_loss 1.4621773236327702 train_accuracy 99.89814814814815\n",
            "epoch 970 train_loss 1.4621729304393132 train_accuracy 99.89814814814815\n",
            "epoch 971 train_loss 1.462169232302242 train_accuracy 99.89814814814815\n",
            "epoch 972 train_loss 1.4621333772385563 train_accuracy 99.90185185185184\n",
            "epoch 973 train_loss 1.4621320752082048 train_accuracy 99.90185185185184\n",
            "epoch 974 train_loss 1.462185475119838 train_accuracy 99.8962962962963\n",
            "epoch 975 train_loss 1.462632093275035 train_accuracy 99.85555555555555\n",
            "epoch 976 train_loss 1.4621791122136292 train_accuracy 99.8962962962963\n",
            "epoch 977 train_loss 1.4621321983911373 train_accuracy 99.90185185185184\n",
            "epoch 978 train_loss 1.4621504948095039 train_accuracy 99.9\n",
            "epoch 979 train_loss 1.4621321271967005 train_accuracy 99.90185185185184\n",
            "epoch 980 train_loss 1.4621321322741332 train_accuracy 99.90185185185184\n",
            "epoch 981 train_loss 1.4621320906612607 train_accuracy 99.90185185185184\n",
            "epoch 982 train_loss 1.4621508220831554 train_accuracy 99.9\n",
            "epoch 983 train_loss 1.4621321270863215 train_accuracy 99.90185185185184\n",
            "epoch 984 train_loss 1.4621314537745935 train_accuracy 99.90185185185184\n",
            "epoch 985 train_loss 1.4621930142243704 train_accuracy 99.89444444444445\n",
            "epoch 986 train_loss 1.462153975279243 train_accuracy 99.9\n",
            "epoch 987 train_loss 1.4621322960765273 train_accuracy 99.90185185185184\n",
            "epoch 988 train_loss 1.4621697559400841 train_accuracy 99.89814814814815\n",
            "epoch 989 train_loss 1.4621839113809445 train_accuracy 99.8962962962963\n",
            "epoch 990 train_loss 1.4624130098908037 train_accuracy 99.87407407407407\n",
            "epoch 991 train_loss 1.4625231069547158 train_accuracy 99.86481481481482\n",
            "epoch 992 train_loss 1.4622227678696313 train_accuracy 99.89074074074074\n",
            "epoch 993 train_loss 1.4622790626905582 train_accuracy 99.88703703703703\n",
            "epoch 994 train_loss 1.4622405449549356 train_accuracy 99.89074074074074\n",
            "epoch 995 train_loss 1.4621772326804974 train_accuracy 99.89814814814815\n",
            "epoch 996 train_loss 1.4622292694118288 train_accuracy 99.89074074074074\n",
            "epoch 997 train_loss 1.462204795965442 train_accuracy 99.89444444444445\n",
            "epoch 998 train_loss 1.462215471488458 train_accuracy 99.89259259259259\n",
            "epoch 999 train_loss 1.462290675993319 train_accuracy 99.88518518518518\n",
            "epoch 999 validation_loss 1.4716083685557046 validation_accuracy 98.93333333333334\n",
            "Final Validation Accuracy: 98.93%\n",
            "epoch 0 test_loss 1.4708676666021347 test_accuracies 99.02\n",
            "Final Test Accuracy: 99.02%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
        "\n",
        "total_epochs = 1000  # Adjust this number as needed\n",
        "# Before training and testing, ensure data loaders are set up\n",
        "batch_size = 50\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)  # DataLoader for the training dataset\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)     # DataLoader for the validation dataset\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)   # DataLoader for the test dataset\n",
        "\n",
        "# Lists to keep history of training loss and accuracy\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "# Lists to keep history of validation loss and accuracy\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Train the model and record the losses and accuracies\n",
        "for epoch in range(total_epochs):\n",
        "    # Train the model on the training dataset and get the training loss and accuracy\n",
        "    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, device)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    print(\"epoch\", epoch, 'train_loss', train_loss, \"train_accuracy\", train_accuracy)\n",
        "\n",
        "    # Every 100 epochs, evaluate the model on the validation dataset\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        val_loss, val_accuracy = test(model, val_loader, criterion, device)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "        print(\"epoch\", epoch, 'validation_loss', val_loss, \"validation_accuracy\", val_accuracy)\n",
        "\n",
        "# Print the final validation accuracy\n",
        "print(f'Final Validation Accuracy: {val_accuracies[-1]:.2f}%')\n",
        "\n",
        "# After all training epochs are completed, test the model on the test dataset\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "test_losses = []       # List to store test losses\n",
        "test_accuracies = []   # List to store test accuracies\n",
        "\n",
        "# Since there's only one epoch mentioned for testing, we loop once\n",
        "for epoch in range(1):\n",
        "    test_loss, test_accuracy = test(model, test_loader, criterion, device)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    print(\"epoch\", epoch, 'test_loss', test_loss, \"test_accuracies\", test_accuracy)\n",
        "\n",
        "# Print the final test accuracy\n",
        "print(f'Final Test Accuracy: {test_accuracies[-1]:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4h7i6yeKtIm"
      },
      "source": [
        "## Loss and accuracy reporting (2 marks)\n",
        "Plot the training and validation loss and accuracy curves. Report the accuracy of your model on the test set.\n",
        "\n",
        "**Remember that your plots must have axes labels and a title. If more than one variable is displayed on the same plot, you must include a legend.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(total_epochs), train_losses, label='Training Loss', color='blue')\n",
        "plt.plot(range(99, total_epochs, 100), val_losses, label='Validation Loss', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(total_epochs), train_accuracies, label='Training Accuracy', color='blue')\n",
        "plt.plot(range(99, total_epochs, 100), val_accuracies, label='Validation Accuracy', color='red', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "4OJyu85yR7P4",
        "outputId": "af5bb484-b2df-421a-8e01-751c4f97cd9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAGGCAYAAACqvTJ0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC5KklEQVR4nOzdd1QU198G8GdBWDoqUhVpKmABFUuwFwyiIdYY0dhLYiwhqDHGXhJsSYyaaN5oxIYxNjSxIrH3hiUaIggiChgLIKiAy7x/zG9HV3rdXXw+58xZZubOnTuzo3vnO/fekQmCIICIiIiIiIiIiKgC6ai7AERERERERERE9PZhUIqIiIiIiIiIiCocg1JERERERERERFThGJQiIiIiIiIiIqIKx6AUERERERERERFVOAaliIiIiIiIiIiowjEoRUREREREREREFY5BKSIiIiIiIiIiqnAMShERERERERERUYVjUIqoEhk6dCgcHR1LtO3s2bMhk8nKtkAaJi4uDjKZDCEhIRW+b5lMhtmzZ0vzISEhkMlkiIuLK3RbR0dHDB06tEzLU5prhYiISN1Y5ykY6zyvsM5DpNkYlCKqADKZrEjTkSNH1F3Ut96ECRMgk8kQHR2db5pp06ZBJpPh6tWrFViy4rt//z5mz56NyMhIdRdFoqwkL1myRN1FISKicsA6j/Zgnafi3Lx5EzKZDAYGBkhJSVF3cYg0ShV1F4DobbBhwwaV+fXr1yM8PDzXcnd391Lt55dffkFOTk6Jtp0+fTq+/PLLUu2/Mhg4cCCWL1+O0NBQzJw5M880mzdvRqNGjeDh4VHi/QwaNAj9+/eHXC4vcR6FuX//PubMmQNHR0c0btxYZV1prhUiIqL8sM6jPVjnqTgbN26EjY0Nnjx5gm3btmHkyJFqLQ+RJmFQiqgCfPTRRyrzZ86cQXh4eK7lb3r27BmMjIyKvB89Pb0SlQ8AqlSpgipV+F9Cy5YtUadOHWzevDnPCtrp06cRGxuLBQsWlGo/urq60NXVLVUepVGaa4WIiCg/rPNoD9Z5KoYgCAgNDcWAAQMQGxuLTZs2aWxQKiMjA8bGxuouBr1l2H2PSEN06NABDRs2xMWLF9GuXTsYGRnhq6++AgDs2rUL3bt3h52dHeRyOVxcXDBv3jwoFAqVPN7sM/96V6n/+7//g4uLC+RyOZo3b47z58+rbJvX+AoymQzjxo1DWFgYGjZsCLlcjgYNGmD//v25yn/kyBE0a9YMBgYGcHFxwc8//1zkMRuOHz+ODz74ALVr14ZcLoe9vT0+//xzPH/+PNfxmZiY4N69e+jZsydMTExgaWmJSZMm5ToXKSkpGDp0KMzNzVG1alUMGTKkyM2lBw4ciH/++QeXLl3KtS40NBQymQwBAQHIysrCzJkz4eXlBXNzcxgbG6Nt27Y4fPhwofvIa3wFQRAwf/581KpVC0ZGRujYsSP+/vvvXNs+fvwYkyZNQqNGjWBiYgIzMzP4+fnhypUrUpojR46gefPmAIBhw4ZJ3SWUY0vkNb5CRkYGJk6cCHt7e8jlcri6umLJkiUQBEElXXGui5J68OABRowYAWtraxgYGMDT0xPr1q3Lle63336Dl5cXTE1NYWZmhkaNGuGHH36Q1mdnZ2POnDmoW7cuDAwMYGFhgTZt2iA8PLzMykpERMXDOg/rPG9TnefkyZOIi4tD//790b9/fxw7dgwJCQm50uXk5OCHH35Ao0aNYGBgAEtLS3Tt2hUXLlxQSbdx40a0aNECRkZGqFatGtq1a4eDBw+qlPn1Mb2U3hyvS/m9HD16FJ9++imsrKxQq1YtAMCdO3fw6aefwtXVFYaGhrCwsMAHH3yQ57hgKSkp+Pzzz+Ho6Ai5XI5atWph8ODBePjwIdLT02FsbIzPPvss13YJCQnQ1dVFcHBwEc8kVVZ8RECkQR49egQ/Pz/0798fH330EaytrQGIPxomJiYICgqCiYkJ/vrrL8ycORNpaWlYvHhxofmGhobi6dOn+PjjjyGTybBo0SL07t0bt2/fLvTp0YkTJ7Bjxw58+umnMDU1xbJly9CnTx/Ex8fDwsICAHD58mV07doVtra2mDNnDhQKBebOnQtLS8siHffWrVvx7NkzjBkzBhYWFjh37hyWL1+OhIQEbN26VSWtQqGAr68vWrZsiSVLluDQoUP49ttv4eLigjFjxgAQKzo9evTAiRMn8Mknn8Dd3R07d+7EkCFDilSegQMHYs6cOQgNDUXTpk1V9v3777+jbdu2qF27Nh4+fIjVq1cjICAAo0aNwtOnT7FmzRr4+vri3LlzuZqPF2bmzJmYP38+unXrhm7duuHSpUt49913kZWVpZLu9u3bCAsLwwcffAAnJyckJyfj559/Rvv27XHjxg3Y2dnB3d0dc+fOxcyZMzF69Gi0bdsWANCqVas89y0IAt5//30cPnwYI0aMQOPGjXHgwAFMnjwZ9+7dw/fff6+SvijXRUk9f/4cHTp0QHR0NMaNGwcnJyds3boVQ4cORUpKilSxCQ8PR0BAADp37oyFCxcCEMdsOHnypJRm9uzZCA4OxsiRI9GiRQukpaXhwoULuHTpErp06VKqchIRUcmxzsM6z9tS59m0aRNcXFzQvHlzNGzYEEZGRti8eTMmT56skm7EiBEICQmBn58fRo4ciZcvX+L48eM4c+YMmjVrBgCYM2cOZs+ejVatWmHu3LnQ19fH2bNn8ddff+Hdd98t8vl/3aeffgpLS0vMnDkTGRkZAIDz58/j1KlT6N+/P2rVqoW4uDisXLkSHTp0wI0bN6RWjenp6Wjbti1u3ryJ4cOHo2nTpnj48CF2796NhIQENG7cGL169cKWLVvw3XffqbSY27x5MwRBwMCBA0tUbqpEBCKqcGPHjhXe/OfXvn17AYCwatWqXOmfPXuWa9nHH38sGBkZCS9evJCWDRkyRHBwcJDmY2NjBQCChYWF8PjxY2n5rl27BADCH3/8IS2bNWtWrjIBEPT19YXo6Ghp2ZUrVwQAwvLly6Vl/v7+gpGRkXDv3j1p2a1bt4QqVarkyjMveR1fcHCwIJPJhDt37qgcHwBh7ty5KmmbNGkieHl5SfNhYWECAGHRokXSspcvXwpt27YVAAhr164ttEzNmzcXatWqJSgUCmnZ/v37BQDCzz//LOWZmZmpst2TJ08Ea2trYfjw4SrLAQizZs2S5teuXSsAEGJjYwVBEIQHDx4I+vr6Qvfu3YWcnBwp3VdffSUAEIYMGSIte/HihUq5BEH8ruVyucq5OX/+fL7H++a1ojxn8+fPV0nXt29fQSaTqVwDRb0u8qK8JhcvXpxvmqVLlwoAhI0bN0rLsrKyBG9vb8HExERIS0sTBEEQPvvsM8HMzEx4+fJlvnl5enoK3bt3L7BMRERUfljnKfz4WOcRVbY6jyCI9RcLCwth2rRp0rIBAwYInp6eKun++usvAYAwYcKEXHkoz9GtW7cEHR0doVevXrnOyevn8c3zr+Tg4KBybpXfS5s2bXLVpfK6Tk+fPi0AENavXy8tmzlzpgBA2LFjR77lPnDggABA2Ldvn8p6Dw8PoX379rm2o7cPu+8RaRC5XI5hw4blWm5oaCj9/fTpUzx8+BBt27bFs2fP8M8//xSa74cffohq1apJ88onSLdv3y50Wx8fH7i4uEjzHh4eMDMzk7ZVKBQ4dOgQevbsCTs7OyldnTp14OfnV2j+gOrxZWRk4OHDh2jVqhUEQcDly5dzpf/kk09U5tu2batyLHv37kWVKlWkp4iAOJ7B+PHji1QeQBwTIyEhAceOHZOWhYaGQl9fHx988IGUp76+PgCxyfXjx4/x8uVLNGvWLM9m8AU5dOgQsrKyMH78eJXm/4GBgbnSyuVy6OiI/30rFAo8evQIJiYmcHV1LfZ+lfbu3QtdXV1MmDBBZfnEiRMhCAL27dunsryw66I09u7dCxsbGwQEBEjL9PT0MGHCBKSnp+Po0aMAgKpVqyIjI6PArnhVq1bF33//jVu3bpW6XEREVHZY52Gd522o8+zbtw+PHj1SqdMEBATgypUrKt0Vt2/fDplMhlmzZuXKQ3mOwsLCkJOTg5kzZ0rn5M00JTFq1KhcY369fp1mZ2fj0aNHqFOnDqpWrapy3rdv3w5PT0/06tUr33L7+PjAzs4OmzZtktZdv34dV69eLXSsOXo7MChFpEFq1qwp/eC/7u+//0avXr1gbm4OMzMzWFpaSv+Jp6amFppv7dq1VeaVlbUnT54Ue1vl9sptHzx4gOfPn6NOnTq50uW1LC/x8fEYOnQoqlevLo2Z0L59ewC5j0/Zxz6/8gBiP3hbW1uYmJiopHN1dS1SeQCgf//+0NXVRWhoKADgxYsX2LlzJ/z8/FQqu+vWrYOHh4c0XpGlpSX27NlTpO/ldXfu3AEA1K1bV2W5paWlyv4AsTL4/fffo27dupDL5ahRowYsLS1x9erVYu/39f3b2dnB1NRUZbny7UjK8ikVdl2Uxp07d1C3bt1cFa43y/Lpp5+iXr168PPzQ61atTB8+PBcYzzMnTsXKSkpqFevHho1aoTJkydr/GutiYjeBqzzsM7zNtR5Nm7cCCcnJ8jlckRHRyM6OhouLi4wMjJSCdLExMTAzs4O1atXzzevmJgY6OjooH79+oXutzicnJxyLXv+/DlmzpwpjbmlPO8pKSkq5z0mJgYNGzYsMH8dHR0MHDgQYWFhePbsGQCxS6OBgYEU9KS3G4NSRBrk9acSSikpKWjfvj2uXLmCuXPn4o8//kB4eLg0hk5RXnGb3xtPhDcGcyzrbYtCoVCgS5cu2LNnD6ZMmYKwsDCEh4dLg1O+eXwV9fYWKysrdOnSBdu3b0d2djb++OMPPH36VKXf+8aNGzF06FC4uLhgzZo12L9/P8LDw9GpU6dyffXwN998g6CgILRr1w4bN27EgQMHEB4ejgYNGlTYK4/L+7ooCisrK0RGRmL37t3S2BB+fn4q42i0a9cOMTEx+PXXX9GwYUOsXr0aTZs2xerVqyusnERElBvrPKzzFIU213nS0tLwxx9/IDY2FnXr1pWm+vXr49mzZwgNDa3QetObA+Qr5fVvcfz48fj666/Rr18//P777zh48CDCw8NhYWFRovM+ePBgpKenIywsTHob4XvvvQdzc/Ni50WVDwc6J9JwR44cwaNHj7Bjxw60a9dOWh4bG6vGUr1iZWUFAwMDREdH51qX17I3Xbt2Df/++y/WrVuHwYMHS8tL83Y0BwcHREREID09XeXJYVRUVLHyGThwIPbv3499+/YhNDQUZmZm8Pf3l9Zv27YNzs7O2LFjh0qz6byaXhelzABw69YtODs7S8v/+++/XE/itm3bho4dO2LNmjUqy1NSUlCjRg1pvjhNuR0cHHDo0CE8ffpU5cmhsquEsnwVwcHBAVevXkVOTo5Ka6m8yqKvrw9/f3/4+/sjJycHn376KX7++WfMmDFDempdvXp1DBs2DMOGDUN6ejratWuH2bNna+zrmImI3las8xQf6zwiTazz7NixAy9evMDKlStVygqI38/06dNx8uRJtGnTBi4uLjhw4AAeP36cb2spFxcX5OTk4MaNGwUOLF+tWrVcb1/MyspCYmJikcu+bds2DBkyBN9++6207MWLF7nydXFxwfXr1wvNr2HDhmjSpAk2bdqEWrVqIT4+HsuXLy9yeahyY0spIg2nfDrz+pOUrKws/PTTT+oqkgpdXV34+PggLCwM9+/fl5ZHR0fn6pOf3/aA6vEJgoAffvihxGXq1q0bXr58iZUrV0rLFApFsX/8evbsCSMjI/z000/Yt28fevfuDQMDgwLLfvbsWZw+fbrYZfbx8YGenh6WL1+ukt/SpUtzpdXV1c31ZG3r1q24d++eyjJjY2MAKNJrobt16waFQoEVK1aoLP/+++8hk8mKPFZGWejWrRuSkpKwZcsWadnLly+xfPlymJiYSN0cHj16pLKdjo4OPDw8AACZmZl5pjExMUGdOnWk9UREpDlY5yk+1nlEmljn2bhxI5ydnfHJJ5+gb9++KtOkSZNgYmIideHr06cPBEHAnDlzcuWjPP6ePXtCR0cHc+fOzdVa6fVz5OLiojI+GAD83//9X74tpfKS13lfvnx5rjz69OmDK1euYOfOnfmWW2nQoEE4ePAgli5dCgsLiwqtW5JmY0spIg3XqlUrVKtWDUOGDMGECRMgk8mwYcOGCm3uW5jZs2fj4MGDaN26NcaMGSP90Dds2BCRkZEFbuvm5gYXFxdMmjQJ9+7dg5mZGbZv316qsYn8/f3RunVrfPnll4iLi0P9+vWxY8eOYo89YGJigp49e0pjLLz5ytr33nsPO3bsQK9evdC9e3fExsZi1apVqF+/PtLT04u1L0tLS0yaNAnBwcF477330K1bN1y+fBn79u3L9XTtvffew9y5czFs2DC0atUK165dw6ZNm1SeNgJipaRq1apYtWoVTE1NYWxsjJYtW+Y5doC/vz86duyIadOmIS4uDp6enjh48CB27dqFwMBAlQE+y0JERARevHiRa3nPnj0xevRo/Pzzzxg6dCguXrwIR0dHbNu2DSdPnsTSpUulp5ojR47E48eP0alTJ9SqVQt37tzB8uXL0bhxY2lciPr166NDhw7w8vJC9erVceHCBWzbtg3jxo0r0+MhIqLSY52n+FjnEWlanef+/fs4fPhwrsHUleRyOXx9fbF161YsW7YMHTt2xKBBg7Bs2TLcunULXbt2RU5ODo4fP46OHTti3LhxqFOnDqZNm4Z58+ahbdu26N27N+RyOc6fPw87OzsEBwcDEOtHn3zyCfr06YMuXbrgypUrOHDgQK5zW5D33nsPGzZsgLm5OerXr4/Tp0/j0KFDsLCwUEk3efJkbNu2DR988AGGDx8OLy8vPH78GLt378aqVavg6ekppR0wYAC++OIL7Ny5E2PGjIGenl4JzixVShXwhj8iekN+r0du0KBBnulPnjwpvPPOO4KhoaFgZ2cnfPHFF9LrVQ8fPiyly+/1yIsXL86VJ954XWx+r0ceO3Zsrm3ffKWsIAhCRESE0KRJE0FfX19wcXERVq9eLUycOFEwMDDI5yy8cuPGDcHHx0cwMTERatSoIYwaNUp63e7rr/YdMmSIYGxsnGv7vMr+6NEjYdCgQYKZmZlgbm4uDBo0SLh8+XKRX4+stGfPHgGAYGtrm+frd7/55hvBwcFBkMvlQpMmTYQ///wz1/cgCIW/HlkQBEGhUAhz5swRbG1tBUNDQ6FDhw7C9evXc53vFy9eCBMnTpTStW7dWjh9+rTQvn37XK/W3bVrl1C/fn3pVdXKY8+rjE+fPhU+//xzwc7OTtDT0xPq1q0rLF68WOU1w8pjKep18SblNZnftGHDBkEQBCE5OVkYNmyYUKNGDUFfX19o1KhRru9t27ZtwrvvvitYWVkJ+vr6Qu3atYWPP/5YSExMlNLMnz9faNGihVC1alXB0NBQcHNzE77++mshKyurwHISEVHZYJ1HFes8ospe5/n2228FAEJERES+aUJCQgQAwq5duwRBEISXL18KixcvFtzc3AR9fX3B0tJS8PPzEy5evKiy3a+//io0adJEkMvlQrVq1YT27dsL4eHh0nqFQiFMmTJFqFGjhmBkZCT4+voK0dHRucqs/F7Onz+fq2xPnjyR6mEmJiaCr6+v8M8//+R53I8ePRLGjRsn1KxZU9DX1xdq1aolDBkyRHj48GGufLt16yYAEE6dOpXveaG3j0wQNOjRAxFVKj179sTff/+NW7duqbsoREREROWGdR6iwvXq1QvXrl0r0hhs9PbgmFJEVCaeP3+uMn/r1i3s3bsXHTp0UE+BiIiIiMoB6zxExZeYmIg9e/Zg0KBB6i4KaRi2lCKiMmFra4uhQ4fC2dkZd+7cwcqVK5GZmYnLly+jbt266i4eERERUZlgnYeo6GJjY3Hy5EmsXr0a58+fR0xMDGxsbNRdLNIgHOiciMpE165dsXnzZiQlJUEul8Pb2xvffPMNK2dERERUqbDOQ1R0R48exbBhw1C7dm2sW7eOASnKhS2liIiIiIiIiIiownFMKSIiIiIiIiIiqnAMShERERERERERUYXjmFIllJOTg/v378PU1BQymUzdxSEiIqJyIggCnj59Cjs7O+jo8HleabD+RERE9HYoav2JQakSun//Puzt7dVdDCIiIqogd+/eRa1atdRdDK3G+hMREdHbpbD6E4NSJWRqagpAPMFmZmZqLg0RERGVl7S0NNjb20u//VRyrD8RERG9HYpaf2JQqoSUTc7NzMxYqSIiInoLsLtZ6bH+RERE9HYprP7EgRGIiIiIiIiIiKjCMShFREREREREREQVjkEpIiIiIiIiIiKqcBxTioiItIZCoUB2dra6i0GVjJ6eHnR1ddVdDCIiIqK3DoNSRESk8QRBQFJSElJSUtRdFKqkqlatChsbGw5mTkRERFSBGJQiIiKNpwxIWVlZwcjIiIEDKjOCIODZs2d48OABAMDW1lbNJSqaY8eOYfHixbh48SISExOxc+dO9OzZU1ovCAJmzZqFX375BSkpKWjdujVWrlyJunXrSmkeP36M8ePH448//oCOjg769OmDH374ASYmJvnu98WLF5g4cSJ+++03ZGZmwtfXFz/99BOsra3L83CJiIiokmJQioiINJpCoZACUhYWFuouDlVChoaGAIAHDx7AyspKK7ryZWRkwNPTE8OHD0fv3r1zrV+0aBGWLVuGdevWwcnJCTNmzICvry9u3LgBAwMDAMDAgQORmJiI8PBwZGdnY9iwYRg9ejRCQ0Pz3e/nn3+OPXv2YOvWrTA3N8e4cePQu3dvnDx5styOlYiIiCovmSAIgroLoY3S0tJgbm6O1NRUmJmZqbs4RESV1osXLxAbGwtHR0cpeEBU1p4/f464uDg4OTlJQRslTf/Nl8lkKi2lBEGAnZ0dJk6ciEmTJgEAUlNTYW1tjZCQEPTv3x83b95E/fr1cf78eTRr1gwAsH//fnTr1g0JCQmws7PLtZ/U1FRYWloiNDQUffv2BQD8888/cHd3x+nTp/HOO+8UWlZNP5dERERUNor6m8+37xERkVZglz0qT5Xp+oqNjUVSUhJ8fHykZebm5mjZsiVOnz4NADh9+jSqVq0qBaQAwMfHBzo6Ojh79mye+V68eBHZ2dkq+bq5uaF27dpSvkRERETFwe57RERERJVIUlISAOQa58na2lpal5SUBCsrK5X1VapUQfXq1aU0eeWrr6+PqlWr5pvvmzIzM5GZmSnNp6WlFetYiIiIqHJjUErDZGcDyjFIr14F2LKdiIhe5+joiMDAQAQGBhYp/ZEjR9CxY0c8efIkVzCBqLwFBwdjzpw56i4G5SM9HShgXHsAYt00MzP/dMqBQFJSgKpVAZkMyMkRP5UNEF++BJKSgBcvgJo1xW2uXgWsrQFHRyA19VWaKlWAxESgXTsgLg4wNQWsrIArV8R9VKsm/v38OfDee4C5ubiPQ4eAx48BDw/gzh3gv/8AZ2fgnXeA8+eBu3eBVq0AQ0NxXvm3vj6wZw9gYADI5YCnJxAdLe7L2Bh49AhISwOMjABdXfHYbt0SP+vXF9OkpIjHceoU4OoK1KghLtPRAdzdgcuXgWvXxL+TkoCnT8V1Hh7iubh8WczP2xuIjRXL8fixmPfjx4CDA2BhAdy4IZY3LU08/mbNgDNnxPI4OYnH8+CBeAxmZuJ5yM4W09eoAYSHi9vXqwfUqSOmyckBnjwBnj0DGjQQy3P7tvj9HDgAvPuu+L2mpwN6euL3U7WqWK5nzwAbG/GYatYEHj4Ul8lkYtp69QAXF+DPPwGFQlzeqJF4HSQkiN9dgwZAVpb4/ejoiGW2tha/90ePxGNq1Eg8t8+eieexe3fxu42JEc+VuTlw8qRYrqdPxXspPT1xH6am4jE+fiyeWzMzcf+3bwPvvy8eb0aGmO/Dh+JxdusGnDsnnv9q1cTvKS5OPM/9+4ufN26IZdDXF/PX0xOvoX//Fc9F/fri/h8+FL+Tp0/FZY8fi99dvXri+Xj+XFxvaipOOjriPuPjxfzc3IALF4D798V5IyPxXFpavjrXVaqI5xAQv2cdHfH7S0kR552cxHJGR4vH6uz86jt/+RI4fBho21Y8l3p64nlychLL9uyZmEdysniO7O3F85GZKR6bra1YhgsXxDK5uIjlsbcX/11fvfrqunR0FI/t9m2xrIaG4nctl4vXqPLfrK6u+L0oFOL3YWoq7v/pUzFvIyOx3Glp4hQTI/7bUX7v//wjLs/JEberXVs8P8ePi/+vZGSI+dSoIZbh9m0xbfXqYh5xceI1YmYmnsOWLcVjiYoSlxkaisddrZp4HcTFif8OkpPFclWpIk7K/9Ps7cVj8fAQ5x88AGrVEre/fFlcZmQkfke1a4vn4+5dMc/0dPG4zczE43R2fhUf+O8/8ViePBH/jWRlif9mdHSAixfFdNWrv/q/2sRE/N7MzcX/U1JSxOM2NRWPMTBQLIc6MCilge7cET8VCvWWg4iISq6w7mCzZs3C7Nmzi53v+fPnYWxsXOT0rVq1QmJiIsyVd27lhMEvzWFjYwMASE5OVnmbYHJyMho3biylUb5xUOnly5d4/PixtH1e+WZlZSElJUXlO05OTs53m6lTpyIoKEiaT0tLg729fUkOSyslJYk3tqamr5YJgnjTVKWKeGNz5gzQpIl4wxAbK954REeLNyt164o3cnFx4k2fu7t4E5GTI94gJSSINyzt24s3I8qbQUEAIiPFm82+fV/dCEZHizckJibiTb5S/fri540br24s79wRb6IuXRJvXtzdxRtlJyfx5uv+/dzH6+ws3hRGRYnzMpkYUEpOzv8cyeXijRJppjVr1F2C3MrqvQrXruW9fMUK1fkdO8pm3xERJd+2vB04oDp/6VLe6VJS8j9v//5b8Pk5f75ERSuSvXvzX3fr1qu/jx0rOJ+//sq97PjxkpVJKT5e/DxzpvC0168XLa833b2be5kyaJeXCxdU548fB6ZMKbx85YVBKQ1TiYa0ICJ6qyUmJkp/b9myBTNnzkSU8k4NgMlrzQ4EQYBCoUCVKoX/LFtaWharHPr6+vkGDKhycnJygo2NDSIiIqQgVFpaGs6ePYsxY8YAALy9vZGSkoKLFy/Cy8sLAPDXX38hJycHLVu2zDNfLy8v6OnpISIiAn369AEAREVFIT4+Ht7e3nluI5fLIZfLy/gINcO//4pPz+/fFwMxDx4Au3YBYWFiC4yDB8Wn7YC43sNDfIJ9964YrCqJsLC8l79+0/WmbdsKz/fGjVd///efOAFiiyWlq1fFz8uX889H2QJCSRAKDkgBxQ9IyWSvWmcVJ425ufh9FYWpqdjKICtLDPL984/YYsTMLO+bPBMTsUXD62xtxRYfCQliYNHGRrwpNTICfH3FVhQnTojb2durnjsjI7GFTGSk2OpJ+Z3Y2Ylp87qxNjERA4dVq4qto5KSxL8fPVK9PkxMxOvz/n3xPOnqimX47z8xIGpsLLaisrQUz5e1tXijbGsrBkeTksS/GzYUW2hYWYktPHbtElv/eHuL5ys7W7zxNTQUp8ePxeu/TRuxJdHjx+J3LwivWlyZmIit4GrWFFvpXLkiBl0dHMSpYUPxHCoU4rbOzmLed++KrXZatRKP4cIFMVDbuLH4fWVliVNEBNC5sxgIPXwYaNpUPO+OjuJxnjgh5m1mJt78d+smluHvv8Vzcv26GPj18REDyI0bi+WzthbPQXIy4OUlBl/u3xdb4rRoIZYhLEz8PtLSxO+pbl3x7ypVxGNRXps6OuL/Fw8fitfskyfi92No+KplUufOYmDI1lbMQ09PPIe1aollSEkRv4fMTDEQnZYmnltly68bN8S0Dx6IAejLl8XrzMBAPP6aNYGzZ8VWf9Wqid+7s7N4fiwtxdY5crl43q5dE8/XgwdA69bieVO2UouPF7/Hnj3FazA5+VXrMjc3sXzx8eK5fL1qY2j4quWXsuVZgwbiuUlPF8+Dk9OrlnE//SQeW716YnCtenVg8mTxu4uOFq+xdu3E1pROTkCHDuK/sehosSy2tuI+790Ty+LiIi7Pzhans2fF/GvVEv9P37RJDOSbmIgtlBwcxCC+k5N4Dq9eFa+V69fFsijLZmoqzhsaiv+Orl0T/3ZzE68VFxcxoK+n9+rf7qNH4rE/eyYGjiwsxGtGEMT/C7KyxHOckiLuu0ULsSxLlojfx7hx4nnMyRH/jevri+W/exfo1Uv87lJTxe9CnS8e5tv3Sqi83h7z8qV4IQLiRfh6kzsioreR8u17eb0VTVuEhIQgMDAQKSkpAF61Ktq7dy+mT5+Oa9eu4eDBg7C3t0dQUBDOnDmDjIwMuLu7Izg4WGVg6Te778lkMvzyyy/Ys2cPDhw4gJo1a+Lbb7/F+++/r7IvZQsmZVm2bNmCwMBA3L17F23atMHatWulVjUvX75EUFAQ1q9fD11dXYwcORJJSUlITU1FWD53xYW1lHry5Ak+++wz/PHHH8jMzET79u2xbNky1P1fn/U7d+5g3LhxOHHiBLKysuDo6IjFixejW7duePLkCcaNG4eDBw8iPT0dtWrVwldffYVhw4aVzReEgq8zTXxjXHp6OqKjowEATZo0wXfffYeOHTuievXqqF27NhYuXIgFCxZg3bp1cHJywowZM3D16lXcuHFDOj4/Pz8kJydj1apVyM7OxrBhw9CsWTOEhoYCAO7du4fOnTtj/fr1aNGiBQBgzJgx2Lt3L0JCQmBmZobx48cDAE693uymAJp4LvPz5Il4s2ZtDRw9Kt6YXLwoVuATEkqXt7JrR0GMjcWbP0Asw4MH4o1gQIB40//62PJGRuKN7r17QL9+4g3Hzp3iujp1xBv0xMRXN8FXr4pBgREjxLqmrq7YGuTff8Ub8U6dxBumWrXEm6AaNcTtTU3FMt24AaxdKwYYpkwRz4vyxlOhENc3aCDeQCq7CykU4o2UhYV40/7ee+Jx/f23WP6MDPEG2MhILH9kJPDBB+L5jo8Xb6batHn1ADc7W0xTs6a4LjJS/I6GDxdvMq9cEc+hhYV486ivLx6zgYE4ZWeLN3o3bojn7vp1scVaXJx4A/l6LFWhEG+IZTIx2GBtLd70KhTAxx+L26emijeSOTliWkA83idPxOOSycTza2QknldAvAaUgSFl90Y7O3FeV1e8UcwvppuYKB4n8KpVXUFdLIvy4Lug/Snl1+Xz+XPxvCr3IwhiEKBhw1flfP3clKfs7Ff3U6WVkyMei7LrZkWUn0pOEMSJ35NmKOpvPltKaZjXfzAYLiQiypvyyWpFMzIq2xatX375JZYsWQJnZ2dUq1YNd+/eRbdu3fD1119DLpdj/fr18Pf3R1RUFGrXrp1vPnPmzMGiRYuwePFiLF++HAMHDsSdO3dQPZ8nG8+ePcOSJUuwYcMG6Ojo4KOPPsKkSZOwadMmAMDChQuxadMmrF27Fu7u7vjhhx8QFhaGjh07lvhYhw4dilu3bmH37t0wMzPDlClT0K1bN9y4cQN6enoYO3YssrKycOzYMRgbG+PGjRtSa7IZM2bgxo0b2LdvH2rUqIHo6Gg8f/68xGWpDC5cuKDyfSi7yA0ZMgQhISH44osvkJGRgdGjRyMlJQVt2rTB/v37VQJumzZtwrhx49C5c2fo6OigT58+WLZsmbQ+OzsbUVFRePbaP7bvv/9eSpuZmQlfX1/89NNPFXDE5UsQxFYUMTHiDf7PPxdve2Xv2Ddb4gQEiGOEWFmJrQ4AMXDRrJn4f9ilS2LAxsJCDOxERQEffigGOywsxCBBRoYYOHrz/57U1FdPuZXjoZRGcHDx0v/666u/33tP/PT0LNq2bdq8+juvRnYODq/SWFuLQaI36euLrQKUunQRJ6X/NRJU8fo5ksvFqXVrcb5dO/GzUaPc273egsDOTvz87jvVNMpY/Os3wzKZ6j7fPI7XG8fm1aC1oADRaz1z0aRJ/umU5SiKojRqzC/wZWiYe5+vfx9AxQUKyiogBaiWmYEOzff6WHakPRiU0jD8R0REVLhnzwofnLc8pKeLT97Lyty5c9HltVp79erV4fnaXd28efOwc+dO7N69G+OUbbDzMHToUAQEBAAAvvnmGyxbtgznzp1D165d80yfnZ2NVatWwcXFBQAwbtw4zJ07V1q/fPlyTJ06Fb169QIArFixAnsLGrChEMpg1MmTJ9GqVSsAYkDE3t4eYWFh+OCDDxAfH48+ffqg0f/uCJ2dnaXt4+Pj0aRJEzRr1gyA2FrsbdehQwcU1NhdJpNh7ty5Kt/rm6pXry61isqLo6Njrn0YGBjgxx9/xI8//lj8QmuwOXPEqSAtWohBJktLMSCSng507Ci2PvLwENMoFGJrnKdPxS4UBcVx5XKxG45Sx4650ytb9eRFGQjjEG5ERKTNGJTSYGwpRURUuSmDLErp6emYPXs29uzZg8TERLx8+RLPnz9HfH4jW/6Ph/KOGICxsTHMzMxyDWL9OiMjIykgBQC2trZS+tTUVCQnJ0vdtQBAV1cXXl5eyMnJKdbxKd28eRNVqlRRGavIwsICrq6uuHnzJgBgwoQJGDNmDA4ePAgfHx/06dNHOq4xY8agT58+uHTpEt5991307NlTCm4RlVROjvi2oeXLc6977z2xC1v//mIgWtmqpjC6umLQytJSbAFFREREBWNQSsOwpRQRUeGMjHIPKltR+y1Lb75Fb9KkSQgPD8eSJUtQp04dGBoaom/fvshSjviZD703+irIZLICA0h5pVf3EJMjR46Er68v9uzZg4MHDyI4OBjffvstxo8fDz8/P9y5cwd79+5FeHg4OnfujLFjx2LJkiVqLTNpL+XAt6+/KSogQByPqXv3su3+Q0RERPljz1gNxpZSRER5k8nE1gsVPZX3g4OTJ09i6NCh6NWrFxo1agQbGxvExcWV707fYG5uDmtra5x/7d3NCoUCl/J7P3QRuLu74+XLlzh79qy07NGjR4iKikJ95bvoAdjb2+OTTz7Bjh07MHHiRPzyyy/SOktLSwwZMgQbN27E0qVL8X//938lLg9R376qAak1a8Q3EvXsyYAUERFRRWJLKQ3Dgc6JiN5edevWxY4dO+Dv7w+ZTIYZM2aUuMtcaYwfPx7BwcGoU6cO3NzcsHz5cjx58gSyIkTlrl27BlNTU2leJpPB09MTPXr0wKhRo/Dzzz/D1NQUX375JWrWrIkePXoAAAIDA+Hn54d69erhyZMnOHz4MNzd3QEAM2fOhJeXFxo0aIDMzEz8+eef0jqi4tq8WXzTHAAMGgSsW8eW6kREROqi1pZSx44dg7+/P+zs7CCTyfJ9zfTrMjMzMW3aNDg4OEAul8PR0RG/vvb6j5CQEMhkMpXpzVc7C4KAmTNnwtbWFoaGhvDx8cGtW7fK+vCIiIiK5bvvvkO1atXQqlUr+Pv7w9fXF02bNq3wckyZMgUBAQEYPHgwvL29YWJiAl9f31y/p3lp164dmjRpIk1eXl4AgLVr18LLywvvvfcevL29IQgC9u7dK3UlVCgUGDt2LNzd3dG1a1fUq1dPequbvr4+pk6dCg8PD7Rr1w66urr47bffyu8EUKX155/AgAHi3127AuvXMyBFRESkTjJBjYNI7Nu3DydPnoSXlxd69+6NnTt3omfPngVu06NHDyQnJ2P+/PmoU6cOEhMTkZOTg9b/e59rSEgIPvvsM0RFRUnbyGQyWFtbS/MLFy5EcHAw1q1bBycnJ8yYMQPXrl3DjRs3ilThBoC0tDSYm5sjNTUVZmZmxT/4AigrR0lJ4mtwiYjeZi9evEBsbCycnJyK/H80la2cnBy4u7ujX79+mDdvnrqLUy4Kus7K8zf/baPOc5mTAzg4AAkJYnfchw/zf7MdERFRkSkUwPHjQGIiYGsLtG0rvvniLVfU33y1dt/z8/ODn59fkdPv378fR48exe3bt1G9enUAeb8WWiaTwcbGJs88BEHA0qVLMX36dKnLwPr162FtbY2wsDD079+/+AdSxmQyseseu+8REZE63LlzBwcPHkT79u2RmZmJFStWIDY2FgOUTUyItNDcuWJAChDHk2JAirQKb3qpstPWa3zHDuCzz179wABArVrADz8AvXurr1xFoSHnXKsGOt+9ezeaNWuGRYsWoWbNmqhXrx4mTZqE58+fq6RLT0+Hg4MD7O3t0aNHD/z999/SutjYWCQlJcHHx0daZm5ujpYtW+L06dMVdiwFYTNyIiJSJx0dHYSEhKB58+Zo3bo1rl27hkOHDnEcJ9JaL18CP/4o/v3NN4Cnp3rLQ1QsO3YAjo5Ax45i/9OOHcV55eBoVD4UCuDIEXEguiNHxHltoI3l1tZrfMcO8c0ZrwekAODePXG5Jpdfg865Vg10fvv2bZw4cQIGBgbYuXMnHj58iE8//RSPHj3C2rVrAQCurq749ddf4eHhgdTUVCxZsgStWrXC33//jVq1aiEpKQkAVLrzKeeV6/KSmZmJzMxMaT4tLa0cjlAVW0oREZE62Nvb4+TrryYj0nJHjojd9WrUACZPVndpKgkNecJe6Slvet+8MVDe9G7bptmtMbT1OtHW1i/aWG5tvcYVCvFc53XTLghiS5PAQKBHD8275jXsnGtVUConJwcymQybNm2Cubk5AHFQ2L59++Knn36CoaEhvL294e3tLW3TqlUruLu74+effy7VOBjBwcGYM2dOqY+hKNhSioiIiKjsbNwofvbpA1TRpNovb9grnjadc22+6QW09zrRsBv2ItPGcpf3NS4IYlPZrKyyn6Kjc7eQenPfd+8CH34oDmioq6sZEwCMHatR/69o0s9yoWxtbVGzZk0pIAUA7u7uEAQBCQkJqFu3bq5t9PT00KRJE0RHRwOANNZUcnIybG1tpXTJyclo3LhxvvueOnUqgoKCpPm0tDTY29uX9pAKxJZSRERERKVz+7bYiwUAhg5Va1FU8Ya94qnrnOfkAE+fAqmpxZvu3SvaTa+lJVC1KmBoWL6Tnl7Rn55r0nWSkwNkZ4vBicI+X7wAxozJ/4YdAD75BKhW7dX50NFR/2dODjBhQsGBhgkTgHbtxGUKxavp5UvV+YqcihrY6dRJvMZLEjxSt+3b1V2C4lGe8+PHgQ4dKmSXWhWUat26NbZu3Yr09HSYmJgAAP7991/o6OigVq1aeW6jUChw7do1dOvWDQDg5OQEGxsbRERESEGotLQ0nD17FmPGjMl333K5HHK5vGwPKB/K/+sZlCIiIiIqneXLxfuSzp2Bd95Rd2n+R5Nu2ItDm1vulPScFzeglJKSe9nTp+VbsX/yRJzKm45O0YJXcjmwa1fBgZ2hQ8Wb3uIEjErymZ1d9uf+v//EIIk2EQTxWre0VHdJSubYsbLLSy4H9PVLPyUnA7//Xvj+BgwQg9/qCvy9Ob14IU6FSUws/bkuIrUGpdLT06UWTIA4CHlkZCSqV6+O2rVrY+rUqbh37x7Wr18PABgwYADmzZuHYcOGYc6cOXj48CEmT56M4cOHw9DQEAAwd+5cvPPOO6hTpw5SUlKwePFi3LlzByNHjgQgvpkvMDAQ8+fPR926deHk5IQZM2bAzs4OPXv2rPBzkBd23yMiIiIqG5cvi5+DBqm3HJLCAjsAMGIEEBcnzqv7Bub1KT1dvBHLj/IJu6MjYGqq/m4qykkmA2bPLvicDxoErF4NpKWVX0BJTw8wNxdbfJibFz7FxRVtELRffgEaNgSePy+fSXn8OTlARoY4ldbTp8DSpaXPp6RkMvH7qFJF9TMrC3j8uPDtbW0BExPx3OTklO9neSmLf1tVqpRu++Rk4I8/Ci/rZ5+J13hpA0nK/w/KgkIBnDolBvvy+p5kMjEYtX69ZgXpjxwRBzUvzGu9ysqbWoNSFy5cQMfXToiye9yQIUMQEhKCxMRExMfHS+tNTEwQHh6O8ePHo1mzZrCwsEC/fv0wf/58Kc2TJ08watQoJCUloVq1avDy8sKpU6dQv359Kc0XX3yBjIwMjB49GikpKWjTpg32798PAw17NzBbShERERGVXE4OcPWq+LeHh3rLIjl+vODuKoDY2mbixAopTrko7Pg00bNnwL59+a/X1y9aIKmgycCgeDfECoXYtbCwm95hw8rvplcQxEBNfgGrZ89yLzt1CggNLTzv994TX4X5emDozSBReX3q5PMS+qLesIeGVljXJghC4cGrY8fE81mY8HCxlVd+x1/RFAoxiF3YNf7tt5oV2AHE8vzwg9jSUiZTLb/y3/nSpZpX7rZtxXNa2Dlv27bCiiQTBIY+SiItLQ3m5uZITU2FmZlZmeYtl4v/98fHA+U8bBURkcZ78eIFYmNj4eTkpHEPD6jyKOg6K8/f/LdNRZ/LffuAbt3ERjv//SfWsdRu82axO0dhvL0BZ+eKbVFUWKuHyEhxgNzC/PCDGAWsiNZbRRkPJzYWOHu28HKPGgX4+uYfUFIHZbdDIO+bXk3s6lnUwM7hwxUX2CmqogZJYmM1K9igreUGtPMaf11eY9XZ24sBKU0tdwWd86L+5mvVmFJvC3bfIyIipQ4dOqBx48ZY+r9uDo6OjggMDERgYGC+28hkMuzcubPU3dLLKh8idfnfCBAYPlxDAlJA0btEfPON5t2wt2wJBAcXfuM7dqxm3fgWNUgyYIDmnfPevcUbxLwGaNfUm14NbIlRZNra+kVbyw1o5zX+ut69xXH0tOWtnoDGnXMNabdHeWEbNiKiMqZQiDcnmzeLnwpFue3K398fXbt2zXPd8ePHIZPJcFXZr6gYzp8/j9GjR5e2eCpmz56d5xtoExMT4efnV6b7elNISAiqVq1arvugt5MgAHv3in8HBKi3LCqUN+z5PYWUycSn7Jp8ww7kLr8m3/hq8zkHxBvEuDixZVFoqPgZG6u5N+vaep0oKW/Ya9ZUXV6rlma32tHWcgPad42/SVdXDGgHBIifmnptv06DzjlbSmkgvn2PiKgcVPCrwEeMGIE+ffogISEh1xti165di2bNmsGjBIPcWFbgm3NsbGwqbF9EZS0xURyzWlcXaNpU3aV5jTa3aAA07gl7kWj7OQde3fRqC228Tl6nja1fAO0tN6B913hloCHnnC2lNBC77xERlTFl3/k3B99Vvgp8x44y3+V7770HS0tLhISEqCxPT0/H1q1bMWLECDx69AgBAQGoWbMmjIyM0KhRI2zevLnAfB0dHaWufABw69YttGvXDgYGBqhfvz7Cw8NzbTNlyhTUq1cPRkZGcHZ2xowZM5CdnQ1AbKk0Z84cXLlyBTKZDDKZTCqzTCZDWFiYlM+1a9fQqVMnGBoawsLCAqNHj0Z6erq0fujQoejZsyeWLFkCW1tbWFhYYOzYsdK+SiI+Ph49evSAiYkJzMzM0K9fPyS/9vavK1euoGPHjjA1NYWZmRm8vLxw4cIFAMCdO3fg7++PatWqwdjYGA0aNMBeZdMZqvT+/Vf8dHQUxzXWKNrcogHQqCfsRabt51wbaeN18jptbP0CaG+56a3FllIajC2liIjyIQjiG3+KQqEAJkzI/1XgMpn4JNfHp/CKm5FRkZ8cVKlSBYMHD0ZISAimTZsG2f+227p1KxQKBQICApCeng4vLy9MmTIFZmZm2LNnDwYNGgQXFxe0aNGi0H3k5OSgd+/esLa2xtmzZ5GamprnWFOmpqYICQmBnZ0drl27hlGjRsHU1BRffPEFPvzwQ1y/fh379+/HoUOHAADm5ua58sjIyICvry+8vb1x/vx5PHjwACNHjsS4ceNUAm+HDx+Gra0tDh8+jOjoaHz44Ydo3LgxRo0aVaTz9ubxKQNSR48excuXLzF27Fh8+OGHOHLkCABg4MCBaNKkCVauXAldXV1ERkZC738RiLFjxyIrKwvHjh2DsbExbty4ARMTk2KXg7TTzZviZ9266i1HvrS5RQOgMU/Yi0Xbz7k20sbrhIgqFINSGogtpYiICvHsGVBWwQVBEFtQ5RGIySU9HTA2LnLWw4cPx+LFi3H06FF0+F+lfO3atejTpw/Mzc1hbm6OSZMmSenHjx+PAwcO4Pfffy9SUOrQoUP4559/cODAAdjZ2QEAvvnmm1zjQE2fPl3629HREZMmTcJvv/2GL774AoaGhjAxMUGVKlUK7K4XGhqKFy9eYP369TD+3zlYsWIF/P39sXDhQlhbWwMAqlWrhhUrVkBXVxdubm7o3r07IiIiShSUioiIwLVr1xAbGwv7/72Odv369WjQoAHOnz+P5s2bIz4+HpMnT4abmxsAoO5rEYj4+Hj06dMHjRo1AgA4OzsXuwykvQ4fFj9btlRvOQrEG/aKx3NORKRR2H1Pg7GlFBGRdnNzc0OrVq3w66+/AgCio6Nx/PhxjBgxAgCgUCgwb948NGrUCNWrV4eJiQkOHDiA+Pj4IuV/8+ZN2NvbSwEpAPD29s6VbsuWLWjdujVsbGxgYmKC6dOnF3kfr+/L09NTCkgBQOvWrZGTk4OoqChpWYMGDaD7WqsDW1tbPHjwoFj7en2f9vb2UkAKAOrXr4+qVavi5v+awQQFBWHkyJHw8fHBggULEBMTI6WdMGEC5s+fj9atW2PWrFklGlietNeJE+Jnly7qLQcRERHlj0EpDcSBzomICmFkJLZaKspU1DGE9u4tPC8jo2IXdcSIEdi+fTuePn2KtWvXwsXFBe3btwcALF68GD/88AOmTJmCw4cPIzIyEr6+vsjKyir2fvJz+vRpDBw4EN26dcOff/6Jy5cvY9q0aWW6j9fpvTF4j0wmQ05OTrnsCxDfHPj333+je/fu+Ouvv1C/fn3s3LkTADBy5Ejcvn0bgwYNwrVr19CsWTMsX7683MpCmiMlReydBQAleJ8AERERVRAGpTQQu+8RERVCJhO70RVlevfdor0K/N13C8+rBP9B9+vXDzo6OggNDcX69esxfPhwaXypkydPokePHvjoo4/g6ekJZ2dn/KscnbkI3N3dcffuXSQq774BnDlzRiXNqVOn4ODggGnTpqFZs2aoW7cu7ty5o5JGX18fCoWi0H1duXIFGRkZ0rKTJ09CR0cHrq6uRS5zcSiP7+7du9KyGzduICUlBfXr15eW1atXD59//jkOHjyI3r17Y+3atdI6e3t7fPLJJ9ixYwcmTpyIX375pVzKSppF2XivZk3A1FS9ZSEiIqL8MSilwdhSioioDChfBQ7kDipVwKvATUxM8OGHH2Lq1KlITEzE0KFDpXV169ZFeHg4Tp06hZs3b+Ljjz9WebNcYXx8fFCvXj0MGTIEV65cwfHjxzFt2jSVNHXr1kV8fDx+++03xMTEYNmyZVJLIiVHR0fExsYiMjISDx8+RGZmZq59DRw4EAYGBhgyZAiuX7+Ow4cPY/z48Rg0aJA0nlRJKRQKREZGqkw3b96Ej48PGjVqhIEDB+LSpUs4d+4cBg8ejPbt26NZs2Z4/vw5xo0bhyNHjuDOnTs4efIkzp8/D3d3dwBAYGAgDhw4gNjYWFy6dAmHDx+W1lHl9s8/4uf/hhojIiIiDcWglAZi9z0iojKm5leBjxgxAk+ePIGvr6/K+E/Tp09H06ZN4evriw4dOsDGxgY9e/Yscr46OjrYuXMnnj9/jhYtWmDkyJH4+uuvVdK8//77+PzzzzFu3Dg0btwYp06dwowZM1TS9OnTB127dkXHjh1haWmJzZs359qXkZERDhw4gMePH6N58+bo27cvOnfujBUrVhTvZOQhPT0dTZo0UZn8/f0hk8mwa9cuVKtWDe3atYOPjw+cnZ2xZcsWAICuri4ePXqEwYMHo169eujXrx/8/PwwZ84cAGKwa+zYsXB3d0fXrl1Rr149/PTTT6UuL2k+5Zv3GJQiIiLSbDJBYOijJNLS0mBubo7U1FSYmZmVad7m5kBaGnDrFlCnTplmTUSkdV68eIHY2Fg4OTnBwMCgdJkpFHwVOOWpoOusPH/z3zYVdS579gR27QKWLwfGjSu33RAREVE+ivqbX6UCy0TFxHAhEVEZ46vAid4Kt2+Ln3y4R0REpNnYfU8DcaBzIiIiopJ78ED8tLFRbzmIiIioYAxKaTC2lCIiIiIqnpwc4OFD8W9LS/WWhYiIiArGoJQG4kDnREREVFpPnz5FYGAgHBwcYGhoiFatWuH8+fPSeplMlue0ePHifPOcPXt2rvRuGjaa+JMn4vBxAINSREREmo5jSmkgdt8jIiKi0ho5ciSuX7+ODRs2wM7ODhs3boSPjw9u3LiBmjVrIjExUSX9vn37MGLECPTp06fAfBs0aIBDhw5J81WqaFZ18r//xE9zc0BfX71lISIiooJpVi2CVLClFBHRKzk5OeouAlVile36ev78ObZv345du3ahXbt2AMRWTn/88QdWrlyJ+fPnw+aNAZd27dqFjh07wtnZucC8q1SpkmtbTaIMSrGVFBERkeZjUEoDsfseEdEr+vr60NHRwf3792FpaQl9fX3I2KSUyoggCMjKysJ///0HHR0d6FeSpjUvX76EQqGAgYGBynJDQ0OcOHEiV/rk5GTs2bMH69atKzTvW7duwc7ODgYGBvD29kZwcDBq166dZ9rMzExkZmZK82lpacU8kuJTBqWsrMp9V0RERFRKDEppIN5rERG9oqOjAycnJyQmJuL+/fvqLg5VUkZGRqhduzZ0dCrHcJumpqbw9vbGvHnz4O7uDmtra2zevBmnT59GnTp1cqVft24dTE1N0bt37wLzbdmyJUJCQuDq6orExETMmTMHbdu2xfXr12FqaporfXBwMObMmVNmx1UUyjfvsaUUERGR5mNQSoOxpRQRkUhfXx+1a9eWWn8QlSVdXV1UqVKl0rXA27BhA4YPH46aNWtCV1cXTZs2RUBAAC5evJgr7a+//oqBAwfmaln1Jj8/P+lvDw8PtGzZEg4ODvj9998xYsSIXOmnTp2KoKAgaT4tLQ329valOKrCsfseERGR9mBQSgNVsjoxEVGZkMlk0NPTg56enrqLQqQVXFxccPToUWRkZCAtLQ22trb48MMPc40Zdfz4cURFRWHLli3F3kfVqlVRr149REdH57leLpdDLpeXqPwlxaAUERGR9qgcbdQrKbaUIiIiotIyNjaGra0tnjx5ggMHDqBHjx4q69esWQMvLy94enoWO+/09HTExMTA1ta2rIpbahxTioiISHswKKWBONA5ERERldaBAwewf/9+xMbGIjw8HB07doSbmxuGDRsmpUlLS8PWrVsxcuTIPPPo3LkzVqxYIc1PmjQJR48eRVxcHE6dOoVevXpBV1cXAQEB5X48RfXwofhZo4Z6y0FERESFU2tQ6tixY/D394ednR1kMhnCwsIK3SYzMxPTpk2Dg4MD5HI5HB0d8euvv0rrf/nlF7Rt2xbVqlVDtWrV4OPjg3PnzqnkMXToUMhkMpWpa9euZX14Jcbue0RERFRaqampGDt2LNzc3DB48GC0adMGBw4cUOkC+9tvv0EQhHyDSjExMXiojPIASEhIQEBAAFxdXdGvXz9YWFjgzJkzsNSgvnJPn4qfZmbqLQcREREVTq1jSmVkZMDT0xPDhw8v9G0vSv369UNycjLWrFmDOnXqIDExETk5OdL6I0eOICAgAK1atYKBgQEWLlyId999F3///Tdq1qwppevatSvWrl0rzVf0eAdFwZZSREREVFL9+vVDv379CkwzevRojB49Ot/1cXFxKvO//fZbWRStXCmDUnm8DJCIiIg0jFqDUn5+fipvcSnM/v37cfToUdy+fRvVq1cHADg6Oqqk2bRpk8r86tWrsX37dkRERGDw4MHScrlcDhsbm5IXvhyx+x4RERFRySiDUiYm6i0HERERFU6rxpTavXs3mjVrhkWLFqFmzZqoV68eJk2ahOfPn+e7zbNnz5CdnS0FsZSOHDkCKysruLq6YsyYMXj06FF5F7/I2H2PiIiIqGTS08VPtpQiIiLSfGptKVVct2/fxokTJ2BgYICdO3fi4cOH+PTTT/Ho0SOVrnivmzJlCuzs7ODj4yMt69q1K3r37g0nJyfExMTgq6++gp+fH06fPg1dXd0888nMzERmZqY0n5aWVrYHlwe2lCIiIiIqOkFgSykiIiJtolVBqZycHMhkMmzatAnm5uYAgO+++w59+/bFTz/9BENDQ5X0CxYswG+//YYjR47AwMBAWt6/f3/p70aNGsHDwwMuLi44cuQIOnfunOe+g4ODMWfOnHI4qtzYfY+IiIio+LKygJcvxb/ZUoqIiEjzaVX3PVtbW9SsWVMKSAGAu7s7BEFAQkKCStolS5ZgwYIFOHjwIDw8PArM19nZGTVq1EB0dHS+aaZOnYrU1FRpunv3bukOhoiIiIjKlLKVFAAYG6uvHERERFQ0WhWUat26Ne7fv4905WABAP7991/o6OigVq1a0rJFixZh3rx52L9/P5o1a1ZovgkJCXj06BFsbW3zTSOXy2FmZqYylRe2lCIiIiIqPmUV0dAQqKJV/QGIiIjeTmoNSqWnpyMyMhKRkZEAgNjYWERGRiI+Ph6A2Drp9TfmDRgwABYWFhg2bBhu3LiBY8eOYfLkyRg+fLjUdW/hwoWYMWMGfv31Vzg6OiIpKQlJSUlSICs9PR2TJ0/GmTNnEBcXh4iICPTo0QN16tSBr69vxZ6AfHCgcyIiIqLi43hSRERE2kWtQakLFy6gSZMmaNKkCQAgKCgITZo0wcyZMwEAiYmJUoAKAExMTBAeHo6UlBQ0a9YMAwcOhL+/P5YtWyalWblyJbKystC3b1/Y2tpK05IlSwAAurq6uHr1Kt5//33Uq1cPI0aMgJeXF44fPw65XF6BR184tpQiIiIiKrqMDPGTXfeIiIi0g1obNnfo0AFCAZGXkJCQXMvc3NwQHh6e7zZxcXEF7tPQ0BAHDhwoahHVgt33iIiIiIrv+XPx08hIveUgIiKiotGqMaXeFuy+R0RERFR8z56Jn2+8kJmIiIg0FINSGowtpYiIiIiKTtlSikEpIiIi7cCglAZi9z0iIiKi4mP3PSIiIu3CoJQGYvc9IiIiouJj9z0iIiLtwqCUBmNLKSIiIqKiY0spIiIi7cKglAZiSykiIiKi4mNLKSIiIu3CoJQGY0spIiIioqLjQOdERETahUEpDcSBzomIiIiKT9lSit33iIiItAODUhqI3feIiIiIio8tpYiIiLQLg1IajC2liIiIiIqOLaWIiIi0C4NSGojd94iIiIiK78UL8dPAQL3lICIioqJhUEoDsfseERERUfFlZ4uf+vrqLQcREREVDYNSGowtpYiIiIiKThmUqlJFveUgIiKiomFQSgOxpRQRERFR8b18KX7q6am3HERERFQ0DEppMLaUIiIiIio6tpQiIiLSLgxKaSAOdE5ERERUfGwpRUREpF0YlNJA7L5HREREVHxsKUVERKRdGJTSYGwpRURERFR0bClFRESkXRiU0kDsvkdERERUfMqgFFtKERERaQcGpTQQu+8RERERFZ+y+x5bShEREWkHBqU0GFtKERERERUdW0oRERFpFwalNBBbShEREVFpPX36FIGBgXBwcIChoSFatWqF8+fPS+uHDh0KmUymMnXt2rXQfH/88Uc4OjrCwMAALVu2xLlz58rzMIqFLaWIiIi0C4NSGowtpYiIiKikRo4cifDwcGzYsAHXrl3Du+++Cx8fH9y7d09K07VrVyQmJkrT5s2bC8xzy5YtCAoKwqxZs3Dp0iV4enrC19cXDx48KO/DKRK2lCIiItIuDEppIA50TkRERKXx/PlzbN++HYsWLUK7du1Qp04dzJ49G3Xq1MHKlSuldHK5HDY2NtJUrVq1AvP97rvvMGrUKAwbNgz169fHqlWrYGRkhF9//bW8D6lIlC2lGJQiIiLSDmoNSh07dgz+/v6ws7ODTCZDWFhYodtkZmZi2rRpcHBwgFwuh6OjY66K0NatW+Hm5gYDAwM0atQIe/fuVVkvCAJmzpwJW1tbGBoawsfHB7du3SrLQysVdt8jIiKi0nj58iUUCgUMDAxUlhsaGuLEiRPS/JEjR2BlZQVXV1eMGTMGjx49yjfPrKwsXLx4ET4+PtIyHR0d+Pj44PTp03luk5mZibS0NJWpPClbSrH7HhERkXZQa1AqIyMDnp6e+PHHH4u8Tb9+/RAREYE1a9YgKioKmzdvhqurq7T+1KlTCAgIwIgRI3D58mX07NkTPXv2xPXr16U0ixYtwrJly7Bq1SqcPXsWxsbG8PX1xYsXL8r0+EqLLaWIiIioJExNTeHt7Y158+bh/v37UCgU2LhxI06fPo3ExEQAYte99evXIyIiAgsXLsTRo0fh5+cHhUKRZ54PHz6EQqGAtbW1ynJra2skJSXluU1wcDDMzc2lyd7evmwP9A1sKUVERKRdZIKgGaEPmUyGnTt3omfPnvmm2b9/P/r374/bt2+jevXqeab58MMPkZGRgT///FNa9s4776Bx48ZYtWoVBEGAnZ0dJk6ciEmTJgEAUlNTYW1tjZCQEPTv379I5U1LS4O5uTlSU1NhZmZW9AMtAg8P4No1IDwceO1hJBEREalBef7ml6eYmBgMHz4cx44dg66uLpo2bYp69erh4sWLuHnzZq70t2/fhouLCw4dOoTOnTvnWn///n3UrFkTp06dgre3t7T8iy++wNGjR3H27Nlc22RmZiIzM1OaT0tLg729fbmdy6pVgdRUICoKqFevzLMnIiKiIipq/UmrxpTavXs3mjVrhkWLFqFmzZqoV68eJk2ahOfPn0tpTp8+rdKsHAB8fX2lZuWxsbFISkpSSWNubo6WLVvm2/S8orH7HhEREZWWi4sLjh49ivT0dNy9exfnzp1DdnY2nJ2d80zv7OyMGjVqIDo6Os/1NWrUgK6uLpKTk1WWJycnw8bGJs9t5HI5zMzMVKbyxIHOiYiItItWBaVu376NEydO4Pr169i5cyeWLl2Kbdu24dNPP5XSJCUlFdisXPlZnKbnQMWPiQCw+x4RERGVnrGxMWxtbfHkyRMcOHAAPXr0yDNdQkICHj16BFtb2zzX6+vrw8vLCxEREdKynJwcREREqLScUidl9z2OKUVERKQdtCoolZOTA5lMhk2bNqFFixbo1q0bvvvuO6xbt06ltVR5qMgxEfj2PSIiIiqtAwcOYP/+/YiNjUV4eDg6duwINzc3DBs2DOnp6Zg8eTLOnDmDuLg4REREoEePHqhTpw58fX2lPDp37owVK1ZI80FBQfjll1+wbt063Lx5E2PGjEFGRgaGDRumjkPMhS2liIiItItWBaVsbW1Rs2ZNmJubS8vc3d0hCAISEhIAADY2NgU2K1d+FqfpOQBMnToVqamp0nT37t0yOaa8sPseERERlVZqairGjh0LNzc3DB48GG3atMGBAwegp6cHXV1dXL16Fe+//z7q1auHESNGwMvLC8ePH4dcLpfyiImJwcOHD6X5Dz/8EEuWLMHMmTPRuHFjREZGYv/+/blaoKtDTo44AWwpRUREpC206jlS69atsXXrVqSnp8PExAQA8O+//0JHRwe1atUCAHh7eyMiIgKBgYHSduHh4VKzcicnJ9jY2CAiIgKNGzcGIA7AdfbsWYwZMybffcvlcpVKWkVgSykiIiIqqX79+qFfv355rjM0NMSBAwcKzSMuLi7XsnHjxmHcuHGlLV6ZU7aSAthSioiISFuotaVUeno6IiMjERkZCUAchDwyMhLx8fEAxNZJgwcPltIPGDAAFhYWGDZsGG7cuIFjx45h8uTJGD58OAwNDQEAn332Gfbv349vv/0W//zzD2bPno0LFy5IlSeZTIbAwEDMnz8fu3fvxrVr1zB48GDY2dkV+Oa/isSWUkRERETFoxxPCmBLKSIiIm2h1udIFy5cQMeOHaX5oKAgAMCQIUMQEhKCxMREKUAFACYmJggPD8f48ePRrFkzWFhYoF+/fpg/f76UplWrVggNDcX06dPx1VdfoW7duggLC0PDhg2lNF988QUyMjIwevRopKSkoE2bNti/fz8MDAwq4KiLji2liIiIiIqGLaWIiIi0j0wQGPooibS0NJibmyM1NbXMX2/s5QVcugTs3Qv4+ZVp1kRERFRM5fmb/7Ypz3P56BFQo4b4t0IB6GjVyKlERESVS1F/8/lzrYHYfY+IiIioeJTd92QyBqSIiIi0BX+yNRjbsBEREREVjbL7HseTIiIi0h4MSmkgZUspBqWIiIiIikahED/ZSoqIiEh78GdbA7H7HhEREVHxKB/msR5FRESkPRiU0mBsKUVERERUPAxKERERaQ8GpTQQK1NERERExcOHeURERNqHQSkNxsoVERERUdGw+x4REZH2YVBKA3GgcyIiIqKSYVCKiIhIezAopYFYmSIiIiIqHj7MIyIi0j4MSmkwVq6IiIiIiobd94iIiLQPg1IaiN33iIiIiEqGQSkiIiLtwaCUBmJlioiIiKh4+DCPiIhI+zAopcFYuSIiIiIqGnbfIyIi0j4MSmkgVqaIiIiISob1KCIiIu3BoJQGY0spIiIioqJhvYmIiEj7MCilgTjQOREREVHJsKUUERGR9mBQSgOxMkVERERUPHyYR0REpH0YlNJgrFwRERERFQ0HOiciItI+DEppIHbfIyIiIioZBqWIiIi0B4NSGoiVKSIiosrH0dERc+fORXx8vLqLUinxYR4REZH2YVBKg7FyRUREVHkEBgZix44dcHZ2RpcuXfDbb78hMzNT3cWqNNh9j4iISPswKKWB2H2PiIio8gkMDERkZCTOnTsHd3d3jB8/Hra2thg3bhwuXbqk7uJVGgxKERERaQ8GpYiIiIgqUNOmTbFs2TLcv38fs2bNwurVq9G8eXM0btwYv/76KwQ+lSoRnjYiIiLtU0XdBaDc2FKKiIio8srOzsbOnTuxdu1ahIeH45133sGIESOQkJCAr776CocOHUJoaKi6i6l12H2PiIhI+6i1pdSxY8fg7+8POzs7yGQyhIWFFZj+yJEjkMlkuaakpCQpjaOjY55pxo4dK6Xp0KFDrvWffPJJeR1msbEyRUREVPlcunRJpctegwYNcP36dZw4cQLDhg3DjBkzcOjQIezcuVPdRdVqrEcRERFpD7W2lMrIyICnpyeGDx+O3r17F3m7qKgomJmZSfNWVlbS3+fPn4dCoZDmr1+/ji5duuCDDz5QyWPUqFGYO3euNG9kZFSSQyhXbClFRERUeTRv3hxdunTBypUr0bNnT+jp6eVK4+TkhP79+6uhdNqP9SYiIiLto9aWUn5+fpg/fz569epVrO2srKxgY2MjTTo6rw7D0tJSZd2ff/4JFxcXtG/fXiUPIyMjlXSvB7nUjd33iIiIKp/bt29j//79+OCDD/IMSAGAsbEx1q5dWyb7e/r0KQIDA+Hg4ABDQ0O0atUK58+fByB2IZwyZQoaNWoEY2Nj2NnZYfDgwbh//36Bec6ePTtXa3M3N7cyKW9ZYUspIiIi7aGVA503btwYtra26NKlC06ePJlvuqysLGzcuBHDhw+H7I0ayqZNm1CjRg00bNgQU6dOxbNnz8q72EXGyhQREVHl8+DBA5w9ezbX8rNnz+LChQtlvr+RI0ciPDwcGzZswLVr1/Duu+/Cx8cH9+7dw7Nnz3Dp0iXMmDEDly5dwo4dOxAVFYX333+/0HwbNGiAxMREaTpx4kSZl70k+DCPiIhI+2jVQOe2trZYtWoVmjVrhszMTKxevRodOnTA2bNn0bRp01zpw8LCkJKSgqFDh6osHzBgABwcHGBnZ4erV69iypQpiIqKwo4dO/Ldd2ZmJjIzM6X5tLS0Mjuu/LByRUREVHmMHTsWX3zxBVq2bKmy/N69e1i4cGGeAauSev78ObZv345du3ahXbt2AMRWTn/88QdWrlyJ+fPnIzw8XGWbFStWoEWLFoiPj0ft2rXzzbtKlSqwsbEps7KWFQ50TkREpH20Kijl6uoKV1dXab5Vq1aIiYnB999/jw0bNuRKv2bNGvj5+cHOzk5l+ejRo6W/GzVqBFtbW3Tu3BkxMTFwcXHJc9/BwcGYM2dOGR1Jwdh9j4iIqPK5ceNGng/RmjRpghs3bpTpvl6+fAmFQgEDAwOV5YaGhvm2bEpNTYVMJkPVqlULzPvWrVuws7ODgYEBvL29ERwcXGAQq6IxKEVERKQ9tLL73utatGiB6OjoXMvv3LmDQ4cOYeTIkYXmoXximVc+SlOnTkVqaqo03b17t+SFLgQrU0RERJWPXC5HcnJyruWJiYmoUqVsnxOamprC29sb8+bNw/3796FQKLBx40acPn0aiYmJudK/ePECU6ZMQUBAQIHjbLZs2RIhISHYv38/Vq5cidjYWLRt2xZPnz7NM31mZibS0tJUpvLCh3lERETaR+uDUpGRkbC1tc21fO3atbCyskL37t2LlAeAPPNRksvlMDMzU5nKGytXRERElce7774rPeRSSklJwVdffYUuXbqU+f42bNgAQRBQs2ZNyOVyLFu2DAEBASoviAHEQc/79esHQRCwcuXKAvP08/PDBx98AA8PD/j6+mLv3r1ISUnB77//nmf64OBgmJubS5O9vX2ZHd+b2H2PiIhI+6i1+156erpK66TY2FhERkaievXqqF27NqZOnYp79+5h/fr1AIClS5fCyckJDRo0wIsXL7B69Wr89ddfOHjwoEq+OTk5WLt2LYYMGZLryWNMTAxCQ0PRrVs3WFhY4OrVq/j888/Rrl07eHh4lP9BFwErU0RERJXPkiVL0K5dOzg4OKBJkyYAxAdj1tbWeQ5DUFouLi44evQoMjIykJaWBltbW3z44YdwdnaW0igDUnfu3MFff/1V7IduVatWRb169fJtbT516lQEBQVJ82lpaeUamAJYjyIiItImag1KXbhwAR07dpTmlZWWIUOGICQkBImJiYiPj5fWZ2VlYeLEibh37x6MjIzg4eGBQ4cOqeQBAIcOHUJ8fDyGDx+ea5/6+vo4dOgQli5dioyMDNjb26NPnz6YPn16OR1lybGlFBERUeVRs2ZNXL16FZs2bcKVK1dgaGiIYcOGISAgAHp6euW2X2NjYxgbG+PJkyc4cOAAFi1aBOBVQOrWrVs4fPgwLCwsip13eno6YmJiMGjQoDzXy+VyyOXyUpW/qFhvIiIi0j4yQeBPeEmkpaXB3NwcqampZd6Vz88P2L8fCAkBhgwp06yJiIiomMrzN788HThwAIIgwNXVFdHR0Zg8eTIMDAxw/PhxAEDfvn1x6dIl/Pnnn7C2tpa2q169OvT19QEAnTt3Rq9evTBu3DgAwKRJk+Dv7w8HBwfcv38fs2bNQmRkJG7cuAFLS8tCy1Se5/LCBaB5c8DeHnjtmSYRERGpQVF/87Xq7XtvCzY7JyIiqrxu3LiB+Ph4ZGVlqSx///33y3Q/qampmDp1KhISElC9enX06dMHX3/9NfT09BAXF4fdu3cDABo3bqyy3eHDh9GhQwcA4rAHDx8+lNYlJCQgICAAjx49gqWlJdq0aYMzZ84UKSBVUViPIiIi0h4MSmkwtmEjIiKqPG7fvo1evXrh2rVrkMlkUDZWl/0viqJQKMp0f/369UO/fv3yXOfo6IiiNJaPi4tTmf/tt9/KomjlgvUmIiIi7VOit+/dvXsXCQkJ0vy5c+cQGBiI//u//yuzgr3NlE/4WLkiIiKqPD777DM4OTnhwYMHMDIywt9//41jx46hWbNmOHLkiLqLp/X49j0iIiLtU6Kg1IABA3D48GEAQFJSErp06YJz585h2rRpmDt3bpkW8G3EyhQREVHlc/r0acydOxc1atSAjo4OdHR00KZNGwQHB2PChAnqLl6lwXoUERGR9ihRUOr69eto0aIFAOD3339Hw4YNcerUKWzatAkhISFlWb63GltKERERVR4KhQKmpqYAgBo1auD+/fsAAAcHB0RFRamzaJUC601ERETap0RjSmVnZ0uv9z106JA0MKebmxsSExPLrnRvKT7hIyIiqnwaNmyIK1euwMnJCS1btsSiRYugr6+P//u//4Ozs7O6i1dpsB5FRESkPUrUUqpBgwZYtWoVjh8/jvDwcHTt2hUAcP/+fVhYWJRpAd9mfOJHRERUeUyfPh05OTkAgLlz5yI2NhZt27bF3r17sWzZMjWXTvux3kRERKR9StRSauHChejVqxcWL16MIUOGwNPTEwCwe/duqVsflRwHOiciIqp8fH19pb/r1KmDf/75B48fP0a1atWkN/BRyXGgcyIiIu1ToqBUhw4d8PDhQ6SlpaFatWrS8tGjR8PIyKjMCve2YmWKiIiocsnOzoahoSEiIyPRsGFDaXn16tXVWKrKifUoIiIi7VGi7nvPnz9HZmamFJC6c+cOli5diqioKFhZWZVpAd9mbClFRERUOejp6aF27dpQKBTqLkqlxXoTERGR9ilRUKpHjx5Yv349ACAlJQUtW7bEt99+i549e2LlypVlWsC3EbvvERERVT7Tpk3DV199hcePH6u7KJUSu+8RERFpnxIFpS5duoS2bdsCALZt2wZra2vcuXMH69ev50CdZYCVKSIiospnxYoVOHbsGOzs7ODq6oqmTZuqTFQ2WI8iIiLSHiUaU+rZs2cwNTUFABw8eBC9e/eGjo4O3nnnHdy5c6dMC/g2Y0spIiKiyqNnz57qLkKlxnoTERGR9ilRUKpOnToICwtDr169cODAAXz++ecAgAcPHsDMzKxMC/g24hM+IiKiymfWrFnqLkKlxu57RERE2qdE3fdmzpyJSZMmwdHRES1atIC3tzcAsdVUkyZNyrSAbzM+8SMiIiIqHgaliIiItEeJWkr17dsXbdq0QWJiIjw9PaXlnTt3Rq9evcqscG8rDnRORERU+ejo6EBWQMSEb+YrHdabiIiItE+JglIAYGNjAxsbGyQkJAAAatWqhRYtWpRZwd5mfMJHRERU+ezcuVNlPjs7G5cvX8a6deswZ84cNZWq8mE9ioiISHuUKCiVk5OD+fPn49tvv0V6ejoAwNTUFBMnTsS0adOgo1OiXoH0Bj7xIyIiqjx69OiRa1nfvn3RoEEDbNmyBSNGjFBDqSoP1puIiIi0T4mCUtOmTcOaNWuwYMECtG7dGgBw4sQJzJ49Gy9evMDXX39dpoV827D7HhER0dvjnXfewejRo9VdDK3Hgc6JiIi0T4mCUuvWrcPq1avx/vvvS8s8PDxQs2ZNfPrppwxKlRIrU0RERG+H58+fY9myZahZs6a6i1JpsB5FRESkPUoUlHr8+DHc3NxyLXdzc8Pjx49LXSgSsaUUERFR5VGtWjWVgc4FQcDTp09hZGSEjRs3qrFklQPrTURERNqnREEpT09PrFixAsuWLVNZvmLFCnh4eJRJwd5m7L5HRERU+Xz//fcqQSkdHR1YWlqiZcuWqFatmhpLVjmw+x4REZH2KVFQatGiRejevTsOHToEb29vAMDp06dx9+5d7N27t0wL+DZiZYqIiKjyGTp0qLqL8FZgPYqIiEh7lOg1ee3bt8e///6LXr16ISUlBSkpKejduzf+/vtvbNiwoazL+NZiSykiIqLKY+3atdi6dWuu5Vu3bsW6devUUKLKhfUmIiIi7VOioBQA2NnZ4euvv8b27duxfft2zJ8/H0+ePMGaNWuKnMexY8fg7+8POzs7yGQyhIWFFZj+yJEjkMlkuaakpCQpzezZs3Otf3P8qxcvXmDs2LGwsLCAiYkJ+vTpg+Tk5GIdf3niEz4iIqLKJzg4GDVq1Mi13MrKCt98840aSlS5sPseERGR9ilxUKosZGRkwNPTEz/++GOxtouKikJiYqI0WVlZqaxv0KCByvoTJ06orP/888/xxx9/YOvWrTh69Cju37+P3r17l/p4yhqf+BEREVUe8fHxcHJyyrXcwcEB8fHxaihR5cSgFBERkfYo0ZhSZcXPzw9+fn7F3s7KygpVq1bNd32VKlVgY2OT57rU1FSsWbMGoaGh6NSpEwCxOb27uzvOnDmDd955p9jlKWsc6JyIiKjysbKywtWrV+Ho6Kiy/MqVK7CwsFBPoSoR1puIiIi0j1pbSpVU48aNYWtriy5duuDkyZO51t+6dQt2dnZwdnbGwIEDVZ4+Xrx4EdnZ2fDx8ZGWubm5oXbt2jh9+nSFlL8wfMJHRERU+QQEBGDChAk4fPgwFAoFFAoF/vrrL3z22Wfo37+/uoun9dh9j4iISPsUq6VUYV3cUlJSSlOWQtna2mLVqlVo1qwZMjMzsXr1anTo0AFnz55F06ZNAQAtW7ZESEgIXF1dkZiYiDlz5qBt27a4fv06TE1NkZSUBH19/VwtraytrVXGpnpTZmYmMjMzpfm0tLRyOcbX8YkfERFR5TFv3jzExcWhc+fOqFJFrILl5ORg8ODBHFOqDDEoRUREpD2KFZQyNzcvdP3gwYNLVaCCuLq6wtXVVZpv1aoVYmJi8P3330tv/Xu9O6CHhwdatmwJBwcH/P777xgxYkSJ9x0cHIw5c+aUvPDFwO57RERElY++vj62bNmC+fPnIzIyEoaGhmjUqBEcHBzUXbRKgfUmIiIi7VOsoNTatWvLqxwl1qJFi1wDmb+uatWqqFevHqKjowEANjY2yMrKQkpKikprqeTk5HzHoQKAqVOnIigoSJpPS0uDvb196Q8gD3zCR0REVHnVrVsXdevWVXcxKi3Wo4iIiLSHVo4p9brIyEjY2trmuz49PR0xMTFSGi8vL+jp6SEiIkJKExUVhfj4eHh7e+ebj1wuh5mZmcpU3vjEj4iIqPLo06cPFi5cmGv5okWL8MEHH6ihRJUL601ERETaR61BqfT0dERGRiIyMhIAEBsbi8jISGlg8qlTp6p0B1y6dCl27dqF6OhoXL9+HYGBgfjrr78wduxYKc2kSZNw9OhRxMXF4dSpU+jVqxd0dXUREBAAQOxiOGLECAQFBeHw4cO4ePEihg0bBm9vb4148x7AJ3xERESV0bFjx9CtW7dcy/38/HDs2LEy39/Tp08RGBgIBwcHGBoaolWrVjh//ry0XhAEzJw5E7a2tjA0NISPjw9u3bpVaL4//vgjHB0dYWBggJYtW+LcuXNlXvaS4EDnRERE2ketQakLFy6gSZMmaNKkCQAgKCgITZo0wcyZMwEAiYmJKm/Oy8rKwsSJE9GoUSO0b98eV65cwaFDh9C5c2cpTUJCAgICAuDq6op+/frBwsICZ86cgaWlpZTm+++/x3vvvYc+ffqgXbt2sLGxwY4dOyroqIuOT/yIiIgqj/T0dOjr6+darqenVy4vUBk5ciTCw8OxYcMGXLt2De+++y58fHxw7949AGILrWXLlmHVqlU4e/YsjI2N4evrixcvXuSb55YtWxAUFIRZs2bh0qVL8PT0hK+vLx48eFDm5S8pBqWIiIi0h0wQGPooibS0NJibmyM1NbXMu/INGQKsXw8sWgRMnlymWRMREVExldVvfosWLfDee+9JD9+UZs+ejT/++AMXL14sbVElz58/h6mpKXbt2oXu3btLy728vODn54d58+bBzs4OEydOxKRJkwAAqampsLa2RkhICPr3759nvi1btkTz5s2xYsUKAOLbA+3t7TF+/Hh8+eWXhZarPOtPe/cC3bsDXl7AhQtlmjUREREVU1F/84s10DlVDD7hIyIiqnxmzJiB3r17IyYmBp06dQIAREREIDQ0FNu2bSvTfb18+RIKhQIGBgYqyw0NDXHixAnExsYiKSkJPj4+0jpzc3O0bNkSp0+fzjMolZWVhYsXL2Lq1KnSMh0dHfj4+OD06dNlWv6SYPc9IiIi7cOglAZjGzYiIqLKw9/fH2FhYfjmm2+wbds2GBoawtPTE3/99ReqV69epvsyNTWFt7c35s2bB3d3d1hbW2Pz5s04ffo06tSpg6SkJACAtbW1ynbW1tbSujc9fPgQCoUiz23++eefPLfJzMxEZmamNF8e3RTfxKAUERGR9tD6t+9VRsrKFINSRERElUv37t1x8uRJZGRk4Pbt2+jXrx8mTZoET0/PMt/Xhg0bIAgCatasCblcjmXLliEgIAA6OhVX/QsODoa5ubk02dvbl9u+WG8iIiLSPgxKaSA+4SMiIqq8jh07hiFDhsDOzg7ffvstOnXqhDNnzpT5flxcXHD06FGkp6fj7t27OHfuHLKzs+Hs7AwbGxsAQHJysso2ycnJ0ro31ahRA7q6usXaZurUqUhNTZWmu3fvlsGR5Y3d94iIiLQPg1IajE/8iIiIKoekpCQsWLAAdevWxQcffAAzMzNkZmYiLCwMCxYsQPPmzctt38bGxrC1tcWTJ09w4MAB9OjRA05OTrCxsUFERISULi0tDWfPnoW3t3ee+ejr68PLy0tlm5ycHEREROS7jVwuh5mZmcpU3hiUIiIi0h4MSmkgVqaIiIgqD39/f7i6uuLq1atYunQp7t+/j+XLl5f7fg8cOID9+/cjNjYW4eHh6NixI9zc3DBs2DDIZDIEBgZi/vz52L17N65du4bBgwfDzs4OPXv2lPLo3Lmz9KY9AAgKCsIvv/yCdevW4ebNmxgzZgwyMjIwbNiwcj+ewvBhHhERkfbhQOcajJUrIiIi7bdv3z5MmDABY8aMQd26dStsv6mpqZg6dSoSEhJQvXp19OnTB19//TX09PQAAF988QUyMjIwevRopKSkoE2bNti/f7/KG/tiYmLw8OFDaf7DDz/Ef//9h5kzZyIpKQmNGzfG/v37cw1+rk58uEdERKQ9GJTSQBzonIiIqPI4ceIE1qxZAy8vL7i7u2PQoEHo379/ue+3X79+6NevX77rZTIZ5s6di7lz5+abJi4uLteycePGYdy4cWVRxDLFehMREZH2Yfc9DcQnfERERJXHO++8g19++QWJiYn4+OOP8dtvv8HOzg45OTkIDw/H06dP1V3ESoEDnRMREWkfBqU0GJ/4ERERVR7GxsYYPnw4Tpw4gWvXrmHixIlYsGABrKys8P7776u7eJUGg1JERETag0EpDcTue0RERJWbq6srFi1ahISEBGzevFndxakUWG8iIiLSPgxKaSA+4SMiIno76OrqomfPnti9e7e6i6L12H2PiIhI+zAopcH4xI+IiIioeBiUIiIi0h4MSmkgdt8jIiIiKh7Wm4iIiLQPg1JEREREpPXYfY+IiEj7MCilgdhSioiIiKhkGJQiIiLSHgxKaSBWpoiIiIiKhw/ziIiItA+DUhqMlSsiIiKiomH3PSIiIu3DoJQGYvc9IiIiopJhUIqIiEh7MCilgViZIiIiIioePswjIiLSPgxKaTBWroiIiIiKhw/3iIiItAeDUhqI3feIiIiIiof1JiIiIu3DoJQG4hM+IiIiouLhQOdERETah0EpDcYnfkRERETFw6AUERGR9lBrUOrYsWPw9/eHnZ0dZDIZwsLCCkx/5MgRyGSyXFNSUpKUJjg4GM2bN4epqSmsrKzQs2dPREVFqeTToUOHXHl88skn5XGIJcLKFBEREVHx8GEeERGR9lFrUCojIwOenp748ccfi7VdVFQUEhMTpcnKykpad/ToUYwdOxZnzpxBeHg4srOz8e677yIjI0Mlj1GjRqnksWjRojI5prLEyhURERFR0bD7HhERkfapos6d+/n5wc/Pr9jbWVlZoWrVqnmu279/v8p8SEgIrKyscPHiRbRr105abmRkBBsbm2LvuyJwoHMiIiKikmFQioiISHto5ZhSjRs3hq2tLbp06YKTJ08WmDY1NRUAUL16dZXlmzZtQo0aNdCwYUNMnToVz549K7fyFhcrU0RERETFw4d5RERE2ketLaWKy9bWFqtWrUKzZs2QmZmJ1atXo0OHDjh79iyaNm2aK31OTg4CAwPRunVrNGzYUFo+YMAAODg4wM7ODlevXsWUKVMQFRWFHTt25LvvzMxMZGZmSvNpaWlle3CvUQalcnLKbRdERERElQq77xEREWkfrQpKubq6wtXVVZpv1aoVYmJi8P3332PDhg250o8dOxbXr1/HiRMnVJaPHj1a+rtRo0awtbVF586dERMTAxcXlzz3HRwcjDlz5pTRkRRMT0/8fPmyQnZHREREVGkwKEVERKQ9tLL73utatGiB6OjoXMvHjRuHP//8E4cPH0atWrUKzKNly5YAkGc+SlOnTkVqaqo03b17t3QFL0CV/4UKs7PLbRdERERElQq77xEREWkfrWoplZfIyEjY2tpK84IgYPz48di5cyeOHDkCJyenIuUBQCWfN8nlcsjl8lKXtyjYUoqIiIioZNhSioiISHuoNSiVnp6u0jopNjYWkZGRqF69OmrXro2pU6fi3r17WL9+PQBg6dKlcHJyQoMGDfDixQusXr0af/31Fw4ePCjlMXbsWISGhmLXrl0wNTVFUlISAMDc3ByGhoaIiYlBaGgounXrBgsLC1y9ehWff/452rVrBw8Pj4o9AflgSykiIiKi4mFLKSIiIu2j1qDUhQsX0LFjR2k+KCgIADBkyBCEhIQgMTER8fHx0vqsrCxMnDgR9+7dg5GRETw8PHDo0CGVPFauXAkA6NChg8q+1q5di6FDh0JfXx+HDh3C0qVLkZGRAXt7e/Tp0wfTp08vxyMtHmVLKQaliIiIiIqGA50TERFpH7UGpTp06AChgMdaISEhKvNffPEFvvjiiwLzLCg/ALC3t8fRo0eLXEZ1ULaUYvc9IiIiouJhUIqIiEh7aP1A55URW0oRERERFQ+77xEREWkfBqU0EFtKERERERUPu+8RERFpHwalNBBbShERERGVDINSRERE2oNBKQ3Et+8RERFRaSgUCsyYMQNOTk4wNDSEi4sL5s2bpzL2pkwmy3NavHhxvvnOnj07V3o3N7eKOKRCsfseERGR9lHrQOeUN2VLKXbfIyIiopJYuHAhVq5ciXXr1qFBgwa4cOEChg0bBnNzc0yYMAEAkJiYqLLNvn37MGLECPTp06fAvBs0aIBDhw5J81WqaEZ1kt33iIiItI9m1CJIBbvvERERUWmcOnUKPXr0QPfu3QEAjo6O2Lx5M86dOyelsbGxUdlm165d6NixI5ydnQvMu0qVKrm21SQMShEREWkPdt/TQBzonIiIiEqjVatWiIiIwL///gsAuHLlCk6cOAE/P7880ycnJ2PPnj0YMWJEoXnfunULdnZ2cHZ2xsCBAxEfH59v2szMTKSlpalM5YXd94iIiLQPW0ppILaUIiIiotL48ssvkZaWBjc3N+jq6kKhUODrr7/GwIED80y/bt06mJqaonfv3gXm27JlS4SEhMDV1RWJiYmYM2cO2rZti+vXr8PU1DRX+uDgYMyZM6dMjqkw7L5HRESkfRiU0kAc6JyIiIhK4/fff8emTZsQGhqKBg0aIDIyEoGBgbCzs8OQIUNypf/1118xcOBAGBgYFJjv6y2tPDw80LJlSzg4OOD333/Ps5XV1KlTERQUJM2npaXB3t6+FEdWOAaliIiItAeDUhqIA50TERFRaUyePBlffvkl+vfvDwBo1KgR7ty5g+Dg4FxBqePHjyMqKgpbtmwp9n6qVq2KevXqITo6Os/1crkccrm8+AdQAuy+R0REpH04ppQGYkspIiIiKo1nz55BR0e1mqerq4ucnJxcadesWQMvLy94enoWez/p6emIiYmBra1ticta1thSioiISHswKKWB2FKKiIiISsPf3x9ff/019uzZg7i4OOzcuRPfffcdevXqpZIuLS0NW7duxciRI/PMp3PnzlixYoU0P2nSJBw9ehRxcXE4deoUevXqBV1dXQQEBJTr8RQFW0oRERFpH3bf00BsKUVERESlsXz5csyYMQOffvopHjx4ADs7O3z88ceYOXOmSrrffvsNgiDkG1SKiYnBw4cPpfmEhAQEBATg0aNHsLS0RJs2bXDmzBlYWlqW6/EUBQc6JyIi0j4MSmkgtpQiIiKi0jA1NcXSpUuxdOnSAtONHj0ao0ePznd9XFycyvxvv/1WBqUrXwxKERERaQ9239NAbClFREREVDzsvkdERKR9GJTSQMqWUgxKERERERUNu+8RERFpHwalNBC77xERERGVDINSRERE2oNBKQ3E7ntERERExcPue0RERNqHQSkNxJZSRERERMXD7ntERETah0EpDfT6mFI5OeotCxEREZE2YVCKiIhIezAopYEMDV/9nZmpvnIQERERaQt23yMiItI+DEppoNeDUs+fq68cRERERNqGLaWIiIi0B4NSGkhPD9DVFf9+9ky9ZSEiIiLSBmwpRUREpH0YlNJQytZSbClFREREVDgOdE5ERKR91BqUOnbsGPz9/WFnZweZTIawsLAC0x85cgQymSzXlJSUpJLuxx9/hKOjIwwMDNCyZUucO3dOZf2LFy8wduxYWFhYwMTEBH369EFycnJZH16pMChFREREVHwMShEREWkPtQalMjIy4OnpiR9//LFY20VFRSExMVGarKyspHVbtmxBUFAQZs2ahUuXLsHT0xO+vr548OCBlObzzz/HH3/8ga1bt+Lo0aO4f/8+evfuXWbHVRaMjMRPBqWIiIiICsfue0RERNqnijp37ufnBz8/v2JvZ2VlhapVq+a57rvvvsOoUaMwbNgwAMCqVauwZ88e/Prrr/jyyy+RmpqKNWvWIDQ0FJ06dQIArF27Fu7u7jhz5gzeeeedEh9PWWJLKSIiIqKiY/c9IiIi7aOVY0o1btwYtra26NKlC06ePCktz8rKwsWLF+Hj4yMt09HRgY+PD06fPg0AuHjxIrKzs1XSuLm5oXbt2lIaTcCgFBEREVHxMShFRESkPbQqKGVra4tVq1Zh+/bt2L59O+zt7dGhQwdcunQJAPDw4UMoFApYW1urbGdtbS2NO5WUlAR9ff1cLa1eT5OXzMxMpKWlqUzliUEpIiIioqJj9z0iIiLto9bue8Xl6uoKV1dXab5Vq1aIiYnB999/jw0bNpTrvoODgzFnzpxy3cfrGJQiIiIiKjp23yMiItI+WtVSKi8tWrRAdHQ0AKBGjRrQ1dXN9Sa95ORk2NjYAABsbGyQlZWFlJSUfNPkZerUqUhNTZWmu3fvlu2BvIFBKSIiIqLiY1CKiIhIe2h9UCoyMhK2trYAAH19fXh5eSEiIkJan5OTg4iICHh7ewMAvLy8oKenp5ImKioK8fHxUpq8yOVymJmZqUzliUEpIiIioqJj9z0iIiLto9bue+np6VIrJwCIjY1FZGQkqlevjtq1a2Pq1Km4d+8e1q9fDwBYunQpnJyc0KBBA7x48QKrV6/GX3/9hYMHD0p5BAUFYciQIWjWrBlatGiBpUuXIiMjQ3obn7m5OUaMGIGgoCBUr14dZmZmGD9+PLy9vTXmzXsAYGwsfmZkqLccRERERNqA3feIiIi0j1qDUhcuXEDHjh2l+aCgIADAkCFDEBISgsTERMTHx0vrs7KyMHHiRNy7dw9GRkbw8PDAoUOHVPL48MMP8d9//2HmzJlISkpC48aNsX//fpXBz7///nvo6OigT58+yMzMhK+vL3766acKOOKiUzbEevpUveUgIiIi0iYMShEREWkPmSCwsXNJpKWlwdzcHKmpqeXSlW/GDGD+fGDcOGD58jLPnoiIiIqovH/z3ybleS4XLgS+/BIYOhRYu7ZMsyYiIqJiKupvvtaPKVVZKb+z1FT1loOIiIhIm7ClFBERkfZgUEpDmZuLn2lp6i0HERERkTZg238iIiLtw6CUhlK2lGJQioiIiKhwHOiciIhI+zAopaHYfY+IiIio+BiUIiIi0h4MSmkotpQiIiIiKjp23yMiItI+DEppKOWYUikpai0GERERkVZg9z0iIiLtw6CUhrK0FD8fPwYUCvWWhYiIiEhbMChFRESkPaqouwCUtxo1xEpVTg7w8CFgba3uEhERERFpLnbfIyJNpFAokJ2dre5iEJU5PT096OrqljofBqU0VJUqYmDqv/+A5GQGpYiIiIgKwu57RKRJBEFAUlISUjgeC1ViVatWhY2NDWSl+PFlUEqDWVu/CkoRERERFZVCocDs2bOxceNGJCUlwc7ODkOHDsX06dOliuPQoUOxbt06le18fX2xf//+AvP+8ccfsXjxYiQlJcHT0xPLly9HixYtyu1YiotBKSLSBMqAlJWVFYyMjEp1006kaQRBwLNnz/DgwQMAgK2tbYnzYlBKg1lbA9evMyhFRERExbNw4UKsXLkS69atQ4MGDXDhwgUMGzYM5ubmmDBhgpSua9euWLt2rTQvl8sLzHfLli0ICgrCqlWr0LJlSyxduhS+vr6IioqClZVVuR1PUbD7HhFpCoVCIQWkLCws1F0conJhaGgIAHjw4AGsrKxK3JWPA51rMGXdjkEpIiIiKo5Tp06hR48e6N69OxwdHdG3b1+8++67OHfunEo6uVwOGxsbaapWrVqB+X733XcYNWoUhg0bhvr162PVqlUwMjLCr7/+Wp6HUyTsvkdEmkI5hpSRkZGaS0JUvpTXeGnGTWNQSoMpx5FiUIqIiIiKo1WrVoiIiMC///4LALhy5QpOnDgBPz8/lXRHjhyBlZUVXF1dMWbMGDx69CjfPLOysnDx4kX4+PhIy3R0dODj44PTp0/nuU1mZibS0tJUJiKitwW77FFlVxbXOINSGoxBKSIiIiqJL7/8Ev3794ebmxv09PTQpEkTBAYGYuDAgVKarl27Yv369YiIiMDChQtx9OhR+Pn5QaFQ5Jnnw4cPoVAoYP3G21esra2RlJSU5zbBwcEwNzeXJnt7+7I7yDewpRQRkWZydHTE0qVLi5z+yJEjkMlkHCT+LcExpTQYg1JERERUEr///js2bdqE0NBQNGjQAJGRkQgMDISdnR2GDBkCAOjfv7+UvlGjRvDw8ICLiwuOHDmCzp07l0k5pk6diqCgIGk+LS2tXANTAINSREQlVVirl1mzZmH27NnFzvf8+fMwNjYucvpWrVohMTER5ubmxd5XSbm5uSE2NhZ37tyBjY1Nhe2XGJTSaAxKERERUUlMnjxZai0FiEGnO3fuIDg4WApKvcnZ2Rk1atRAdHR0nkGpGjVqQFdXF8lvVEySk5PzrcDL5fJCB08vKxzonIiodBITE6W/t2zZgpkzZyIqKkpaZmJiIv0tCAIUCgWqVCk8pGBpaVmscujr61doYOjEiRN4/vw5+vbti3Xr1mHKlCkVtu+8ZGdnQ09PT61lqEjsvqfBHBzEz9u3WdEiIiKionv27Bl0dFSrebq6usjJycl3m4SEBDx69Cjf1zrr6+vDy8sLERER0rKcnBxERETA29u7bApeCuy+R0RUOq+/+MLc3BwymUya/+eff2Bqaop9+/bBy8sLcrkcJ06cQExMDHr06AFra2uYmJigefPmOHTokEq+b3bfk8lkWL16NXr16gUjIyPUrVsXu3fvlta/2X0vJCQEVatWxYEDB+Du7g4TExN07dpVJYj28uVLTJgwAVWrVoWFhQWmTJmCIUOGoGfPnoUe95o1azBgwAAMGjQozxd3JCQkICAgANWrV4exsTGaNWuGs2fPSuv/+OMPNG/eHAYGBqhRowZ69eqlcqxhYWEq+VWtWhUhISEAgLi4OMhkMmzZsgXt27eHgYEBNm3ahEePHiEgIAA1a9aEkZERGjVqhM2bN6vkk5OTg0WLFqFOnTqQy+WoXbs2vv76awBAp06dMG7cOJX0//33H/T19VV+xzUBg1IarE4dQEcHSEsDXvv3RkRERFQgf39/fP3119izZw/i4uKwc+dOfPfdd1JFOT09HZMnT8aZM2cQFxeHiIgI9OjRA3Xq1IGvr6+UT+fOnbFixQppPigoCL/88gvWrVuHmzdvYsyYMcjIyMCwYcMq/Bjzw6AUEWkiQQAyMtQzlWUDhy+//BILFizAzZs34eHhgfT0dHTr1g0RERG4fPkyunbtCn9/f8THxxeYz5w5c9CvXz9cvXoV3bp1w8CBA/H48eN80z979gxLlizBhg0bcOzYMcTHx2PSpEnS+oULF2LTpk1Yu3YtTp48ibS0tFzBoLw8ffoUW7duxUcffYQuXbogNTUVx48fl9anp6ejffv2uHfvHnbv3o0rV67giy++kB7y7NmzB7169UK3bt1w+fJlREREoEWLFoXu901ffvklPvvsM9y8eRO+vr548eIFvLy8sGfPHly/fh2jR4/GoEGDVN6iO3XqVCxYsAAzZszAjRs3EBoaKo37OHLkSISGhiIzM1NKv3HjRtSsWROdOnUqdvnKlUAlkpqaKgAQUlNTy3U/deoIAiAIERHluhsiIiLKR0X95peltLQ04bPPPhNq164tGBgYCM7OzsK0adOEzMxMQRAE4dmzZ8K7774rWFpaCnp6eoKDg4MwatQoISkpSSUfBwcHYdasWSrLli9fLtSuXVvQ19cXWrRoIZw5c6bI5SrPczl9ulhnGjeuzLMmIiqW58+fCzdu3BCeP38uLUtPF/+PUseUnl78Y1i7dq1gbm4uzR8+fFgAIISFhRW6bYMGDYTly5dL8w4ODsL3338vzQMQpk+f/tq5SRcACPv27VPZ15MnT6SyABCio6OlbX788UfB2tpamre2thYWL14szb98+VKoXbu20KNHjwLL+n//939C48aNpfnPPvtMGDJkiDT/888/C6ampsKjR4/y3N7b21sYOHBgvvkDEHbu3KmyzNzcXFi7dq0gCIIQGxsrABCWLl1aYDkFQRC6d+8uTJw4URAE8XdeLpcLv/zyS55pnz9/LlSrVk3YsmWLtMzDw0OYPXt2ofspjryudaWi/uZzTCkN5+4OREcD//wDaFpAk4iIiDSTqakpli5dmu/bjgwNDXHgwIFC84mLi8u1bNy4cbm6BGgCdt8jIip/zZo1U5lPT0/H7NmzsWfPHiQmJuLly5d4/vx5oS2lPDw8pL+NjY1hZmaGBw8e5JveyMgILi4u0rytra2UPjU1FcnJySotlHR1deHl5VVgt3UA+PXXX/HRRx9J8x999BHat2+P5cuXw9TUFJGRkWjSpAmqV6+e5/aRkZEYNWpUgfsoijfPq0KhwDfffIPff/8d9+7dQ1ZWFjIzM2FkZAQAuHnzJjIzM/N9MYmBgYHUHbFfv364dOkSrl+/rtJNUlMwKKXh3NyAP/4Qg1JEREREVDAGpYhIExkZAenp6tt3WXnzLXqTJk1CeHg4lixZgjp16sDQ0BB9+/ZFVlZWgfm8OZC3TCYrMICUV3qhlP0Sb9y4gTNnzuDcuXMqg5srFAr89ttvGDVqFAwNDQvMo7D1eZUzOzs7V7o3z+vixYvxww8/YOnSpWjUqBGMjY0RGBgondfC9guIXfgaN26MhIQErF27Fp06dYKDcuBqDcIxpTScm5v4+fff6i0HERERkSbjS2GISJPJZICxsXqm8gzWnzx5EkOHDkWvXr3QqFEj2NjY5NnKtjyZm5vD2toa58+fl5YpFApcunSpwO3WrFmDdu3a4cqVK4iMjJSmoKAgrFmzBoDYoisyMjLf8a48PDwKHDjc0tJSZUD2W7du4dmzZ4Ue08mTJ9GjRw989NFH8PT0hLOzM/79919pfd26dWFoaFjgvhs1aoRmzZrhl19+QWhoKIYPH17oftWBQSkN5+Ulfp49C+QRUCUiIiIisPseEZE61K1bFzt27EBkZCSuXLmCAQMGFNplrjyMHz8ewcHB2LVrF6KiovDZZ5/hyZMnkOXzo5CdnY0NGzYgICAADRs2VJlGjhyJs2fP4u+//0ZAQABsbGzQs2dPnDx5Erdv38b27dtx+vRpAMCsWbOwefNmzJo1Czdv3sS1a9ewcOFCaT+dOnXCihUrcPnyZVy4cAGffPJJrlZfealbty7Cw8Nx6tQp3Lx5Ex9//DGSk5Ol9QYGBpgyZQq++OILrF+/HjExMThz5owUTFMaOXIkFixYAEEQVN4KqEkYlNJwjRoB1auLb02IjFR3aYiIiIg0G4NSREQV57vvvkO1atXQqlUr+Pv7w9fXF02bNq3wckyZMgUBAQEYPHgwvL29YWJiAl9fXxgYGOSZfvfu3Xj06FGegRp3d3e4u7tjzZo10NfXx8GDB2FlZYVu3bqhUaNGWLBgAXR1dQEAHTp0wNatW7F79240btwYnTp1UnlD3rfffgt7e3u0bdsWAwYMwKRJk6RxoQoyffp0NG3aFL6+vujQoYMUGHvdjBkzMHHiRMycORPu7u748MMPc43LFRAQgCpVqiAgICDfc6FuMqG0HTFL4dixY1i8eDEuXryIxMRE7Ny5M9eJzs/JkyfRvn17NGzYEJGvRWscHR1x586dXOk//fRT/PjjjwDEC+fo0aMq6z/++GOsWrWqyGVPS0uDubk5UlNTYWZmVuTtSsLXFzh4EPj5Z2D06HLdFREREb2hIn/zK7vyPJdTpwILFgCBgcD335dp1kRExfLixQvExsbCyclJYwMBlV1OTg7c3d3Rr18/zJs3T93FUZu4uDi4uLjg/Pnz5RIsLOhaL+pvvlpbSmVkZMDT01MKFhVVSkoKBg8enOdI8+fPn0diYqI0hYeHAwA++OADlXSjRo1SSbdo0aKSH0g58/QUP69cUW85iIiIiDQdW0oREb197ty5g19++QX//vsvrl27hjFjxiA2NhYDBgxQd9HUIjs7G0lJSZg+fTreeecdtbReKyq1vn3Pz88Pfn5+xd7uk08+wYABA6Crq4uwsDCVdZaWlirzCxYsgIuLC9q3b6+y3MjICDY2NsXetzoor59Tp9RbjgIpFMDx40BiImBrC7RtC/yvSSMRERFReeNA50REby8dHR2EhIRg0qRJEAQBDRs2xKFDh+Du7q7uoqnFyZMn0bFjR9SrVw/btm1Td3EKpNagVEmsXbsWt2/fxsaNGzF//vwC02ZlZWHjxo0ICgrKNcDZpk2bsHHjRtjY2MDf3x8zZswoUt9OdejUSfyMjASSkwFra7UWJ7cdO4DPPgMSEl4tq1UL+OEHoHdv9ZWrKLQ1mKat5dZmPOdERBqNA50TEb297O3tcfLkSXUXQ2N06NABahypqVi0Kih169YtfPnllzh+/DiqVCm86GFhYUhJScHQoUNVlg8YMAAODg6ws7PD1atXMWXKFERFRWHHjh355pWZmYnMzExpPi0trcTHUVxWVkCTJsDly8ChQ8DAgRW268Lt2AH07Zv78eS9e+Lybds0NzClrcE0bS23kjYGd7T5nGvj+VbS1rJra7mJKgkGpYiIiLSH1rx9T6FQYMCAAZgzZw7+v717D4uqXPsH/p0ZYDgfBORgnFQ8hKjlKTxmemlqpqalhoZJWamllYWmll1t071rW1k73t37U9y+eXizLe4OHl5UNDVPqKAmESqKIYiKnM8zz++PpxkYQUAd1jD0/VzXXMOs9cxa97pnMfPMPc9aq1OnTk16zpo1azBq1Cj4+/ubTJ81axZGjhyJ8PBwREZGYv369YiPj8eFCxfuuKwVK1bAzc3NeAsICLiv7blbI0bI+127FF1tw3Q6+UW9vgqsYdr8+bJdS2MoptUuMgA1xbQGCpQWZa1xG2zdCgQHA0OHAs8+K++Dg1t23Nacc2vMt4G1xm6tcQPyvXrfPmDTJnnfEt+762OtcZPZWckPwkRERFSL1YyUKioqQlJSEk6dOoW5c+cCkGfUF0LAxsYG//d//4fHDMe5QZ7obPfu3Q2OfjLo168fAOD8+fPo0KFDvW0WLVqEN954w/i4sLBQ0cLUiBHAX/8qi1LV1UATBoo1vwMH6n5Rr00I4MoVYPhwecyhWm16U6nqTrvTdHO2BYAlSxoupr34IlBQUPO8O7nTvHt5TmPL0+uB115rOO7Zs4HQUMDFBXBwkDdHx5axw1jbqDqdDigpAV599c45V6nk/AEDAHt7wNZW3mxsLP9TvbXluzZrjd1a4wasdzSgtcZNzYKH7xEREVmfFvBNtWlcXV1x5swZk2lffvkl9u7di2+//RYhISEm8+Li4tC2bVuMGTOm0WUnJycDAPz8/O7YRqvVQqvV3n3gZjJgAODmBuTmAl98IQcgWVx2dtPa7dvXrGE0i7w8YOZMS0dx965dA7p3rzvdxqamQFW7WNUcf2u1db8RNDaqTqWSO/W4cXUPc6quBsrKgPLymvvaf9/tfVPbVlU1nm8hgKtXgfoummAoUN1+s7Nr2rT7aavRyHw2VMB8+WXA2bmmUGuYfvt9Q/Pu9b6heTodMGdOw7G/9JIsAtrZyW013NTq+3tc37Smfru9n33c0qy1mGatcVOzY1GKiIjIeli0KFVcXIzz588bH2dkZCA5ORlt2rRBYGAgFi1ahKysLKxfvx5qtRrdunUzeX7btm1hb29fZ7per0dcXByioqLqnHvqwoUL2LhxI0aPHg1PT0+cPn0ar7/+OgYPHozu9X2ZbyG0WmDlSuCVV4C//11+Z7O1tXBQDRTxTLz2GtChgxzpI4S8v/1mrulNec7ly0BSUuNxd+/e8Dbe6TiBho4fuJd5huk5OcC5c3d+voGTk/yCXF5eM626GigqkrfmplLJgkHtYpVe37RRdUFBsihQuzhkrYfiVFU1rbBlKdevAyNHWjqKe3PjBtCEHxzMpimFraoqGdedGPbxhx8GPD1lodhw02jM+/hunqNSyQ+Whopps2cDgYFyW2u/l9a+r2+aue9r/11dDSxaZJ1FQGo2PHyPiIjI+li0KJWUlIShQ4caHxsOj4uKisK6deuQnZ2NzMzMu17u7t27kZmZiZn1jHSxs7PD7t278emnn6KkpAQBAQGYOHEilixZcu8bopAZM4D33pPf7ePjgWeesXBAgwbJwySysurvCapUcv6qVS3rS8G+ffI8L4357DPg0UebO5qma2rcP/wg49brgYoKoLRUFnfKypr3b0PxSIiaeXcrK6vh+XZ2sshlb6/M/bFjwOjRjce9Z48czmgoRBlulZV1p91pelOnNaXtlSvAL780HndAAODubjqswPB3Y/fN1TY3F0hLazz2wEDA1VXud3q9vDfc7uZxU9xN28acPm2e5ShFCDkCs08fS0dydwxFwAMHWtb7ODUrHr5HRERkfVTCWq4T2MIUFhbCzc0NBQUFcHV1VWy9S5cCf/kL0K8fcOhQC6j1GA6fAEwLU4YeYUs8fEKnkycebqyYlpHRAhJcS0uPu6rqzoWrw4eBmJjGl/HZZ0D//vUXieztaw41U0pLz/mdNLWAmZjY8r6wKx27YSTlnYpWTS1wHT0qD4lszLJlQOfOcqSPTifvDbfbHyvR5tYtWQhsjLu7HIVpODefpe+zsoATJxqPe+NGYOrUxts1wlKf+a1Rc+byzTfl72AxMXJ0ORGRpZSXlyMjIwMhISGwt7e3dDiKe/TRR9GzZ098+umnAIDg4GDMnz8f8xs4B41KpUJ8fDzGjx9/X+s213KoaRra15v6mW8155QiacYM2dE6ehSIiwNeeMHCAT31lCw81Xei2U8/bXkFKUAWDz77TBbTVKr6i2mfftqyigxAy4/b1lae+MzNre68/v2Bzz9vvLgzZ07LyntLz/mdNHUU46BBysfWGKVjN1wI4X4vBhAeLn8xaCzuJUta1v7S1CJgfHzLKmA2Ne6mHmZOrQJ/ZiWiVkmnkyN/s7Pl59qgQc3Wlxg7diyqqqqwc+fOOvMOHDiAwYMHIyUl5a5Pe3P8+HE4OTmZK0wAwLJly7Bt2zbj+aENsrOz4eHhYdZ13UlZWRnatWsHtVqNrKwsi56D2popPOyA7leHDsDbb8u/X3wRuHjRsvEAkIWnS5fkyIWNG+V9RkbLLEgZGIpp7dqZTn/ggZY5usvAWuM2FHeAusdVtOTiDmCdObfmfFtr7NYat6EI2NCVPwMCWl4B01rjpmbFw/eIqNXZulWO2h86FHj2WXkfHCynN4Po6GgkJCTg93rOBRsXF4fevXvf03mYvb294ejoaI4QG+Xr66tYcejf//43wsLC0KVLF2zbtk2Rdd6JEALV1dUWjeFesShlhWofITJpElBcbLlYjDQa+Sv61KnyvqV98aqPNRbTAOuO29qKOwbWmHNrz7c1xm6NcVtrMc1a4yZFsChFRK2C4TQptxeIDFeZbYbC1BNPPAFvb2+sW7fOZHpxcTG2bNmC6Oho3Lx5E1OnTkW7du3g6OiI8PBwbNq0qcHlBgcHGw/lA4D09HQMHjwY9vb2ePDBB5GQkFDnOTExMejUqRMcHR3Rvn17LF26FFV/XERo3bp1eP/995GSkgKVSgWVSmWMWaVSmRSIzpw5g8ceewwODg7w9PTErFmzUFzrC/SMGTMwfvx4fPzxx/Dz84OnpyfmzJljXFdD1qxZg2nTpmHatGlYs2ZNnfm//PILnnjiCbi6usLFxQWDBg3ChQsXjPPXrl2LsLAwaLVa+Pn5Ye7cuQCAS5cuQaVSmYwCy8/Ph0qlwr4/rmy/b98+qFQq7NixA7169YJWq8XBgwdx4cIFjBs3Dj4+PnB2dkafPn2we/duk7gqKioQExODgIAAaLVadOzYEWvWrIEQAh07dsTHH39s0j45ORkqlcrkInXmxMP3rFBAgDx8b/Bg4NQpYOZMYNMm9r3viaGYZm2sNe6nnpJXw1JoCLJZWWPOrTnf1hq7NcZtjYdhA9YbNzUbHr5HRC2aEPKcq02h08krmDd0ldl584Dhw5vWx3B0bFLF3sbGBs899xzWrVuHxYsXQ/XHc7Zs2QKdToepU6eiuLgYvXr1QkxMDFxdXfHjjz9i+vTp6NChA/r27dvoOvR6PZ566in4+Pjg6NGjKCgoqPdcUy4uLli3bh38/f1x5swZvPjii3BxccHbb7+NyZMn4+zZs9i5c6ex4OJWzylESkpKMHLkSEREROD48ePIzc3FCy+8gLlz55oU3hITE+Hn54fExEScP38ekydPRs+ePfHiiy/ecTsuXLiAw4cPY+vWrRBC4PXXX8fly5cRFBQEAMjKysLgwYPx6KOPYu/evXB1dcWhQ4eMo5liY2PxxhtvYOXKlRg1ahQKCgpw6NChRvN3u4ULF+Ljjz9G+/bt4eHhgStXrmD06NFYvnw5tFot1q9fj7FjxyItLQ2BgYEAgOeeew6HDx/G6tWr0aNHD2RkZODGjRtQqVSYOXMm4uLisGDBAuM64uLiMHjwYHTs2PGu42sSQfekoKBAABAFBQUWi+E//zFcI1vevv1WCL3eYuEQEZE1q64WIjFRiI0b5X11taUjahoF4m4Jn/mtRXPmct482R965x2zL5qI6K6UlZWJc+fOibKyspqJxcWmX96UvBUXNzn21NRUAUAkJiYapw0aNEhMmzbtjs8ZM2aMePPNN42PhwwZIubNm2d8HBQUJD755BMhhBC7du0SNjY2Iisryzh/x44dAoCIj4+/4zo++ugj0atXL+Pj9957T/To0aNOu9rL+eqrr4SHh4corrX9P/74o1Cr1SInJ0cIIURUVJQICgoS1bX6D08//bSYPHnyHWMRQoh33nlHjB8/3vh43Lhx4r333jM+XrRokQgJCRGVlZX1Pt/f318sXry43nkZGRkCgDh16pRx2q1bt0xel8TERAFAbNu2rcE4hRAiLCxMfP7550IIIdLS0gQAkZCQUG/brKwsodFoxNGjR4UQQlRWVgovLy+xbt26etvXu6//oamf+Tx8z4o9+STwz3/WPJ40CRg2DLhxw3IxERGRlbLGw7AB642bzI4jpYiI7l+XLl3Qv39/rF27FgBw/vx5HDhwANHR0QAAnU6HDz74AOHh4WjTpg2cnZ2xa9cuZGZmNmn5qampCAgIgL+/v3FaREREnXb/+7//iwEDBsDX1xfOzs5YsmRJk9dRe109evQwOcn6gAEDoNfrkZaWZpwWFhYGTa3+g5+fH3IbuDqxTqfDv/71L0ybNs04bdq0aVi3bh30ej0AecjboEGDYGtrW+f5ubm5uHr1KoYNG3ZX21Of3r17mzwuLi7GggUL0LVrV7i7u8PZ2RmpqanG3CUnJ0Oj0WDIkCH1Ls/f3x9jxowxvv7ff/89Kioq8PTTT993rHfCopSVmzUL+H//r+ZxYiLg7Q14ecnTbRw9Kkd/EhEREbVmPNE5EbVojo7yZMBNuW3f3rRlbt/etOXd5UnGo6Oj8e9//xtFRUWIi4tDhw4djEWMjz76CJ999hliYmKQmJiI5ORkjBw5EpWVlXebkTs6fPgwIiMjMXr0aPzwww84deoUFi9ebNZ11HZ74UilUhmLS/XZtWsXsrKyMHnyZNjY2MDGxgZTpkzB5cuXsWfPHgCAg4PDHZ/f0DwAUKtlmUbU+rXlTue4uv2qhgsWLEB8fDw+/PBDHDhwAMnJyQgPDzfmrrF1A8ALL7yAzZs3o6ysDHFxcZg8eXKznqieRalWIDoa0OuBn38GPD3ltJs3gfnzgUcekVc6d3ICevWSPyInJsr5xcVAejpQWGjJ6ImIiIjMh0UpImqRVCr5pawptxEjmnaV2REjmra8u3xjfOaZZ6BWq7Fx40asX78eM2fONJ5f6tChQxg3bhymTZuGHj16oH379vjtt9+avOyuXbviypUryM7ONk47cuSISZuff/4ZQUFBWLx4MXr37o3Q0FBcvnzZpI2dnR10jYy+6Nq1K1JSUlBSUmKcdujQIajVanTu3LnJMd9uzZo1mDJlCpKTk01uU6ZMMZ7wvHv37jhw4EC9xSQXFxcEBwcbC1i38/b2BgCTHNU+6XlDDh06hBkzZmDChAkIDw+Hr68vLl26ZJwfHh4OvV6P/fv333EZo0ePhpOTE2JjY7Fz507MnDmzSeu+VyxKtRIqFRARASQlAe++C4wZA9QaEYnSUuDkSWD/fuCxx+RIKhcXoFMnwM0NCAyUJ04fNw7o3x/w8AAefhgID5dFr4sX5UnVDQXj24fIG94P9HqgqIhD6ImIiEhZ7HsQUath4avMOjs7Y/LkyVi0aBGys7MxY8YM47zQ0FAkJCTg559/RmpqKl566SVcu3atycsePnw4OnXqhKioKKSkpODAgQNYvHixSZvQ0FBkZmZi8+bNuHDhAlavXo34+HiTNsHBwcjIyEBycjJu3LiBioqKOuuKjIyEvb09oqKicPbsWSQmJuLVV1/F9OnT4ePjc3dJ+cP169fx/fffIyoqCt26dTO5Pffcc9i2bRvy8vIwd+5cFBYWYsqUKUhKSkJ6ejr+53/+x3jY4LJly/D3v/8dq1evRnp6Ok6ePInPP/8cgBzN9Mgjj2DlypVITU3F/v37sWTJkibFFxoaiq1btyI5ORkpKSl49tlnTUZ9BQcHIyoqCjNnzsS2bduQkZGBffv24ZtvvjG20Wg0mDFjBhYtWoTQ0NB6D680J159r5UJDgbef7/mcUaGLFSdOCELRxs2yAtC3e7KFXmr7dQpeX/2LPDHIaUAADs7oLJSFu99fWXB6tYtoEsXIC2tpnDVtauc7+4ul+3hIZ9z7pwsgIWEyCLZpUuy3alT8jxZ+flAx45Ahw5y2oEDssA2YgRgayvX7e4u13P4sCyode8ui2u//w7s3i3XNWmSHDl2/rzc9h49ZBzOzrLjWlYG5OXJGKZMkaNaNRp5+GNxsdymggK5HZcuyYtolZbK9VRWAtXVQEkJ0LmzXH51tbzXamVhzs0NuHZNPvbwAKqq5PO1WsDeviaftx9ucOSIzI3hfTIvD2jTpuHX/Y+LOBhVVckRcvUcwmyioACIjQWmT697FfvGnlfPBS4AyNdF3cRyt+HiIYbnlZff9ejiZldVJfcHDw9LR0JERA3h4XtE1KpY+Cqz0dHRWLNmDUaPHm1y/qclS5bg4sWLGDlyJBwdHTFr1iyMHz8eBQUFTVquWq1GfHw8oqOj0bdvXwQHB2P16tV4/PHHjW2efPJJvP7665g7dy4qKiowZswYLF26FMuWLTO2mThxIrZu3YqhQ4ciPz8fcXFxJsUzAHB0dMSuXbswb9489OnTB46Ojpg4cSJWrVp1z3lZv349nJyc6j0f1LBhw+Dg4ICvv/4ar732Gvbu3Yu33noLQ4YMgUajQc+ePTFgwAAAQFRUFMrLy/HJJ59gwYIF8PLywqRJk4zLWrt2LaKjo9GrVy907twZf/vb3zBixIhG41u1ahVmzpyJ/v37w8vLCzExMSi87dCo2NhYvPPOO5g9ezZu3ryJwMBAvPPOOyZtoqOj8eGHH+L555+/lzTdFZUQ/F3pXhQWFsLNzQ0FBQVwdXW1dDh35cIF2WHTamURYMcOeUifk5MsZKSkyFFV1DR2drKgcnthqDZXV9MRZF27ykMoa58/z8VFtjHo3FkW+QzrcHOTxbqiIuD6dfkaajTydbx+Xb6WGo0seFVXy+kDB8riW2EhEBQEHDxYU0y6dcu0QPnHFULh4CCLTmq13CcCAuTyKyqAAQPkZ2JCghxxFxIi13v8uCxqFRfLv21s5DY+8IAs4JWUyJF32dlyu319ZcFswwa5vr595eGnajUwaJAsJrZrJwuUlZWy/bFjsqiYlydz8PzzclsLC+V2q1Qy7uxsmdf27WV8lZUynuvXZR7btpXLunoVGDpUviZqtSx8Xr0KnDkjRxoWFckC5tat8nUYMkS+zufOAf36yXx5esp16XQyLjc3WbwqKZGxhoTI+9OnZSE1JAR48EH5+mRmynXb2soc29jI9VdWygLvjz/KaYMHy+caCponTsg8P/EE8NNP8vXt0kUWTvv1Ay5frtk/HB3l8x56CPjmG1lYrayU8QwZIvNhayv3T5VKvl6Gwq23tyxoG6b7+ckCb0aG3O7iYiAsTL5+KpXcphs35LY7OMjH9vZyP3NxkXEUF8scnTsn129vL18zLy8Zl+GUB3o9kJUli+xBQbLNb7/J/dHDQ+ahoEBuu729fP2rquT6e/eW+5ifn8zDjRuyaG34LLazA1JTZc4zMuR+ev26XF55udxvXFzkdly/LvfBsjK57h49ZOx2djJHzs5yfyoslHkvKal5rZycZJxqtZyfny+3pU0bmfOMDBl3u3Zym06elP8DYWEyZ8eOySJ9z55yn7x0CejTR+6XGRny0OyQEBn3xYtyuW3bythOnJB5fPBBuX/q9TKmX3+V2+fgIJefmSnbODnJfaSsTL6WbdrIv9PS5Db98ov8/9DpZL6qq2va5OXJ2Lp3l+8R3brJvNy8WfM+dPGi3EZvb7kPpafL9tnZ8nVycZGvPyBj6tRJ7hPffy9/NJg/X+7jGo38n6mslJ9j338vi/cREXI/+P13+T/Qo8fdvYc3hTV/5rc0zZnLuXOBf/xDjhiv/QMdEZHSysvLkZGRgZCQENjX/jX6Xuh08ld6wwfnoEG8qAc1uwMHDmDYsGG4cuVKg6PKGtrXm/qZz6LUPfozdVBzc+Xond695ZcQW1v5xSc9XX5R7NBBfqGys5NfJPR6+aXo+nX5pTYvT36BcnKSj2/dkl9I8/Lkl7WkpJp19ewJJCfL9lVV8ovM7t1yXq9echmHDskv6/WM0ERAQN0RX7a2Mq7sbPllrLKyppBU3zKIiMg6rVgBLFxo/uX+mT7zm1tz5nLOHODLL1mUIiLLM2tRikhBFRUVuH79OqKiouDr64sNGzY02N4cRSkevkeNattW/mJ/O19fWagH5AnUa3v2WfOtX6cz/THAUFQyHPqVmSkfe3rKAlR1tZwnhCw82dvL+6NH5TmyAFnUMvzPVFfLkQfe3jWjIgyH5F27JgtZbdrIEQOGEQydOsnnFhfL0S1du9YcFnj1qhydceOGHBlRXS3X7+0tl7Nzp4zVzk5eMKNXLzlSyNFRjkzYvl2u38tLjr7IzQWGD5cjTI4fl7mIiJBFQY1GjnxwcpLrPXlS/t2unYzbcE47NzdZQKyslDGVlAA5OXJ7tFq5PYYinYOD3O7u3WWOiorkMm/elCMRiork8nNyZL7Vahnv+fOy8KdWy2Kivb18XlaWXJ+LixzZoVLJdjY28jmdOslcnz0r4+nWTY7qqKiQeQXkthUWytemslI+39tbFiHbt5d51+lkjFqtHNVhOJH/6dPyNejYUcZTWChjKC2Vo7eysuQ25+XJfFZXy23UamWMarUcIXbhghwxUlgo19uli3xuebn829tb7osFBXLZt27JUS+OjvJ5oaEy9vR0mWtbW5ljvV6+xhqNzFNRkYwhN1fuFyUlMhd2dnLZV67I3NrYyDwIIUfEeXrKgm5mpoy5okKuMzlZbrtOJ1/7U6fkaJ6hQ+WIIRcXmeObN2VMbm4y9vx8uW9WV8tlGfbrgAD5nKwsuT9rNHIb8vNlLO7ucl1+fvI1KCmRubGxkQVoV1e5Hw8cKNsbDgeuqJDrLi6W+76vr4wvI0Muv2NHOSomO1vmwMtL/s9VVMjtzciQ+23XrnKZt27JeQEB8rVVqWRc+fmy3cMPy7guXZLtfXxkm9RUmUs3N7l8Dw+Zm9LSmlFkfn5yWlmZXKaLi3xOebncP7RaubzKypqRPYbRlEVFso1hZFNWlnxcUCD/3595Rq5zz56aZQoh793c5Hba2MjYDaPSgoLktubmymX17CljS0+X7fR6+ZzwcPl/Vl4u46uurjlM+PTpmtGXhng1GhnDmTNyHbm5Mr+GHwWcnGreLzIz5f0DD8jlGy66UVoq85WTU/M+bhgt2batfD2rquTr4uEhf+S4eFHGcP263J527WQbvb5mlK9WK183X18ZS2mp/L8PCjLfZw9ZHycn+b/V0g4DJyIishabNm1CdHQ0evbsifXr1yuyTo6Uukf81ZSIiOjPgZ/55sNcEtGfAUdK0Z+FOUZK8ep7RERERK2MTqfD0qVLERISAgcHB3To0AEffPABDL9FVlVVISYmBuHh4XBycoK/vz+ee+45XL16tcHlLlu2DCqVyuTWpUsXJTaJiIiIWiEevkdERETUyvz1r39FbGws/vWvfyEsLAxJSUl4/vnn4ebmhtdeew2lpaU4efIkli5dih49euDWrVuYN28ennzySSTVPtljPcLCwrDbcMJHADY27E4SERHRvWEvgoiIiKiV+fnnnzFu3DiMGTMGABAcHIxNmzbh2LFjAAA3NzckJCSYPOeLL75A3759kZmZiUDDJVnrYWNjA19f3+YLnoioleCZcqi1M8c+zsP3iIiIiFqZ/v37Y8+ePfjtt98AACkpKTh48CBGjRp1x+cUFBRApVLB3d29wWWnp6fD398f7du3R2RkJDIzM80ZOhGR1bO1tQUAlJaWWjgSouZl2McN+/y94EgpIiIiolZm4cKFKCwsRJcuXaDRaKDT6bB8+XJERkbW2768vBwxMTGYOnVqgycj7devH9atW4fOnTsjOzsb77//PgYNGoSzZ8/CxXA5z1oqKipQUVFhfFxYWHj/G0dE1MJpNBq4u7sjNzcXAODo6AiVSmXhqIjMRwiB0tJS5Obmwt3dHRrDZZbvAYtSRERERK3MN998gw0bNmDjxo0ICwtDcnIy5s+fD39/f0RFRZm0raqqwjPPPAMhBGJjYxtcbu2RVt27d0e/fv0QFBSEb775BtHR0XXar1ixAu+//755NoqIyIoYDnM2FKaIWiN3d/f7PqRfJXig6z3hJY2JiIj+HKzxMz8gIAALFy7EnDlzjNP+8pe/4Ouvv8avv/5qnGYoSF28eBF79+6Fp6fnXa+rT58+GD58OFasWFFnXn0jpQICAqwql0RE90On06GqqsrSYRCZna2tbYMjpJraf+JIKSIiIqJWprS0FGq16alDNRoN9Hq98bGhIJWeno7ExMR7KkgVFxfjwoULmD59er3ztVottFrtXS+XiKi10Gg093VoE1FrxxOdExEREbUyY8eOxfLly/Hjjz/i0qVLiI+Px6pVqzBhwgQAsiA1adIkJCUlYcOGDdDpdMjJyUFOTg4qKyuNyxk2bBi++OIL4+MFCxZg//79uHTpEn7++WdMmDABGo0GU6dOVXwbiYiIyPpxpBQRERFRK/P5559j6dKlmD17NnJzc+Hv74+XXnoJ7777LgAgKysL3333HQCgZ8+eJs9NTEzEo48+CgC4cOECbty4YZz3+++/Y+rUqbh58ya8vb0xcOBAHDlyBN7e3opsFxEREbUuPKfUPbLG80sQERHR3eNnvvkwl0RERH8OPKdUMzPU8nhpYyIiotbN8FnP3/HuH/tPREREfw5N7T+xKHWPioqKAMir2xAREVHrV1RUBDc3N0uHYdXYfyIiIvpzaaz/xMP37pFer8fVq1fh4uIClUpl1mUbLpd85coVDm1XCHOuLOZbecy5sphv5TVnzoUQKCoqgr+/f50r2tHdYf+pdWHOlcecK4v5Vh5zrqyW0H/iSKl7pFar8cADDzTrOlxdXfmPqDDmXFnMt/KYc2Ux38prrpxzhJR5sP/UOjHnymPOlcV8K485V5Yl+0/8uY+IiIiIiIiIiBTHohQRERERERERESmORakWSKvV4r333oNWq7V0KH8azLmymG/lMefKYr6Vx5wT9wHlMefKY86VxXwrjzlXVkvIN090TkREREREREREiuNIKSIiIiIiIiIiUhyLUkREREREREREpDgWpYiIiIiIiIiISHEsSrVA//jHPxAcHAx7e3v069cPx44ds3RIVmfFihXo06cPXFxc0LZtW4wfPx5paWkmbcrLyzFnzhx4enrC2dkZEydOxLVr10zaZGZmYsyYMXB0dETbtm3x1ltvobq6WslNsVorV66ESqXC/PnzjdOYc/PLysrCtGnT4OnpCQcHB4SHhyMpKck4XwiBd999F35+fnBwcMDw4cORnp5usoy8vDxERkbC1dUV7u7uiI6ORnFxsdKb0uLpdDosXboUISEhcHBwQIcOHfDBBx+g9qkZme/789NPP2Hs2LHw9/eHSqXCtm3bTOabK7+nT5/GoEGDYG9vj4CAAPztb39r7k0jBbD/ZB7sQ1kW+0/KYP9JWexDNS+r7z8JalE2b94s7OzsxNq1a8Uvv/wiXnzxReHu7i6uXbtm6dCsysiRI0VcXJw4e/asSE5OFqNHjxaBgYGiuLjY2Obll18WAQEBYs+ePSIpKUk88sgjon///sb51dXVolu3bmL48OHi1KlTYvv27cLLy0ssWrTIEptkVY4dOyaCg4NF9+7dxbx584zTmXPzysvLE0FBQWLGjBni6NGj4uLFi2LXrl3i/PnzxjYrV64Ubm5uYtu2bSIlJUU8+eSTIiQkRJSVlRnbPP7446JHjx7iyJEj4sCBA6Jjx45i6tSpltikFm358uXC09NT/PDDDyIjI0Ns2bJFODs7i88++8zYhvm+P9u3bxeLFy8WW7duFQBEfHy8yXxz5LegoED4+PiIyMhIcfbsWbFp0ybh4OAg/vnPfyq1mdQM2H8yH/ahLIf9J2Ww/6Q89qGal7X3n1iUamH69u0r5syZY3ys0+mEv7+/WLFihQWjsn65ubkCgNi/f78QQoj8/Hxha2srtmzZYmyTmpoqAIjDhw8LIeQ/t1qtFjk5OcY2sbGxwtXVVVRUVCi7AVakqKhIhIaGioSEBDFkyBBjp4o5N7+YmBgxcODAO87X6/XC19dXfPTRR8Zp+fn5QqvVik2bNgkhhDh37pwAII4fP25ss2PHDqFSqURWVlbzBW+FxowZI2bOnGky7amnnhKRkZFCCObb3G7vVJkrv19++aXw8PAweU+JiYkRnTt3buYtoubE/lPzYR9KGew/KYf9J+WxD6Uca+w/8fC9FqSyshInTpzA8OHDjdPUajWGDx+Ow4cPWzAy61dQUAAAaNOmDQDgxIkTqKqqMsl1ly5dEBgYaMz14cOHER4eDh8fH2ObkSNHorCwEL/88ouC0VuXOXPmYMyYMSa5BZjz5vDdd9+hd+/eePrpp9G2bVs89NBD+O///m/j/IyMDOTk5Jjk3M3NDf369TPJubu7O3r37m1sM3z4cKjVahw9elS5jbEC/fv3x549e/Dbb78BAFJSUnDw4EGMGjUKAPPd3MyV38OHD2Pw4MGws7Mzthk5ciTS0tJw69YthbaGzIn9p+bFPpQy2H9SDvtPymMfynKsof9kc1/PJrO6ceMGdDqdyQcKAPj4+ODXX3+1UFTWT6/XY/78+RgwYAC6desGAMjJyYGdnR3c3d1N2vr4+CAnJ8fYpr7XwjCP6tq8eTNOnjyJ48eP15nHnJvfxYsXERsbizfeeAPvvPMOjh8/jtdeew12dnaIiooy5qy+nNbOedu2bU3m29jYoE2bNsz5bRYuXIjCwkJ06dIFGo0GOp0Oy5cvR2RkJAAw383MXPnNyclBSEhInWUY5nl4eDRL/NR82H9qPuxDKYP9J2Wx/6Q89qEsxxr6TyxKUas3Z84cnD17FgcPHrR0KK3alStXMG/ePCQkJMDe3t7S4fwp6PV69O7dGx9++CEA4KGHHsLZs2fxX//1X4iKirJwdK3PN998gw0bNmDjxo0ICwtDcnIy5s+fD39/f+abiFol9qGaH/tPymP/SXnsQ1FDePheC+Ll5QWNRlPnahrXrl2Dr6+vhaKybnPnzsUPP/yAxMREPPDAA8bpvr6+qKysRH5+vkn72rn29fWt97UwzCNTJ06cQG5uLh5++GHY2NjAxsYG+/fvx+rVq2FjYwMfHx/m3Mz8/Pzw4IMPmkzr2rUrMjMzAdTkrKH3FF9fX+Tm5prMr66uRl5eHnN+m7feegsLFy7ElClTEB4ejunTp+P111/HihUrADDfzc1c+eX7TOvD/lPzYB9KGew/KY/9J+WxD2U51tB/YlGqBbGzs0OvXr2wZ88e4zS9Xo89e/YgIiLCgpFZHyEE5s6di/j4eOzdu7fOUMNevXrB1tbWJNdpaWnIzMw05joiIgJnzpwx+QdNSEiAq6trnQ8yAoYNG4YzZ84gOTnZeOvduzciIyONfzPn5jVgwIA6l+n+7bffEBQUBAAICQmBr6+vSc4LCwtx9OhRk5zn5+fjxIkTxjZ79+6FXq9Hv379FNgK61FaWgq12vRjU6PRQK/XA2C+m5u58hsREYGffvoJVVVVxjYJCQno3LkzD92zUuw/mRf7UMpi/0l57D8pj30oy7GK/tN9nyqdzGrz5s1Cq9WKdevWiXPnzolZs2YJd3d3k6tpUONeeeUV4ebmJvbt2yeys7ONt9LSUmObl19+WQQGBoq9e/eKpKQkERERISIiIozzDZfXHTFihEhOThY7d+4U3t7evLzuXah99RghmHNzO3bsmLCxsRHLly8X6enpYsOGDcLR0VF8/fXXxjYrV64U7u7u4j//+Y84ffq0GDduXL2XgH3ooYfE0aNHxcGDB0VoaCgvr1uPqKgo0a5dO+PljLdu3Sq8vLzE22+/bWzDfN+foqIicerUKXHq1CkBQKxatUqcOnVKXL58WQhhnvzm5+cLHx8fMX36dHH27FmxefNm4ejoaJZLGpPlsP9kPuxDWR77T82L/SflsQ/VvKy9/8SiVAv0+eefi8DAQGFnZyf69u0rjhw5YumQrA6Aem9xcXHGNmVlZWL27NnCw8NDODo6igkTJojs7GyT5Vy6dEmMGjVKODg4CC8vL/Hmm2+KqqoqhbfGet3eqWLOze/7778X3bp1E1qtVnTp0kV89dVXJvP1er1YunSp8PHxEVqtVgwbNkykpaWZtLl586aYOnWqcHZ2Fq6uruL5558XRUVFSm6GVSgsLBTz5s0TgYGBwt7eXrRv314sXrzY5NK4zPf9SUxMrPe9OyoqSghhvvympKSIgQMHCq1WK9q1aydWrlyp1CZSM2L/yTzYh7I89p+aH/tPymIfqnlZe/9JJYQQ9zfWioiIiIiIiIiI6O7wnFJERERERERERKQ4FqWIiIiIiIiIiEhxLEoREREREREREZHiWJQiIiIiIiIiIiLFsShFRERERERERESKY1GKiIiIiIiIiIgUx6IUEREREREREREpjkUpIiIiIiIiIiJSHItSRETNQKVSYdu2bZYOg4iIiMhqsP9E9OfDohQRtTozZsyASqWqc3v88cctHRoRERFRi8T+ExFZgo2lAyAiag6PP/444uLiTKZptVoLRUNERETU8rH/RERK40gpImqVtFotfH19TW4eHh4A5NDw2NhYjBo1Cg4ODmjfvj2+/fZbk+efOXMGjz32GBwcHODp6YlZs2ahuLjYpM3atWsRFhYGrVYLPz8/zJ0712T+jRs3MGHCBDg6OiI0NBTfffedcd6tW7cQGRkJb29vODg4IDQ0tE4nkIiIiEhJ7D8RkdJYlCKiP6WlS5di4sSJSElJQWRkJKZMmYLU1FQAQElJCUaOHAkPDw8cP34cW7Zswe7du006TbGxsZgzZw5mzZqFM2fO4LvvvkPHjh1N1vH+++/jmWeewenTpzF69GhERkYiLy/PuP5z585hx44dSE1NRWxsLLy8vJRLABEREdFdYv+JiMxOEBG1MlFRUUKj0QgnJyeT2/Lly4UQQgAQL7/8sslz+vXrJ1555RUhhBBfffWV8PDwEMXFxcb5P/74o1Cr1SInJ0cIIYS/v79YvHjxHWMAIJYsWWJ8XFxcLACIHTt2CCGEGDt2rHj++efNs8FERERE94n9JyKyBJ5TiohapaFDhyI2NtZkWps2bYx/R0REmMyLiIhAcnIyACA1NRU9evSAk5OTcf6AAQOg1+uRlpYGlUqFq1evYtiwYQ3G0L17d+PfTk5OcHV1RW5uLgDglVdewcSJE3Hy5EmMGDEC48ePR//+/e9pW4mIiIjMgf0nIlIai1JE1Co5OTnVGQ5uLg4ODk1qZ2tra/JYpVJBr9cDAEaNGoXLly9j+/btSEhIwLBhwzBnzhx8/PHHZo+XiIiIqCnYfyIipfGcUkT0p3TkyJE6j7t27QoA6Nq1K1JSUlBSUmKcf+jQIajVanTu3BkuLi4IDg7Gnj177isGb29vREVF4euvv8ann36Kr7766r6WR0RERNSc2H8iInPjSCkiapUqKiqQk5NjMs3GxsZ4MswtW7agd+/eGDhwIDZs2IBjx45hzZo1AIDIyEi89957iIqKwrJly3D9+nW8+uqrmD59Onx8fAAAy5Ytw8svv4y2bdti1KhRKCoqwqFDh/Dqq682Kb53330XvXr1QlhYGCoqKvDDDz8YO3VERERElsD+ExEpjUUpImqVdu7cCT8/P5NpnTt3xq+//gpAXtll8+bNmD17Nvz8/LBp0yY8+OCDAABHR0fs2rUL8+bNQ58+feDo6IiJEydi1apVxmVFRUWhvLwcn3zyCRYsWAAvLy9MmjSpyfHZ2dlh0aJFuHTpEhwcHDBo0CBs3rzZDFtOREREdG/YfyIipamEEMLSQRARKUmlUiE+Ph7jx4+3dChEREREVoH9JyJqDjynFBERERERERERKY5FKSIiIiIiIiIiUhwP3yMiIiIiIiIiIsVxpBQRERERERERESmORSkiIiIiIiIiIlIci1JERERERERERKQ4FqWIiIiIiIiIiEhxLEoREREREREREZHiWJQiIiIiIiIiIiLFsShFRERERERERESKY1GKiIiIiIiIiIgUx6IUEREREREREREp7v8DVstom+Mnz1sAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After all training epochs are completed, test on the test dataset\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False) # Create a DataLoader for the test dataset\n",
        "test_losses = []       # List to store test losses for each epoch\n",
        "test_accuracies = []   # List to store test accuracies for each epoch\n",
        "\n",
        "# Since there's only one epoch mentioned for testing, we loop once\n",
        "for epoch in range(1):\n",
        "    # Evaluate the model on the test dataset and get the test loss and accuracy\n",
        "    test_loss, test_accuracy = test(model, test_loader, criterion, device)\n",
        "    test_losses.append(test_loss)            # Append the test loss to the list\n",
        "    test_accuracies.append(test_accuracy)    # Append the test accuracy to the list\n",
        "    # Print the test loss and accuracy for the current epoch\n",
        "    print(\"epoch\", epoch, 'test_loss', test_loss, \"test_accuracies\", test_accuracy)\n",
        "\n",
        "# Print the final test accuracy\n",
        "print(f'Final Test Accuracy: {test_accuracies[-1]:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJhWkpFeWe5D",
        "outputId": "1caed99f-5850-4ad6-ff1f-ad9233c1bf41"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 test_loss 1.4708676666021347 test_accuracies 99.02\n",
            "Final Test Accuracy: 99.02%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}